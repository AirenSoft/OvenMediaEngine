diff --git a/VERSION b/VERSION
new file mode 100644
index 0000000000..978675e160
--- /dev/null
+++ b/VERSION
@@ -0,0 +1 @@
+n5.1.4.xlnx.2
diff --git a/configure b/configure
index 6629783f34..05f0307bf5 100755
--- a/configure
+++ b/configure
@@ -318,6 +318,9 @@ External library support:
   --enable-opengl          enable OpenGL rendering [no]
   --enable-openssl         enable openssl, needed for https support
                            if gnutls, libtls or mbedtls is not used [no]
+  --enable-libxma2api      enable Xilinx Media Accelerator API
+  --enable-libxrm          enable Xilinx Resource Management API
+  --enable-libxvbm         enable Xilinx video buffer management API
   --enable-pocketsphinx    enable PocketSphinx, needed for asr filter [no]
   --disable-sndio          disable sndio support [autodetect]
   --disable-schannel       disable SChannel SSP, needed for TLS support on
@@ -1874,6 +1877,8 @@ EXTERNAL_LIBRARY_LIST="
     libvorbis
     libvpx
     libwebp
+    libxma2api
+    libxrm
     libxml2
     libzimg
     libzmq
@@ -1885,6 +1890,7 @@ EXTERNAL_LIBRARY_LIST="
     openssl
     pocketsphinx
     vapoursynth
+    libxvbm
 "
 
 HWACCEL_AUTODETECT_LIBRARY_LIST="
@@ -3002,6 +3008,13 @@ zlib_decoder_select="inflate_wrapper"
 zlib_encoder_select="deflate_wrapper"
 zmbv_decoder_select="inflate_wrapper"
 zmbv_encoder_select="deflate_wrapper"
+h264_vcu_mpsoc_decoder_deps="libxma2api xvbm libxrm"
+hevc_vcu_mpsoc_decoder_deps="libxma2api xvbm libxrm"
+split_deps="xvbm"
+multiscale_xma_deps="libxma2api xvbm libxrm"
+h264_vcu_mpsoc_encoder_deps="libxma2api xvbm libxrm"
+hevc_vcu_mpsoc_encoder_deps="libxma2api xvbm libxrm"
+xvbm_convert_deps="libxma2api xvbm"
 
 # hardware accelerators
 crystalhd_deps="libcrystalhd_libcrystalhd_if_h"
@@ -6674,6 +6687,10 @@ enabled libx264           && require_pkg_config libx264 x264 "stdint.h x264.h" x
 enabled libx265           && require_pkg_config libx265 x265 x265.h x265_api_get &&
                              require_cpp_condition libx265 x265.h "X265_BUILD >= 70"
 enabled libxavs           && require libxavs "stdint.h xavs.h" xavs_encoder_encode "-lxavs $pthreads_extralibs $libm_extralibs"
+enabled libxma2api         && { require_pkg_config libxma2api libxma2api xma.h xma_initialize &&
+                                warn "XILINX: Adding libxma2api to ffmpeg"; }
+enabled libxrm            && require_pkg_config libxrm "libxrm >= 1.3.23" xrm.h xrmCreateContext
+enabled libxvbm           && require_pkg_config xvbm xvbm xvbm.h xvbm_buffer_refcnt_inc
 enabled libxavs2          && require_pkg_config libxavs2 "xavs2 >= 1.3.0" "stdint.h xavs2.h" xavs2_api_get
 enabled libxvid           && require libxvid xvid.h xvid_global -lxvidcore
 enabled libzimg           && require_pkg_config libzimg "zimg >= 2.7.0" zimg.h zimg_get_api_version
diff --git a/fftools/cmdutils.c b/fftools/cmdutils.c
index 18e768b386..15eb783f69 100644
--- a/fftools/cmdutils.c
+++ b/fftools/cmdutils.c
@@ -29,6 +29,7 @@
    Studio) will not omit unused inline functions and create undefined
    references to libraries that are not being built. */
 
+#include "xma.h"
 #include "config.h"
 #include "compat/va_copy.h"
 #include "libavformat/avformat.h"
@@ -61,6 +62,46 @@ AVDictionary *format_opts, *codec_opts;
 
 int hide_banner = 0;
 
+#if CONFIG_LIBXMA2API
+
+int opt_xlnx_hwdev(void *optctx, const char *opt, const char *arg)
+{
+    int ret = -1, val = -1;
+
+    val = atoi(arg);
+    if (val)
+        ret = setenv("XRM_DEVICE_ID", arg, 0);
+    else
+        ret = setenv("XRM_DEVICE_ID", "0", 0);
+
+    if (ret)
+    {
+        av_log(NULL, AV_LOG_ERROR, "Unable to set XRM_DEVICE_ID through %s option. \n", opt);
+        exit_program(1);
+    }
+    return 0;
+}
+
+static void xlnx_hwdev_init(int xlnx_num_devs, XmaXclbinParameter *xclbin_nparam )
+{
+    int i = 0;
+    for(i=0; i< xlnx_num_devs;i++)
+    {
+        av_log (NULL, AV_LOG_INFO, "------------------i=%d------------------------------------------\n\n",i);
+        av_log (NULL, AV_LOG_INFO, "   xclbin_name :  %s\n", xclbin_nparam[i].xclbin_name);
+        av_log (NULL, AV_LOG_INFO, "   device_id   :  %d \n", xclbin_nparam[i].device_id);
+        av_log (NULL, AV_LOG_INFO, "------------------------------------------------------------\n\n");
+    }
+
+    /* Initialize the Xilinx Media Accelerator */
+    if (xma_initialize(xclbin_nparam, xlnx_num_devs) != 0)
+    {
+        av_log(NULL, AV_LOG_ERROR, "ERROR: XMA Initialization failed. Program exiting\n");
+        exit_program(1);
+    }
+}
+#endif
+
 void uninit_opts(void)
 {
     av_dict_free(&swr_opts);
@@ -690,6 +731,12 @@ int split_commandline(OptionParseContext *octx, int argc, char *argv[],
 {
     int optindex = 1;
     int dashdash = -2;
+#if CONFIG_LIBXMA2API
+    int dev_id = 0, xlnx_num_devs = 0;
+    bool dev_list[MAX_XLNX_DEVS];
+    XmaXclbinParameter xclbin_nparam[MAX_XLNX_DEVS];
+    memset(dev_list, false, MAX_XLNX_DEVS*sizeof(bool));
+#endif
 
     /* perform system-dependent conversions for arguments list */
     prepare_app_arguments(&argc, &argv);
@@ -702,6 +749,47 @@ int split_commandline(OptionParseContext *octx, int argc, char *argv[],
         const OptionDef *po;
         int ret;
 
+#if CONFIG_LIBXMA2API
+        if (strcmp(opt, "-filter_complex") == 0)
+        {
+           char* ptr_sc;
+           ptr_sc = strstr(argv[optindex],"lxlnx_hwdev=");
+           if (ptr_sc != NULL)
+           {
+              sscanf(ptr_sc, "lxlnx_hwdev=%d", &dev_id);
+              if ((dev_id >= 0) && (dev_list[dev_id] == false))
+              {
+                 xclbin_nparam[xlnx_num_devs].device_id = dev_id;
+                 xclbin_nparam[xlnx_num_devs].xclbin_name = XLNX_XCLBIN_PATH;
+                 dev_list[dev_id] = true;
+                 xlnx_num_devs++;
+              }
+           }
+        }
+        else if((strcmp(opt,"-lxlnx_hwdev") == 0) || (strcmp(opt,"-xlnx_hwdev") == 0))
+        {
+           if(optindex >= argc)  {
+                av_log(NULL, AV_LOG_ERROR, "No device ID suppled to Xilinx device command line options.\n");
+                return AVERROR(EINVAL);
+           }
+           dev_id = atoi(argv[optindex]);
+           if ((dev_id >= 0) && (dev_id < MAX_XLNX_DEVS)) {
+              if (dev_list[dev_id] == false)
+              {
+                  xclbin_nparam[xlnx_num_devs].device_id = dev_id;
+                  xclbin_nparam[xlnx_num_devs].xclbin_name = XLNX_XCLBIN_PATH;
+                  dev_list[dev_id] = true;
+                  xlnx_num_devs++;
+              }
+           }
+           else
+              {
+                 av_log(NULL, AV_LOG_ERROR, "Invalid device ID %d suppled to Xilinx device command line options.\n", dev_id);
+                 return AVERROR(EINVAL);                                                \
+           }
+        }
+#endif
+
         av_log(NULL, AV_LOG_DEBUG, "Reading option '%s' ...", opt);
 
         if (opt[0] == '-' && opt[1] == '-' && !opt[2]) {
@@ -781,6 +869,30 @@ do {                                                                           \
         return AVERROR_OPTION_NOT_FOUND;
     }
 
+#if CONFIG_LIBXMA2API
+    if (xlnx_num_devs == 0)
+    {
+       if ((!getenv("XRM_DEVICE_ID")) && (!getenv("XRM_RESERVE_ID")))//TODO:check if this additional condition is needed
+       {
+         setenv("XRM_DEVICE_ID", "0" , 0); //set defualt device to 0
+         xclbin_nparam[xlnx_num_devs].device_id = dev_id;
+         xclbin_nparam[xlnx_num_devs].xclbin_name = XLNX_XCLBIN_PATH;
+         xlnx_num_devs++;
+         av_log(NULL, AV_LOG_WARNING, "No device set hence falling to default device 0\n");
+       }
+    }
+    else if (xlnx_num_devs > MAX_XLNX_DEVICES_PER_CMD)
+    {
+        av_log(NULL, AV_LOG_ERROR, "ERROR: ffmpeg command is requesting for  %d devices which is more than supported %d devices.\n", xlnx_num_devs, MAX_XLNX_DEVICES_PER_CMD);
+        return AVERROR(EINVAL);
+     }
+
+    if (!getenv("XRM_RESERVE_ID"))
+    {
+       xlnx_hwdev_init(xlnx_num_devs, xclbin_nparam );
+    }
+#endif
+
     if (octx->cur_group.nb_opts || codec_opts || format_opts)
         av_log(NULL, AV_LOG_WARNING, "Trailing option(s) found in the "
                "command: may be ignored.\n");
diff --git a/fftools/cmdutils.h b/fftools/cmdutils.h
index d87e162ccd..b9d6eb1a25 100644
--- a/fftools/cmdutils.h
+++ b/fftools/cmdutils.h
@@ -34,6 +34,12 @@
 #undef main /* We don't want SDL to override our main() */
 #endif
 
+
+#if CONFIG_LIBXMA2API
+#define MAX_XLNX_DEVS 128
+#define XLNX_XCLBIN_PATH "/opt/xilinx/xcdr/xclbins/transcode.xclbin"
+#define MAX_XLNX_DEVICES_PER_CMD 2
+#endif
 /**
  * program name, defined by the program for show_version().
  */
@@ -82,6 +88,10 @@ void log_callback_help(void* ptr, int level, const char* fmt, va_list vl);
  */
 int opt_default(void *optctx, const char *opt, const char *arg);
 
+#if CONFIG_LIBXMA2API
+int opt_xlnx_hwdev(void *optctx, const char *opt, const char *arg);
+#endif
+
 /**
  * Limit the execution time.
  */
diff --git a/fftools/ffmpeg.c b/fftools/ffmpeg.c
index e7384f052a..7ab6630697 100644
--- a/fftools/ffmpeg.c
+++ b/fftools/ffmpeg.c
@@ -40,6 +40,12 @@
 #include <unistd.h>
 #endif
 
+#include <xma.h>
+#include <xrm.h>
+#include <uuid/uuid.h>
+#include <experimental/xrt_xclbin.h>
+#include <errno.h>
+
 #include "libavformat/avformat.h"
 #include "libavdevice/avdevice.h"
 #include "libswresample/swresample.h"
@@ -100,6 +106,8 @@
 #include <conio.h>
 #endif
 
+#include <syslog.h>
+
 #include <time.h>
 
 #include "ffmpeg.h"
@@ -107,6 +115,8 @@
 
 #include "libavutil/avassert.h"
 
+#define xrm_str_size (64)
+
 const char program_name[] = "ffmpeg";
 const int program_birth_year = 2000;
 
@@ -2464,6 +2474,11 @@ static int process_input_packet(InputStream *ist, const AVPacket *pkt, int no_eo
             if (decode_failed) {
                 av_log(NULL, AV_LOG_ERROR, "Error while decoding stream #%d:%d: %s\n",
                        ist->file_index, ist->st->index, av_err2str(ret));
+                if(strstr(ist->dec_ctx->codec->name, "mpsoc_vcu")) {
+                    /* VCU can throw error at data send stage due to insufficient processing power.
+                     * We dont want to retry, but call cleanup callback and exit */
+                    exit_program(1);
+                }
             } else {
                 av_log(NULL, AV_LOG_FATAL, "Error while processing the decoded "
                        "data for stream #%d:%d\n", ist->file_index, ist->st->index);
@@ -3040,6 +3055,15 @@ static int init_output_stream_encode(OutputStream *ost, AVFrame *frame)
             enc_ctx->bits_per_raw_sample = FFMIN(dec_ctx->bits_per_raw_sample,
                                                  av_pix_fmt_desc_get(enc_ctx->pix_fmt)->comp[0].depth);
 
+#if CONFIG_LIBXMA2API
+        if (dec_ctx) {
+            enc_ctx->bits_per_raw_sample = av_pix_fmt_desc_get(dec_ctx->pix_fmt)->comp[0].depth;
+        }
+        else {
+            enc_ctx->bits_per_raw_sample = ost->bits_per_raw_sample;
+        }
+#endif
+
         if (frame) {
             enc_ctx->color_range            = frame->color_range;
             enc_ctx->color_primaries        = frame->color_primaries;
@@ -4283,6 +4307,9 @@ static int transcode_step(void)
          * of the peeked AVFrame as-is), we could get rid of this additional
          * early encoder initialization.
          */
+        #if CONFIG_LIBXVBM
+        init_output_stream_wrapper(ost, NULL, 1);
+        #endif
         if (av_buffersink_get_type(ost->filter->filter) == AVMEDIA_TYPE_AUDIO)
             init_output_stream_wrapper(ost, NULL, 1);
 
@@ -4515,9 +4542,17 @@ static int64_t getmaxrss(void)
 
 int main(int argc, char **argv)
 {
-    int i, ret;
+    int i=0, ret, xrm_reserve_id;
     BenchmarkTimeStamps ti;
 
+    struct timespec latency;
+    long long int time_taken;
+    clock_gettime (CLOCK_REALTIME, &latency);
+    time_taken = (latency.tv_sec * 1e3) + (latency.tv_nsec / 1e6);
+    openlog ("FFmpeg", LOG_PID, LOG_USER);
+    syslog(LOG_DEBUG, "FFmpeg start : %lld\n", time_taken);
+
+
     init_dynload();
 
     register_exit(ffmpeg_cleanup);
@@ -4534,6 +4569,119 @@ int main(int argc, char **argv)
 
     show_banner(argc, argv, options);
 
+#if CONFIG_LIBXMA2API
+//////////////////////////// XRM SETUP////////////////////////
+    av_log (NULL, AV_LOG_INFO, "\n<<<<<<<==  FFmpeg xrm ===>>>>>>>>\n");
+    xrmContext *xrm_ctx = (xrmContext *)xrmCreateContext(XRM_API_VERSION_1);
+    if (xrm_ctx == NULL)
+    {
+       av_log(NULL, AV_LOG_ERROR, "create local XRM context failed\n");
+       exit_program(1);
+    }
+
+    int dev_id = 0, xlnx_num_devs = 0;
+    bool dev_list[MAX_XLNX_DEVS];
+    XmaXclbinParameter xclbin_nparam[MAX_XLNX_DEVS];
+    memset(dev_list, false, MAX_XLNX_DEVS*sizeof(bool));
+
+    if (getenv("XRM_RESERVE_ID"))
+    {
+       //Query the XRM reserved device resource to use
+       xrmCuPoolResourceV2 query_transcode_cu_pool_res;
+       memset(&query_transcode_cu_pool_res, 0, sizeof(query_transcode_cu_pool_res));
+       char* endptr;
+       errno=0;
+       xrm_reserve_id = strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);
+       //check for strtol errors
+       if (errno != 0)
+       {
+           perror("strtol");
+           av_log(NULL, AV_LOG_ERROR, "xrmReservation: fail to use XRM_RESERVE_ID\n");
+           exit_program(1);
+       }
+
+       xrmReservationQueryInfoV2 reserveQueryInfo;
+       memset(&reserveQueryInfo, 0, sizeof(xrmReservationQueryInfoV2));
+       reserveQueryInfo.poolId = xrm_reserve_id;
+
+       ret = xrmReservationQueryV2(xrm_ctx, &reserveQueryInfo, &query_transcode_cu_pool_res);
+       if (ret != 0)
+       {
+          av_log(NULL, AV_LOG_ERROR, "xrmReservationQueryV2: fail to query allocated cu list\n");
+          exit_program(1);
+       }
+       else if (query_transcode_cu_pool_res.cuNum > 0)
+       {
+            for (i = 0; i < query_transcode_cu_pool_res.cuNum; i++)
+            {
+                dev_id =query_transcode_cu_pool_res.cuResources[i].deviceId;
+                if (dev_id < MAX_XLNX_DEVS) {
+                    if (dev_list[dev_id] == false) {
+                       xclbin_nparam[xlnx_num_devs].device_id = dev_id;
+                       xclbin_nparam[xlnx_num_devs].xclbin_name = XLNX_XCLBIN_PATH;
+                       dev_list[dev_id] = true;
+                       xlnx_num_devs++;
+                    }
+                }
+                else
+                {
+                    av_log(NULL, AV_LOG_ERROR, "Invalid device ID %d suppled to Xilinx device command line options.\n", dev_id);
+                    return AVERROR(EINVAL);                                                \
+                }
+
+#if 0
+                printf("--------------\nquery the reserved cu pool: cu %d\n", i);
+                printf("   xclbinFileName is:  %s\n", query_transcode_cu_pool_res.cuResources[i].xclbinFileName);
+                printf("   kernelPluginFileName is:  %s\n", query_transcode_cu_pool_res.cuResources[i].kernelPluginFileName);
+                printf("   kernelName is:  %s\n", query_transcode_cu_pool_res.cuResources[i].kernelName);
+                printf("   kernelAlias is:  %s\n", query_transcode_cu_pool_res.cuResources[i].kernelAlias);
+                printf("   instanceName is:  %s\n", query_transcode_cu_pool_res.cuResources[i].instanceName);
+                printf("   cuName is:  %s\n", query_transcode_cu_pool_res.cuResources[i].cuName);
+                printf("   deviceId is:  %d\n", query_transcode_cu_pool_res.cuResources[i].deviceId);
+                printf("   cuId is:  %d\n", query_transcode_cu_pool_res.cuResources[i].cuId);
+                printf("   cuType is:  %d\n", query_transcode_cu_pool_res.cuResources[i].cuType);
+                printf("   baseAddr is:  0x%lx\n", query_transcode_cu_pool_res.cuResources[i].baseAddr);
+                printf("   membankId is:  %d\n", query_transcode_cu_pool_res.cuResources[i].membankId);
+                printf("   membankType is:  %d\n", query_transcode_cu_pool_res.cuResources[i].membankType);
+                printf("   membankSize is:  0x%lx\n", query_transcode_cu_pool_res.cuResources[i].membankSize);
+                printf("   membankBaseAddr is:  0x%lx\n", query_transcode_cu_pool_res.cuResources[i].membankBaseAddr);
+                printf("   poolId is:  %lu\n", query_transcode_cu_pool_res.cuResources[i].poolId);
+#endif
+            }
+
+            if (xlnx_num_devs > MAX_XLNX_DEVICES_PER_CMD)
+            {
+                av_log(NULL, AV_LOG_ERROR, "ERROR: ffmpeg command is requesting for  %d devices which is more than supported %d devices.\n", xlnx_num_devs, MAX_XLNX_DEVICES_PER_CMD);
+                return AVERROR(EINVAL);                                                \
+            }
+
+            /* Initialize the Xilinx Media Accelerator */
+            for (int nd=0; nd<xlnx_num_devs; nd++)
+                printf("xclbin[%d] dev_id=%d\n", nd,xclbin_nparam[nd].device_id);
+
+            if (xma_initialize(xclbin_nparam, xlnx_num_devs) != 0)
+            {
+               av_log(NULL, AV_LOG_ERROR, "XMA Initialization failed\n");
+               exit_program(1);
+            }
+       }
+       else
+       {
+            //Given XRM_RESERVE_ID is not correct, falling back to XRM_DEVICE_ID flow
+            unsetenv("XRM_RESERVE_ID");
+            av_log(NULL, AV_LOG_ERROR, "Wrong XRM reserve ID\n");
+            exit_program(1);
+       }
+    }
+
+    //Destroy XRM context created for querry
+    if (xrmDestroyContext(xrm_ctx) != XRM_SUCCESS)
+       av_log(NULL, AV_LOG_ERROR, "XRM : Query destroy context failed\n");
+
+
+#endif
+
+
     /* parse options and open all input/output files */
     ret = ffmpeg_parse_options(argc, argv);
     if (ret < 0)
diff --git a/fftools/ffmpeg.h b/fftools/ffmpeg.h
index 391a35cf50..505d8f1621 100644
--- a/fftools/ffmpeg.h
+++ b/fftools/ffmpeg.h
@@ -114,6 +114,9 @@ typedef struct OptionsContext {
     /* input options */
     int64_t input_ts_offset;
     int loop;
+#if CONFIG_LIBXMA2API
+    int xlnx_hwdev; //Xilinx hw device
+#endif
     int rate_emu;
     float readrate;
     int accurate_seek;
diff --git a/fftools/ffmpeg_opt.c b/fftools/ffmpeg_opt.c
index 0969b12e7f..7b9eb88b7c 100644
--- a/fftools/ffmpeg_opt.c
+++ b/fftools/ffmpeg_opt.c
@@ -3654,6 +3654,10 @@ const OptionDef options[] = {
         "overwrite output files" },
     { "n",              OPT_BOOL,                                    {              &no_file_overwrite },
         "never overwrite output files" },
+#if CONFIG_LIBXMA2API
+    { "xlnx_hwdev",     HAS_ARG,                                     { .func_arg  = opt_xlnx_hwdev },
+       "set Xilinx device id to be used"  },
+#endif
     { "ignore_unknown", OPT_BOOL,                                    {              &ignore_unknown_streams },
         "Ignore unknown stream types" },
     { "copy_unknown",   OPT_BOOL | OPT_EXPERT,                       {              &copy_unknown_streams },
diff --git a/libavcodec/Makefile b/libavcodec/Makefile
index 457ec58377..6e13c77371 100644
--- a/libavcodec/Makefile
+++ b/libavcodec/Makefile
@@ -26,6 +26,7 @@ HEADERS = ac3_parser.h                                                  \
           videotoolbox.h                                                \
           vorbis_parser.h                                               \
           xvmc.h                                                        \
+          xlnx_lookahead.h                                              \
 
 OBJS = ac3_parser.o                                                     \
        adts_parser.o                                                    \
@@ -397,6 +398,10 @@ OBJS-$(CONFIG_H264_QSV_ENCODER)        += qsvenc_h264.o
 OBJS-$(CONFIG_H264_RKMPP_DECODER)      += rkmppdec.o
 OBJS-$(CONFIG_H264_VAAPI_ENCODER)      += vaapi_encode_h264.o h264_levels.o
 OBJS-$(CONFIG_H264_VIDEOTOOLBOX_ENCODER) += videotoolboxenc.o
+OBJS-$(CONFIG_HEVC_VCU_MPSOC_ENCODER)  += xlnx_lookahead.o mpsoc_vcu_enc.o
+OBJS-$(CONFIG_H264_VCU_MPSOC_DECODER)  += mpsoc_vcu_dec.o
+OBJS-$(CONFIG_HEVC_VCU_MPSOC_DECODER)  += mpsoc_vcu_dec.o
+OBJS-$(CONFIG_H264_VCU_MPSOC_ENCODER)  += xlnx_lookahead.o mpsoc_vcu_enc.o
 OBJS-$(CONFIG_H264_V4L2M2M_DECODER)    += v4l2_m2m_dec.o
 OBJS-$(CONFIG_H264_V4L2M2M_ENCODER)    += v4l2_m2m_enc.o
 OBJS-$(CONFIG_HAP_DECODER)             += hapdec.o hap.o
@@ -1169,7 +1174,6 @@ OBJS-$(CONFIG_VP8_PARSER)              += vp8_parser.o
 OBJS-$(CONFIG_VP9_PARSER)              += vp9_parser.o
 OBJS-$(CONFIG_WEBP_PARSER)             += webp_parser.o
 OBJS-$(CONFIG_XBM_PARSER)              += xbm_parser.o
-OBJS-$(CONFIG_XMA_PARSER)              += xma_parser.o
 
 # bitstream filters
 OBJS-$(CONFIG_AAC_ADTSTOASC_BSF)          += aac_adtstoasc_bsf.o
diff --git a/libavcodec/allcodecs.c b/libavcodec/allcodecs.c
index bdfc2f6f45..93ae2f9939 100644
--- a/libavcodec/allcodecs.c
+++ b/libavcodec/allcodecs.c
@@ -862,6 +862,10 @@ extern const FFCodec ff_vp9_mediacodec_decoder;
 extern const FFCodec ff_vp9_qsv_decoder;
 extern const FFCodec ff_vp9_vaapi_encoder;
 extern const FFCodec ff_vp9_qsv_encoder;
+extern const FFCodec ff_h264_vcu_mpsoc_decoder;
+extern const FFCodec ff_h264_vcu_mpsoc_encoder;
+extern const FFCodec ff_hevc_vcu_mpsoc_decoder;
+extern const FFCodec ff_hevc_vcu_mpsoc_encoder;
 
 // The iterate API is not usable with ossfuzz due to the excessive size of binaries created
 #if CONFIG_OSSFUZZ
diff --git a/libavcodec/codec_id.h b/libavcodec/codec_id.h
index 81fb316cff..adad143ee2 100644
--- a/libavcodec/codec_id.h
+++ b/libavcodec/codec_id.h
@@ -277,6 +277,7 @@ enum AVCodecID {
     AV_CODEC_ID_CLEARVIDEO,
     AV_CODEC_ID_XPM,
     AV_CODEC_ID_AV1,
+    AV_CODEC_ID_XLNX_COPY,
     AV_CODEC_ID_BITPACKED,
     AV_CODEC_ID_MSCC,
     AV_CODEC_ID_SRGC,
diff --git a/libavcodec/encode.c b/libavcodec/encode.c
index 1f39ab1a2f..cd9beb2d0e 100644
--- a/libavcodec/encode.c
+++ b/libavcodec/encode.c
@@ -434,9 +434,11 @@ static int encode_preinit_video(AVCodecContext *avctx)
 
     if (    avctx->bits_per_raw_sample < 0
         || (avctx->bits_per_raw_sample > 8 && pixdesc->comp[0].depth <= 8)) {
+#if !CONFIG_LIBXMA2API
         av_log(avctx, AV_LOG_WARNING, "Specified bit depth %d not possible with the specified pixel formats depth %d\n",
             avctx->bits_per_raw_sample, pixdesc->comp[0].depth);
         avctx->bits_per_raw_sample = pixdesc->comp[0].depth;
+#endif
     }
     if (avctx->width <= 0 || avctx->height <= 0) {
         av_log(avctx, AV_LOG_ERROR, "dimensions not set\n");
diff --git a/libavcodec/h264_parse.h b/libavcodec/h264_parse.h
index 4ee863df66..945d9499a7 100644
--- a/libavcodec/h264_parse.h
+++ b/libavcodec/h264_parse.h
@@ -1,4 +1,6 @@
 /*
+ * Modifications Copyright(C) [2024] Advanced Micro Devices, Inc.
+ *
  * This file is part of FFmpeg.
  *
  * FFmpeg is free software; you can redistribute it and/or
@@ -32,6 +34,10 @@
 
 #include "get_bits.h"
 #include "h264_ps.h"
+#include "internal.h"
+#include "parser.h"
+#include "h264dsp.h"
+#include "h264_sei.h"
 
 #define MB_TYPE_REF0       MB_TYPE_ACPRED // dirty but it fits in 16 bit
 #define MB_TYPE_8x8DCT     0x01000000
@@ -92,6 +98,23 @@ typedef struct H264POCContext {
     int prev_frame_num;         ///< frame_num of the last pic for POC type 1/2
 } H264POCContext;
 
+typedef struct H264ParseContext {
+    ParseContext pc;
+    H264ParamSets ps;
+    H264DSPContext h264dsp;
+    H264POCContext poc;
+    H264SEIContext sei;
+    int is_avc;
+    int nal_length_size;
+    int got_first;
+    int picture_structure;
+    uint8_t parse_history[6];
+    int parse_history_count;
+    int parse_last_mb;
+    int64_t reference_dts;
+    int last_frame_num, last_picture_structure;
+} H264ParseContext;
+
 int ff_h264_pred_weight_table(GetBitContext *gb, const SPS *sps,
                               const int *ref_count, int slice_type_nos,
                               H264PredWeightTable *pwt,
@@ -133,4 +156,13 @@ static av_always_inline uint32_t pack16to32(unsigned a, unsigned b)
 #endif
 }
 
+static int find_start_code(const uint8_t *buf, int buf_size,
+                                  int buf_index, int next_avc)
+{
+    uint32_t state = -1;
+
+    buf_index = avpriv_find_start_code(buf + buf_index, buf + next_avc + 1, &state) - buf - 1;
+
+    return FFMIN(buf_index, buf_size);
+}
 #endif /* AVCODEC_H264_PARSE_H */
diff --git a/libavcodec/h264_parser.c b/libavcodec/h264_parser.c
index 0a2451a153..97040b5bec 100644
--- a/libavcodec/h264_parser.c
+++ b/libavcodec/h264_parser.c
@@ -1,5 +1,7 @@
 /*
  * H.26L/H.264/AVC/JVT/14496-10/... parser
+ * Modifications Copyright(C) [2024] Advanced Micro Devices, Inc.
+ *
  * Copyright (c) 2003 Michael Niedermayer <michaelni@gmx.at>
  *
  * This file is part of FFmpeg.
@@ -49,32 +51,32 @@
 #include "parser.h"
 #include "startcode.h"
 
-typedef struct H264ParseContext {
-    ParseContext pc;
-    H264ParamSets ps;
-    H264DSPContext h264dsp;
-    H264POCContext poc;
-    H264SEIContext sei;
-    int is_avc;
-    int nal_length_size;
-    int got_first;
-    int picture_structure;
-    uint8_t parse_history[6];
-    int parse_history_count;
-    int parse_last_mb;
-    int64_t reference_dts;
-    int last_frame_num, last_picture_structure;
-} H264ParseContext;
-
-static int find_start_code(const uint8_t *buf, int buf_size,
-                                  int buf_index, int next_avc)
-{
-    uint32_t state = -1;
-
-    buf_index = avpriv_find_start_code(buf + buf_index, buf + next_avc + 1, &state) - buf - 1;
-
-    return FFMIN(buf_index, buf_size);
-}
+// typedef struct H264ParseContext {
+//     ParseContext pc;
+//     H264ParamSets ps;
+//     H264DSPContext h264dsp;
+//     H264POCContext poc;
+//     H264SEIContext sei;
+//     int is_avc;
+//     int nal_length_size;
+//     int got_first;
+//     int picture_structure;
+//     uint8_t parse_history[6];
+//     int parse_history_count;
+//     int parse_last_mb;
+//     int64_t reference_dts;
+//     int last_frame_num, last_picture_structure;
+// } H264ParseContext;
+
+// static int find_start_code(const uint8_t *buf, int buf_size,
+//                                   int buf_index, int next_avc)
+// {
+//     uint32_t state = -1;
+
+//     buf_index = avpriv_find_start_code(buf + buf_index, buf + next_avc + 1, &state) - buf - 1;
+
+//     return FFMIN(buf_index, buf_size);
+// }
 
 static int h264_find_frame_end(H264ParseContext *p, const uint8_t *buf,
                                int buf_size, void *logctx)
diff --git a/libavcodec/internal.h b/libavcodec/internal.h
index 17e1de8127..0082dece30 100644
--- a/libavcodec/internal.h
+++ b/libavcodec/internal.h
@@ -1,4 +1,6 @@
 /*
+ * Modifications Copyright(C) [2024] Advanced Micro Devices, Inc.
+ *
  * This file is part of FFmpeg.
  *
  * FFmpeg is free software; you can redistribute it and/or
@@ -218,6 +220,10 @@ int avpriv_h264_has_num_reorder_frames(AVCodecContext *avctx);
 
 int avpriv_codec_get_cap_skip_frame_fill_param(const AVCodec *codec);
 
+const uint8_t *avpriv_find_start_code(const uint8_t *av_restrict p,
+                                      const uint8_t *end,
+                                      uint32_t *av_restrict state);
+
 /**
  * Check that the provided frame dimensions are valid and set them on the codec
  * context.
diff --git a/libavcodec/mpsoc_vcu_dec.c b/libavcodec/mpsoc_vcu_dec.c
new file mode 100644
index 0000000000..170bce5fb0
--- /dev/null
+++ b/libavcodec/mpsoc_vcu_dec.c
@@ -0,0 +1,1194 @@
+/*
+ * Modifications Copyright (C) 2024 Advanced Micro Devices, Inc.
+ * Copyright (C) 2018 Xilinx Inc.
+ * All rights reserved.
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/internal.h"
+#include "libavutil/common.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/timestamp.h"
+#include "libavutil/fifo.h"
+#include "libavcodec/h264dec.h"
+#include "libavcodec/h264_parse.h"
+#include "libavcodec/parser.h"
+#include "libavcodec/golomb.h"
+#include "libavcodec/h264data.h"
+#include "libavcodec/hevc_parse.h"
+#include "libavcodec/hevcdec.h"
+#include "libavcodec/h264.h"
+#include "libavcodec/hevc.h"
+#include "libavcodec/mpsoc_vcu_hdr10.h"
+#include "avcodec.h"
+#include "internal.h"
+#include "codec_internal.h"
+#include <unistd.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <assert.h>
+#include <memory.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/mman.h>
+#include <fcntl.h>
+#include <xma.h>
+#include <xrm.h>
+#include <dlfcn.h>
+#include <errno.h>
+
+#include "../xmaPropsTOjson.h"
+
+/* Below are the initial sizes. These sizes will not be the max that can be seen
+ * at runtime, can grow but not indefinetely. */
+#define PKT_FIFO_SIZE  20
+#define PKT_FIFO_WATERMARK_SIZE 10
+#define DTS_FIFO_SIZE  32
+#define DTS_FIFO_INC_SIZE 16
+
+#define MAX_DEC_PARAMS 11
+#define XRM_PRECISION_1000000_BIT_MASK(load) ((load << 8))
+
+
+typedef struct mpsoc_vcu_dec_ctx {
+    const AVClass     *class;
+    XmaDecoderSession *dec_session;
+    char               dec_params_name[MAX_DEC_PARAMS][100];
+    XmaParameter       dec_params[MAX_DEC_PARAMS];
+    xrmContext        *xrm_ctx;
+    xrmCuListResourceV2 decode_cu_list_res;
+    bool               decode_res_inuse;
+    XmaDataBuffer      buffer;
+    XmaFrame           xma_frame;
+    XmaFrameProperties props;
+    AVCodecContext    *avctx;
+    bool               flush_sent;
+    int  lxlnx_hwdev;
+    uint32_t           bitdepth;
+    uint32_t           codec_type;
+    uint32_t           low_latency;
+    uint32_t           entropy_buffers_count;
+    uint32_t           latency_logging;
+    uint32_t           splitbuff_mode;
+    uint32_t           idr_count;
+    int64_t            genpts;
+    AVRational         pts_q;
+    uint32_t           chroma_mode;
+    AVFifoBuffer      *dts_fifo;
+} mpsoc_vcu_dec_ctx;
+
+/*----------------------------------------------------------------------------*/
+// typedef struct H264ParseContext {
+//     ParseContext pc;
+//     H264ParamSets ps;
+//     H264DSPContext h264dsp;
+//     H264POCContext poc;
+//     H264SEIContext sei;
+//     int is_avc;
+//     int nal_length_size;
+//     int got_first;
+//     int picture_structure;
+//     uint8_t parse_history[6];
+//     int parse_history_count;
+//     int parse_last_mb;
+//     int64_t reference_dts;
+//     int last_frame_num, last_picture_structure;
+// } H264ParseContext;
+
+//Derived from parse_nal_units(), and removing unneeded parts
+static inline int mpsoc_decode_parse_nal_units_for_slice_type(AVCodecParserContext *s,
+                                  AVCodecContext *avctx,
+                                  const uint8_t * const buf, int buf_size, unsigned int *slice_type)
+{
+    H264ParseContext *p = s->priv_data;
+    H2645RBSP rbsp = { NULL };
+    H2645NAL nal = { NULL };
+    int buf_index, next_avc;
+    unsigned int pps_id;
+    int state = -1, got_reset = 0;
+    int field_poc[2];
+    int ret;
+
+    if (!buf_size)
+        return 0;
+    av_fast_padded_malloc(&rbsp.rbsp_buffer, &rbsp.rbsp_buffer_alloc_size, buf_size);
+    if (!rbsp.rbsp_buffer)
+        return AVERROR(ENOMEM);
+    buf_index     = 0;
+    next_avc      = p->is_avc ? 0 : buf_size;
+    for (;;) {
+        int src_length, consumed, nalsize = 0;
+        if (buf_index >= next_avc) {
+            nalsize = get_nalsize(p->nal_length_size, buf, buf_size, &buf_index, avctx);
+            if (nalsize < 0)
+                break;
+            next_avc = buf_index + nalsize;
+        } else {
+            buf_index = find_start_code(buf, buf_size, buf_index, next_avc);
+            if (buf_index >= buf_size)
+                break;
+            if (buf_index >= next_avc)
+                continue;
+        }
+        src_length = next_avc - buf_index;
+        state = buf[buf_index];
+        if(state & 0x1f == H264_NAL_SLICE){
+            // Do not walk the whole buffer just to decode slice header
+            if ((state & 0x1f) == H264_NAL_IDR_SLICE || ((state >> 5) & 0x3) == 0) {
+                /* IDR or disposable slice
+                 * No need to decode many bytes because MMCOs shall not be present. */
+                if (src_length > 60)
+                    src_length = 60;
+            } else {
+                /* To decode up to MMCOs */
+                if (src_length > 1000)
+                    src_length = 1000;
+            }
+        }
+        consumed = ff_h2645_extract_rbsp(buf + buf_index, src_length, &rbsp, &nal, 1);
+        if (consumed < 0)
+            break;
+        buf_index += consumed;
+        ret = init_get_bits8(&nal.gb, nal.data, nal.size);
+        if (ret < 0)
+            goto fail;
+        get_bits1(&nal.gb);
+        nal.ref_idc = get_bits(&nal.gb, 2);
+        nal.type    = get_bits(&nal.gb, 5);
+        if (nal.type == H264_NAL_SLICE){
+            get_ue_golomb_long(&nal.gb);  // skip first_mb_in_slice
+            *slice_type   = get_ue_golomb_31(&nal.gb);
+            av_freep(&rbsp.rbsp_buffer);
+            return 0; /* no need to evaluate the rest */
+        }
+    }
+    av_log(avctx, AV_LOG_ERROR, "missing picture in access unit with size %d\n", buf_size);
+fail:
+    av_freep(&rbsp.rbsp_buffer);
+    return -1;
+}
+
+static bool mpsoc_decode_is_h2645_I_frame (AVCodecContext *avctx, AVPacket *pkt)
+{
+    AVCodecParserContext *s = av_parser_init(avctx->codec_id); // Initialize AVCodecParserContext object
+    int size = pkt->size;
+    unsigned char* data = pkt->data;
+    unsigned int slice_type;
+    mpsoc_decode_parse_nal_units_for_slice_type(s, avctx, data, size, &slice_type);
+    av_parser_close(s);
+    if (ff_h264_golomb_to_pict_type[slice_type % 5] == AV_PICTURE_TYPE_I)
+            return true;
+    return false;
+}
+
+/*----------------------------------------------------------------------------*/
+
+enum mpsoc_vcu_dec_supported_bitdepth {
+	MPSOC_VCU_BITDEPTH_8BIT = 8,
+	MPSOC_VCU_BITDEPTH_10BIT = 10,
+};
+
+static bool is_bitdepth_supported(const uint32_t bitdepth)
+{
+	switch(bitdepth) {
+	case MPSOC_VCU_BITDEPTH_8BIT :
+	case MPSOC_VCU_BITDEPTH_10BIT :
+		/* Supported bitdepth */
+		return true;
+	default:
+		/* Not Supported */
+		return false;
+	}
+}
+
+#define VD AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_DECODING_PARAM
+#define OFFSET(x) offsetof(mpsoc_vcu_dec_ctx, x)
+
+static int vcu_dec_get_out_buffer(struct AVCodecContext *s, AVFrame *frame, int flags);
+#define FLAGS (AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_FILTERING_PARAM)
+
+static const AVOption options[] = {
+    { "lxlnx_hwdev", "set local device ID for decoder if it needs to be different from global xlnx_hwdev", OFFSET(lxlnx_hwdev), AV_OPT_TYPE_INT, {.i64 = -1}, -1, INT_MAX, VD, "lxlnx_hwdev"},
+    { "low_latency", "Should low latency decoding be used", OFFSET(low_latency), AV_OPT_TYPE_INT, { }, 0, 1, VD, "low_latency" },
+    { "entropy_buffers_count", "Specify number of internal entropy buffers", OFFSET(entropy_buffers_count), AV_OPT_TYPE_INT , { .i64 = 2 }, 2, 10, VD, "entropy_buffers_count" },
+    { "latency_logging", "Log latency information to syslog", OFFSET(latency_logging), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VD, "latency_logging" },
+    { "splitbuff_mode", "configure decoder in split/unsplit input buffer mode", OFFSET(splitbuff_mode), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VD, "splitbuff_mode" },
+    { NULL },
+};
+
+static int mpsoc_report_error(mpsoc_vcu_dec_ctx *ctx, const char *err_str, int32_t err_type)
+{
+    if (ctx)
+    {
+        av_log(ctx, AV_LOG_ERROR, "decoder error: %s : ffmpeg pid %d on device index =  %d cu index = %d\n",
+                   err_str, getpid(), ctx->decode_cu_list_res.cuResources[0].deviceId,
+                   ctx->decode_cu_list_res.cuResources[1].cuId);
+    }
+
+    return err_type;
+}
+
+static bool mpsoc_decode_is_h264_syncpoint (AVCodecContext *avctx, AVPacket *pkt)
+{
+    unsigned char* pt = pkt->data;
+    unsigned char* end = pkt->data + pkt->size - 3;
+    while (pt < end)
+    {
+        //IDR
+        if ((pt[0] == 0x00) && (pt[1] == 0x00) && (pt[2] == 0x01) && ((pt[3] & 0x1F) == H264_NAL_IDR_SLICE))
+            return true;
+        //I frame
+        else if ((pt[0] == 0x00) && (pt[1] == 0x00) && (pt[2] == 0x01) && ((pt[3] & 0x1F) == H264_NAL_SLICE)){
+            if (mpsoc_decode_is_h2645_I_frame(avctx, pkt))
+                 return true;
+        }
+        pt++;
+    }
+    return false;
+}
+
+static bool mpsoc_decode_is_hevc_idr (AVPacket *pkt)
+{
+    unsigned char* pt = pkt->data;
+    unsigned char* end = pkt->data + pkt->size - 3;
+    while (pt < end)
+    {
+        if ((pt[0] == 0x00) && (pt[1] == 0x00) && (pt[2] == 0x01))
+        {
+            unsigned char naluType = (pt[3] & 0x7E) >> 1;
+            if (naluType == HEVC_NAL_IDR_W_RADL || naluType == HEVC_NAL_IDR_N_LP || naluType == HEVC_NAL_CRA_NUT)
+                return true;
+        }
+        pt++;
+    }
+    return false;
+}
+
+static void  mpsoc_vcu_flush(AVCodecContext *avctx)
+{
+    mpsoc_vcu_dec_ctx *ctx = avctx->priv_data;
+
+    /* reinitialize as we loop (-stream_loop) without going through init */
+    ctx->flush_sent = false;
+}
+
+static av_cold int mpsoc_vcu_decode_close (AVCodecContext *avctx)
+{
+    mpsoc_vcu_dec_ctx *ctx = avctx->priv_data;
+
+    xma_dec_session_destroy(ctx->dec_session);
+
+    //XRM decoder list/CU de-allocation
+    if (ctx->decode_res_inuse)
+    {
+        if (!(xrmCuListReleaseV2(ctx->xrm_ctx, &ctx->decode_cu_list_res)))
+           av_log(avctx, AV_LOG_ERROR, "XRM: failed to release decoder HW cu\n");
+    }
+
+    if (xrmDestroyContext(ctx->xrm_ctx) != XRM_SUCCESS)
+       av_log(avctx, AV_LOG_ERROR, "XRM : decoder destroy context failed\n");
+
+    if (ctx->dts_fifo) {
+        int64_t dts = AV_NOPTS_VALUE;
+        while (av_fifo_size(ctx->dts_fifo)) {
+            av_fifo_generic_read(ctx->dts_fifo, &dts, sizeof(dts), NULL);
+        }
+        av_fifo_free(ctx->dts_fifo);
+    }
+
+    return 0;
+}
+
+static int vcu_dec_get_out_buffer(struct AVCodecContext *s, AVFrame *frame, int flags)
+{
+    mpsoc_vcu_dec_ctx *ctx;
+    uint32_t ret = 0;
+    ctx  = s->priv_data;
+
+    if (!s || !frame || (!is_bitdepth_supported(ctx->bitdepth)))
+        return -1;
+
+    frame->width       = s->width;;
+    frame->height      = s->height;
+    frame->linesize[0] = ctx->xma_frame.frame_props.linesize[0];
+    frame->linesize[1] = ctx->xma_frame.frame_props.linesize[1];
+    switch (ctx->bitdepth) {
+        case MPSOC_VCU_BITDEPTH_8BIT:  frame->format = AV_PIX_FMT_XVBM_8;  break;
+        case MPSOC_VCU_BITDEPTH_10BIT: frame->format = AV_PIX_FMT_XVBM_10; break;
+    }
+
+    // Check for HDR data and transfer it to AVFrame
+    XmaSideDataHandle hdr_sd = xma_frame_get_side_data(&(ctx->xma_frame), XMA_FRAME_HDR);
+    if(hdr_sd)
+    {
+        uint8_t *hdr_sd_ptr  = (uint8_t *)xma_side_data_get_buffer(hdr_sd);
+        size_t hdr_sd_size = xma_side_data_get_size(hdr_sd);
+
+        AVFrameSideData *avframe_sidedata = av_frame_new_side_data(frame, AV_FRAME_XLNX_HDR_SIDEBAND_DATA, hdr_sd_size);
+        if (!avframe_sidedata){
+            av_log(NULL, AV_LOG_ERROR, "mpsoc_vcu_dec: Unable to allocate AVFrameSideData\n");
+            return AVERROR(ENOMEM);
+        }
+        memcpy(avframe_sidedata->data, hdr_sd_ptr, hdr_sd_size);
+        /* Clear all side data from xmaframe to free the side data allocation */
+        xma_frame_clear_all_side_data(&(ctx->xma_frame));
+    }
+
+    ret = av_frame_clone_xma_frame (frame, &(ctx->xma_frame));
+    frame->pts = ctx->xma_frame.pts;
+    if(ret != 0) {
+        av_log(NULL, AV_LOG_ERROR, "Failed to clone XMAFrame into AVFrame \n");
+	return ret;
+    }
+
+    return 0;
+}
+
+static int32_t mpsoc_send_data (
+    mpsoc_vcu_dec_ctx *ctx,
+    unsigned char *buf,
+    uint32_t       size,
+    int64_t        pts,
+    int            is_eof
+)
+{
+    int data_used;
+    int offset    = 0;
+    while (offset < size)
+    {
+        ctx->buffer.data.buffer = buf;
+        ctx->buffer.alloc_size = size;
+        ctx->buffer.is_eof = is_eof;
+        ctx->buffer.pts = pts;
+
+        int32_t ret = xma_dec_session_send_data(ctx->dec_session, &ctx->buffer, &data_used);
+        if (ret != XMA_SUCCESS)
+            return ret;
+
+        offset += data_used;
+        pts = -1; /* only first packet will carry pts */
+    }
+    return XMA_SUCCESS;
+}
+
+
+//XRM decoder plugin load calculation
+static int _calc_dec_load(xrmContext *xrm_ctx, XmaDecoderProperties *dec_props, int32_t func_id, int32_t *dec_load)
+{
+    char pluginName[XRM_MAX_NAME_LEN];
+
+    xrmPluginFuncParam param;
+    memset(&param, 0, sizeof(xrmPluginFuncParam));
+    char *err;
+    void *handle;
+    void (*convertXmaPropsToJson)(void* props, char* funcName, char* jsonJob);
+
+    handle = dlopen("/opt/xilinx/xrm/plugin/libxmaPropsTOjson.so", RTLD_NOW );
+    if (!handle) {
+        av_log(NULL, AV_LOG_ERROR, "Unable to load libxmaPropsTOjson.so  - %s\n", dlerror());
+        return XMA_ERROR;
+    }
+    dlerror(); /* clear error code */
+
+    convertXmaPropsToJson = dlsym(handle, "convertXmaPropsToJson");
+    if ((err = dlerror()) != NULL) {
+        av_log(NULL, AV_LOG_ERROR, "convertXmaPropsToJson symbol not found\n");
+        return XMA_ERROR;
+    }
+
+    (*convertXmaPropsToJson) (dec_props, "DECODER", param.input);
+    dlclose(handle);
+
+    strcpy(pluginName, "xrmU30DecPlugin");
+    if (xrmExecPluginFunc(xrm_ctx, pluginName, func_id, &param) != XRM_SUCCESS)
+    {
+       av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: decoder plugin function %d, fail to run the function\n", func_id);
+       return XMA_ERROR;
+    }
+    else
+    {
+       *dec_load = atoi((char*)(strtok(param.output, " ")));
+       if (*dec_load <= 0)
+       {
+          av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: decoder plugin function %d, calculated load %d.\n", *dec_load);
+          return XMA_ERROR;
+       }
+       else if(*dec_load > XRM_MAX_CU_LOAD_GRANULARITY_1000000)
+       {
+          av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: decoder plugin function %d, calculated load %d is greater than maximum supported.\n", *dec_load);
+          return XMA_ERROR;
+       }
+    }
+
+    return 0;
+}
+
+//XRM decoder CU list allocation
+static int _xrm_dec_cuListAlloc(mpsoc_vcu_dec_ctx *ctx, int32_t dec_load, int32_t xrm_reserve_id, XmaDecoderProperties *dec_props)
+{
+    xrmCuListPropertyV2 decode_cu_list_prop;
+    int ret = -1;
+    int hw_xdevice_id;
+    uint64_t deviceInfoDeviceIndex = 0;
+    uint64_t deviceInfoContraintType = XRM_DEVICE_INFO_CONSTRAINT_TYPE_HARDWARE_DEVICE_INDEX;
+
+    memset(&decode_cu_list_prop, 0, sizeof(xrmCuListPropertyV2));
+    memset(&ctx->decode_cu_list_res, 0, sizeof(xrmCuListResourceV2));
+
+    decode_cu_list_prop.cuNum = 2;
+    strcpy(decode_cu_list_prop.cuProps[0].kernelName, "decoder");
+    strcpy(decode_cu_list_prop.cuProps[0].kernelAlias, "DECODER_MPSOC");
+    decode_cu_list_prop.cuProps[0].devExcl = false;
+    decode_cu_list_prop.cuProps[0].requestLoad = XRM_PRECISION_1000000_BIT_MASK(dec_load);
+
+    strcpy(decode_cu_list_prop.cuProps[1].kernelName, "kernel_vcu_decoder");
+    decode_cu_list_prop.cuProps[1].devExcl = false;
+    decode_cu_list_prop.cuProps[1].requestLoad = XRM_PRECISION_1000000_BIT_MASK(XRM_MAX_CU_LOAD_GRANULARITY_1000000);
+
+    if ((ctx->lxlnx_hwdev > -1) && (xrm_reserve_id > -1)) //2dev mode launcher
+    {
+       deviceInfoDeviceIndex = ctx->lxlnx_hwdev;
+       decode_cu_list_prop.cuProps[0].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+       decode_cu_list_prop.cuProps[0].poolId = xrm_reserve_id;
+       decode_cu_list_prop.cuProps[1].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+       decode_cu_list_prop.cuProps[1].poolId = xrm_reserve_id;
+    }
+    else if (xrm_reserve_id > -1) //1dev mode launcher
+    {
+       decode_cu_list_prop.cuProps[0].poolId = xrm_reserve_id;
+       decode_cu_list_prop.cuProps[1].poolId = xrm_reserve_id;
+    }
+    else if ((ctx->lxlnx_hwdev > -1) || (getenv("XRM_DEVICE_ID")))  //explicit ffmpeg device command
+    {
+       if (ctx->lxlnx_hwdev > -1)
+           deviceInfoDeviceIndex = ctx->lxlnx_hwdev;
+       else
+       {
+           char* endptr;
+           errno=0;
+           deviceInfoDeviceIndex =  strtol(getenv("XRM_DEVICE_ID"), &endptr, 0);
+           if (errno != 0)
+           {
+              av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_DEVICE_ID in decoder plugin\n");
+              return -1;
+           }
+        }
+
+       decode_cu_list_prop.cuProps[0].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+       decode_cu_list_prop.cuProps[1].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+    }
+
+    ret = xrmCuListAllocV2(ctx->xrm_ctx, &decode_cu_list_prop, &ctx->decode_cu_list_res);
+
+    if (ret != 0)
+    {
+        av_log(NULL, AV_LOG_ERROR, "xrm_allocation: fail to allocate cu list from reserve id=%d or device=%lu\n", xrm_reserve_id, deviceInfoDeviceIndex);
+        return ret;
+    }
+    else
+    {
+        ctx->decode_res_inuse = true;
+#if 0
+        for (int i = 0; i < ctx->decode_cu_list_res.cuNum; i++) {
+            printf("Allocated decoder cu list: cu %d\n", i);
+            printf("   xclbinFileName is:  %s\n", ctx->decode_cu_list_res.cuResources[i].xclbinFileName);
+            printf("   kernelPluginFileName is:  %s\n", ctx->decode_cu_list_res.cuResources[i].kernelPluginFileName);
+            printf("   kernelName is:  %s\n", ctx->decode_cu_list_res.cuResources[i].kernelName);
+            printf("   kernelAlias is:  %s\n", ctx->decode_cu_list_res.cuResources[i].kernelAlias);
+            printf("   instanceName is:  %s\n", ctx->decode_cu_list_res.cuResources[i].instanceName);
+            printf("   cuName is:  %s\n", ctx->decode_cu_list_res.cuResources[i].cuName);
+            printf("   deviceId is:  %d\n", ctx->decode_cu_list_res.cuResources[i].deviceId);
+            printf("   cuId is:  %d\n", ctx->decode_cu_list_res.cuResources[i].cuId);
+            printf("   channelId is:  %d\n", ctx->decode_cu_list_res.cuResources[i].channelId);
+            printf("   cuType is:  %d\n", ctx->decode_cu_list_res.cuResources[i].cuType);
+            printf("   baseAddr is:  0x%lx\n", ctx->decode_cu_list_res.cuResources[i].baseAddr);
+            printf("   membankId is:  %d\n", ctx->decode_cu_list_res.cuResources[i].membankId);
+            printf("   membankType is:  %d\n", ctx->decode_cu_list_res.cuResources[i].membankType);
+            printf("   membankSize is:  0x%lx\n", ctx->decode_cu_list_res.cuResources[i].membankSize);
+            printf("   membankBaseAddr is:  0x%lx\n", ctx->decode_cu_list_res.cuResources[i].membankBaseAddr);
+            printf("   allocServiceId is:  %lu\n", ctx->decode_cu_list_res.cuResources[i].allocServiceId);
+            printf("   poolId is:  %lu\n", ctx->decode_cu_list_res.cuResources[i].poolId);
+            printf("   channelLoad is:  %d\n", ctx->decode_cu_list_res.cuResources[i].channelLoad);
+        }
+#endif
+    }
+
+    //Set XMA plugin SO and device index
+    dec_props->plugin_lib = ctx->decode_cu_list_res.cuResources[0].kernelPluginFileName;
+    dec_props->dev_index = ctx->decode_cu_list_res.cuResources[0].deviceId;
+    dec_props->ddr_bank_index = -1;//XMA to select the ddr bank based on xclbin meta data
+    dec_props->cu_index = ctx->decode_cu_list_res.cuResources[1].cuId;
+    dec_props->channel_id = ctx->decode_cu_list_res.cuResources[1].channelId;//SW kernel always used 100%
+
+    return 0;
+}
+
+static int _allocate_xrm_dec_cu(mpsoc_vcu_dec_ctx *ctx, XmaDecoderProperties *dec_props)
+{
+
+    int xrm_reserve_id = -1;
+    int ret = -1;
+    char* endptr;
+
+    //create XRM local context
+    ctx->xrm_ctx = (xrmContext *)xrmCreateContext(XRM_API_VERSION_1);
+    if (ctx->xrm_ctx == NULL)
+    {
+       av_log(NULL, AV_LOG_ERROR, "create local XRM context failed\n");
+       return XMA_ERROR;
+    }
+
+    //XRM decoder plugin load calculation
+    int32_t func_id = 0, dec_load=0;
+    ret = _calc_dec_load(ctx->xrm_ctx, dec_props, func_id, &dec_load);
+    if (ret < 0) return ret;
+
+    if (getenv("XRM_RESERVE_ID"))
+    {
+       errno=0;
+       xrm_reserve_id =  strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);
+       if (errno != 0)
+       {
+          av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_RESERVE_ID in decoder plugin\n");
+          return -1;
+       }
+
+    }
+
+    ret = _xrm_dec_cuListAlloc(ctx,dec_load,xrm_reserve_id,dec_props);
+    if (ret < 0) return ret;
+
+    av_log(NULL, AV_LOG_DEBUG, "---decoder xrm out: dec_load=%d, plugin=%s, device=%d, cu=%d, ch=%d\n",
+    dec_load, dec_props->plugin_lib,dec_props->dev_index,dec_props->cu_index,dec_props->channel_id);
+
+    return ret;
+}
+
+static bool extract_info_from_container(const AVCodecContext *avctx)
+{
+  mpsoc_vcu_dec_ctx *ctx = avctx->priv_data;
+  if (ctx == NULL)
+    return false;
+  switch(avctx->pix_fmt)
+  {
+    case AV_PIX_FMT_YUV420P:
+      ctx->bitdepth = MPSOC_VCU_BITDEPTH_8BIT;
+      ctx->chroma_mode = 420;
+      break;
+    case AV_PIX_FMT_YUYV422:
+      ctx->bitdepth = MPSOC_VCU_BITDEPTH_8BIT;
+      ctx->chroma_mode = 422;
+      break;
+    case AV_PIX_FMT_YUV420P10LE:
+      ctx->bitdepth = MPSOC_VCU_BITDEPTH_10BIT;
+      ctx->chroma_mode = 420;
+      break;
+    case AV_PIX_FMT_YUV422P10LE:
+      ctx->bitdepth = MPSOC_VCU_BITDEPTH_10BIT;
+      ctx->chroma_mode = 422;
+	  break;
+	default:
+	  av_log(ctx, AV_LOG_ERROR, "Unable to extract pixel format or SPS info from stream\n");
+	  return false;
+   }
+   return true;
+}
+
+static bool extract_stream_info(AVCodecContext *avctx)
+{
+    uint32_t fr_num, fr_den;
+    int64_t gcd;
+    int ret;
+    mpsoc_vcu_dec_ctx *ctx = avctx->priv_data;
+
+    /* FFmpeg assigns codec_id based on user specified parameter on command line. Hence it is not reliable.
+     * Following is a workaround to prevent incorrect parsing based on avctx->codec_id.
+     */
+    char *name = avcodec_profile_name(avctx->codec_id, avctx->profile);
+    if (!name) {
+        av_log(ctx, AV_LOG_ERROR, "input stream type does not match with specified codec type\n");
+	return false;
+    }
+
+    bool valid_container_framerate = false;
+    /* give prefernce to framerate in container, if present within valid range */
+    if (avctx->framerate.num && avctx->framerate.den && (avctx->framerate.num/avctx->framerate.den) <= 120)
+        valid_container_framerate = true;
+    else
+        valid_container_framerate = false;
+    if (avctx->extradata_size > 0 && avctx->extradata) {
+        if (avctx->codec_id == AV_CODEC_ID_H264) {
+            const SPS *h264_sps = NULL;
+            H264Context s;
+            memset(&s, 0, sizeof(H264Context));
+            ret = ff_h264_decode_extradata(avctx->extradata, avctx->extradata_size, &s.ps, &s.is_avc, &s.nal_length_size, avctx->err_recognition, avctx);
+            if (ret < 0) {
+                ff_h264_ps_uninit(&s.ps);
+                av_log(ctx, AV_LOG_ERROR, "decoding extradata failed\n");
+                return false;
+            }
+
+            for (int i = 0; i < FF_ARRAY_ELEMS(s.ps.sps_list); i++) {
+                if (s.ps.sps_list[i]) {
+                    h264_sps = (SPS *) s.ps.sps_list[i]->data;
+                    break;
+                }
+            }
+
+            if (!valid_container_framerate && h264_sps && h264_sps->timing_info_present_flag) {
+                fr_num = h264_sps->time_scale;
+                fr_den = h264_sps->num_units_in_tick * 2;
+                gcd = av_gcd(fr_num, fr_den);
+                if (gcd > 0) {
+                    avctx->framerate.num = fr_num/gcd;
+                    avctx->framerate.den = fr_den/gcd;
+                }
+            } else {
+                av_log(ctx, AV_LOG_INFO, "timing information from stream is not available\n");
+            }
+
+			if (h264_sps == NULL) {
+			  av_log(ctx, AV_LOG_INFO, "unable to extract sps params from stream\n");
+              return extract_info_from_container(avctx);
+			} else {
+              ctx->bitdepth = h264_sps->bit_depth_luma;
+
+              if (h264_sps->chroma_format_idc == 0)
+                  ctx->chroma_mode = 400;
+              else if (h264_sps->chroma_format_idc == 1)
+                  ctx->chroma_mode = 420;
+              else if (h264_sps->chroma_format_idc == 2)
+                  ctx->chroma_mode = 422;
+              else if (h264_sps->chroma_format_idc == 3)
+                  ctx->chroma_mode = 444;
+              else
+                  ctx->chroma_mode = 420;
+            }
+
+            ff_h264_ps_uninit(&s.ps);
+        } else {
+            //HEVC
+            HEVCContext s;
+            const HEVCSPS *hevc_sps = NULL;
+            memset(&s, 0, sizeof(HEVCContext));
+            ret = ff_hevc_decode_extradata(avctx->extradata, avctx->extradata_size, &s.ps, &s.sei, &s.is_nalff,
+                                                &s.nal_length_size, avctx->err_recognition,
+                                                s.apply_defdispwin, avctx);
+            if (ret < 0) {
+                ff_hevc_ps_uninit(&s.ps);
+                av_log(ctx, AV_LOG_ERROR, "decoding extradata failed\n");
+                return false;
+            }
+
+            for (int i = 0; i < FF_ARRAY_ELEMS(s.ps.sps_list); i++) {
+                if (s.ps.sps_list[i]) {
+                    hevc_sps= (HEVCSPS *) s.ps.sps_list[i]->data;
+                    break;
+                }
+            }
+
+            if (!valid_container_framerate && hevc_sps && hevc_sps->vui.vui_timing_info_present_flag) {
+                fr_num = hevc_sps->vui.vui_time_scale;
+                fr_den = hevc_sps->vui.vui_num_units_in_tick;
+                gcd = av_gcd(fr_num, fr_den);
+                if (gcd > 0) {
+                    avctx->framerate.num = fr_num/gcd;
+                    avctx->framerate.den = fr_den/gcd;
+	            }
+            } else {
+                av_log(ctx, AV_LOG_INFO, "timing information from stream is not available\n");
+            }
+
+           if (hevc_sps == NULL) {
+                av_log(ctx, AV_LOG_INFO, "unable to extract sps params from stream\n");
+                return extract_info_from_container(avctx);
+           } else {
+
+                ctx->bitdepth = hevc_sps->bit_depth;
+                if (hevc_sps->chroma_format_idc == 0)
+                    ctx->chroma_mode = 400;
+                else if (hevc_sps->chroma_format_idc == 1)
+                    ctx->chroma_mode = 420;
+                else if (hevc_sps->chroma_format_idc == 2)
+                   ctx->chroma_mode = 422;
+                else if (hevc_sps->chroma_format_idc == 3)
+                   ctx->chroma_mode = 444;
+                else
+                   ctx->chroma_mode = 420;
+           }
+
+           ff_hevc_ps_uninit(&s.ps);
+        }
+    }
+
+    if (!is_bitdepth_supported(ctx->bitdepth)) {
+        av_log(ctx, AV_LOG_ERROR, "Unsupported bit depth: %d-bit is not supported\n", ctx->bitdepth);
+        return false;
+    }
+
+    return true;
+}
+
+HDR10_VUI_Params* get_hdr10_vui_params()
+{
+    return &g_hdr10_vui_params;
+}
+
+void init_hdr10_vui_params()
+{
+    if(g_hdr10_vui_params.isInitialized)
+        return;
+    sprintf(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");
+    sprintf(g_hdr10_vui_params.TxChar,"TRANSFER_UNSPECIFIED");
+    sprintf(g_hdr10_vui_params.ColorMatrix,"COLOUR_MAT_UNSPECIFIED");
+    g_hdr10_vui_params.isInitialized = 1;
+}
+
+void print_hdr10_vui_params()
+{
+    printf("\n");
+    printf("g_hdr10_vui_params.ColorDesc   = %s\n",g_hdr10_vui_params.ColorDesc);
+    printf("g_hdr10_vui_params.TxChar      = %s\n",g_hdr10_vui_params.TxChar);
+    printf("g_hdr10_vui_params.ColorMatrix = %s\n",g_hdr10_vui_params.ColorMatrix);
+    printf("\n");
+}
+
+static bool set_hdr10_vui(AVCodecContext *avctx)
+{
+    init_hdr10_vui_params();
+    switch(avctx->color_primaries)
+    {
+        case AVCOL_PRI_RESERVED0     : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");    break;
+        case AVCOL_PRI_BT709         : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_BT_709");         break;
+        case AVCOL_PRI_UNSPECIFIED   : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");    break;
+        case AVCOL_PRI_RESERVED      : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");    break;
+        case AVCOL_PRI_BT470M        : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_BT_470_NTSC");    break;
+        case AVCOL_PRI_BT470BG       : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");    break;
+        case AVCOL_PRI_SMPTE170M     : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");    break;
+        case AVCOL_PRI_SMPTE240M     : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_SMPTE_240M");     break;
+        case AVCOL_PRI_FILM          : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_GENERIC_FILM");   break;
+        case AVCOL_PRI_BT2020        : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_BT_2020");        break;
+        case AVCOL_PRI_SMPTE428      : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_SMPTE_ST_428");   break;
+        case AVCOL_PRI_SMPTE431      : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_SMPTE_RP_431");   break;
+        case AVCOL_PRI_SMPTE432      : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_SMPTE_EG_432");   break;
+        case AVCOL_PRI_EBU3213       : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_EBU_3213");       break;
+        default                      : strcpy(g_hdr10_vui_params.ColorDesc,"COLOUR_DESC_UNSPECIFIED");    break;
+    }
+
+    switch(avctx->color_trc)
+    {
+        case AVCOL_TRC_UNSPECIFIED  : strcpy(g_hdr10_vui_params.TxChar,"TRANSFER_UNSPECIFIED");    break;
+        case AVCOL_TRC_SMPTE2084    : strcpy(g_hdr10_vui_params.TxChar,"TRANSFER_BT_2100_PQ");     break;
+        case AVCOL_TRC_ARIB_STD_B67 : strcpy(g_hdr10_vui_params.TxChar,"TRANSFER_BT_2100_HLG");    break;
+        default                     : strcpy(g_hdr10_vui_params.TxChar,"TRANSFER_UNSPECIFIED");    break;
+    }
+
+    switch(avctx->colorspace)
+    {
+        case AVCOL_SPC_UNSPECIFIED : strcpy(g_hdr10_vui_params.ColorMatrix,"COLOUR_MAT_UNSPECIFIED");    break;
+        case AVCOL_SPC_BT2020_NCL  : strcpy(g_hdr10_vui_params.ColorMatrix,"COLOUR_MAT_BT_2100_YCBCR");  break;
+        default                    : strcpy(g_hdr10_vui_params.ColorMatrix,"COLOUR_MAT_UNSPECIFIED");    break;
+    }
+
+    return true;
+
+}
+
+static av_cold int mpsoc_vcu_decode_init (AVCodecContext *avctx)
+{
+    XmaDecoderProperties dec_props;
+    mpsoc_vcu_dec_ctx   *ctx  = avctx->priv_data;
+    uint32_t scan_type, zero_copy, index;
+    bool valid;
+
+    /* extract stream information from SPS and update 'mpsoc_vcu_dec_ctx'.
+     * This prior information is needed for decoder to derive optimum output buffer size during preallocation */
+    valid = extract_stream_info(avctx);
+    if (!valid)
+        return AVERROR(ENOTSUP);
+
+    set_hdr10_vui(avctx);
+
+    strcpy(dec_props.hwvendor_string, "MPSoC");
+
+    dec_props.hwdecoder_type        = XMA_MULTI_DECODER_TYPE;
+    dec_props.params                = ctx->dec_params;
+    dec_props.param_cnt             = MAX_DEC_PARAMS;
+    dec_props.width                 = avctx->width;
+    dec_props.height                = avctx->height;
+    dec_props.framerate.numerator   = avctx->framerate.num;
+
+    if (avctx->framerate.den)
+        dec_props.framerate.denominator = avctx->framerate.den;
+    else
+        dec_props.framerate.denominator = 1;
+
+    scan_type = avctx->field_order;
+
+    ctx->avctx = avctx;
+    ctx->flush_sent = false;
+    index = 0;
+
+    strcpy(ctx->dec_params_name[index], "bitdepth");
+    ctx->dec_params[index].name       = ctx->dec_params_name[index];
+    ctx->dec_params[index].type       = XMA_UINT32;
+    ctx->dec_params[index].length     = sizeof(ctx->bitdepth);
+    ctx->dec_params[index].value      = &(ctx->bitdepth);
+    index++;
+
+    ctx->codec_type = (avctx->codec_id == AV_CODEC_ID_H264) ? 0 : 1;
+    strcpy(ctx->dec_params_name[index], "codec_type");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(ctx->codec_type);
+    ctx->dec_params[index].value  = &(ctx->codec_type);
+    index++;
+
+    if(ctx->low_latency && avctx->has_b_frames > 0) {
+        return mpsoc_report_error(ctx, "Attempting to use decoder low latency, but input has B-Frames!", AVERROR(EINVAL));
+    }
+    strcpy(ctx->dec_params_name[index], "low_latency");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(ctx->low_latency);
+    ctx->dec_params[index].value  = &(ctx->low_latency);
+    index++;
+
+    strcpy(ctx->dec_params_name[index], "entropy_buffers_count");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(ctx->entropy_buffers_count);
+    ctx->dec_params[index].value  = &(ctx->entropy_buffers_count);
+    index++;
+
+    zero_copy = 1; //always zero copy output
+    strcpy(ctx->dec_params_name[index], "zero_copy");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(zero_copy);
+    ctx->dec_params[index].value  = &(zero_copy);
+    index++;
+
+    strcpy(ctx->dec_params_name[index], "profile");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(avctx->profile);
+    ctx->dec_params[index].value  = &(avctx->profile);
+    index++;
+
+    strcpy(ctx->dec_params_name[index], "level");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(avctx->level);
+    ctx->dec_params[index].value  = &(avctx->level);
+    index++;
+
+    strcpy(ctx->dec_params_name[index], "chroma_mode");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(ctx->chroma_mode);
+    ctx->dec_params[index].value  = &(ctx->chroma_mode);
+    index++;
+
+    strcpy(ctx->dec_params_name[index], "scan_type");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(scan_type);
+    ctx->dec_params[index].value  = &(scan_type);
+    index++;
+
+    strcpy(ctx->dec_params_name[index], "latency_logging");
+    ctx->dec_params[index].name   = ctx->dec_params_name[index];
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(ctx->latency_logging);
+    ctx->dec_params[index].value  = &(ctx->latency_logging);
+    index++;
+
+    ctx->dec_params[index].name   = "splitbuff_mode";
+    ctx->dec_params[index].type   = XMA_UINT32;
+    ctx->dec_params[index].length = sizeof(ctx->splitbuff_mode);
+    ctx->dec_params[index].value  = &(ctx->splitbuff_mode);
+    index++;
+
+    /*----------------------------------------------------
+      Allocate decoder resource from XRM reserved resource
+      ----------------------------------------------------*/
+    ctx->decode_res_inuse    = false;
+    if (_allocate_xrm_dec_cu(ctx, &dec_props) < 0) {
+            av_log(ctx, AV_LOG_ERROR, "xrm_allocation: resource allocation failed\n");
+            return XMA_ERROR;
+    }
+
+    ctx->dec_session = xma_dec_session_create(&dec_props);
+    if (!ctx->dec_session)
+        return mpsoc_report_error(ctx, "ERROR: Unable to allocate MPSoC decoder session", AVERROR_EXTERNAL);
+
+    switch (ctx->bitdepth) {
+        case MPSOC_VCU_BITDEPTH_8BIT:
+            ctx->xma_frame.frame_props.format = XMA_VCU_NV12_FMT_TYPE;
+	break;
+	case MPSOC_VCU_BITDEPTH_10BIT:
+            ctx->xma_frame.frame_props.format = XMA_VCU_NV12_10LE32_FMT_TYPE;
+	break;
+        default:
+            av_log(ctx, AV_LOG_ERROR, "unsupported bit depth %d\n", ctx->bitdepth);
+            return XMA_ERROR;
+    }
+
+    ctx->xma_frame.side_data                  = NULL;
+    ctx->xma_frame.frame_props.width          = avctx->width;
+    ctx->xma_frame.frame_props.height         = avctx->height;
+    ctx->xma_frame.frame_props.bits_per_pixel = ctx->bitdepth;
+    ctx->xma_frame.frame_rate.numerator       = avctx->framerate.num;
+    ctx->xma_frame.frame_rate.denominator     = avctx->framerate.den;
+
+    for (uint32_t i = 0; i < xma_frame_planes_get(&ctx->xma_frame.frame_props); i++) {
+        ctx->xma_frame.data[i].buffer = NULL;
+        ctx->xma_frame.data[i].buffer_type = XMA_DEVICE_BUFFER_TYPE;
+        ctx->xma_frame.data[i].refcount = 1;
+        ctx->xma_frame.data[i].is_clone = 1;
+    }
+
+    ctx->dts_fifo = av_fifo_alloc(DTS_FIFO_SIZE * sizeof(int64_t));
+    if(!ctx->dts_fifo)
+        return mpsoc_report_error(ctx, "DTS fifo allocation failed", AVERROR(ENOMEM));
+
+    ctx->genpts = -1;
+    ctx->pts_q = av_make_q(0, 0);
+    ctx->idr_count = 0;
+
+    switch (ctx->bitdepth) {
+        case MPSOC_VCU_BITDEPTH_8BIT:  avctx->pix_fmt = AV_PIX_FMT_XVBM_8;  break;
+        case MPSOC_VCU_BITDEPTH_10BIT: avctx->pix_fmt = AV_PIX_FMT_XVBM_10; break;
+    }
+
+    return 0;
+}
+
+static void set_pts(AVCodecContext *avctx, AVFrame *frame)
+{
+    AVRational fps;
+    mpsoc_vcu_dec_ctx *ctx = avctx->priv_data;
+
+    av_fifo_generic_read(ctx->dts_fifo, &frame->pkt_dts, sizeof(int64_t), NULL);
+    if (ctx->genpts != -1) {
+        fps.num = avctx->time_base.den;
+        fps.den = avctx->time_base.num * avctx->ticks_per_frame;
+
+        frame->pts = ctx->xma_frame.pts = ctx->genpts;
+        ctx->pts_q = av_div_q(av_inv_q(avctx->pkt_timebase), fps);
+        frame->pts = (int64_t)(frame->pts * av_q2d(ctx->pts_q));
+
+        ctx->genpts++;
+    }
+}
+
+static uint8_t mpsoc_decode_hevc_unit_type (AVPacket* pkt)
+{
+    unsigned char* pt = pkt->data;
+    unsigned char* end = pkt->data + pkt->size - 3;
+    while (pt < end)
+    {
+        if ((pt[0] == 0x00) && (pt[1] == 0x00) && (pt[2] == 0x01))
+        {
+            unsigned char naluType = (pt[3] & 0x7E) >> 1;
+            if (naluType <= HEVC_NAL_RASL_R || (naluType >= HEVC_NAL_BLA_W_LP && naluType <= HEVC_NAL_CRA_NUT))
+                return naluType;
+        }
+        pt++;
+    }
+    return 255;
+}
+
+static int mpsoc_vcu_decode (AVCodecContext *avctx, void *data, int *got_frame, AVPacket *avpkt)
+{
+    int send_ret, recv_ret;
+
+    AVFrame *frame	= data;
+    int data_used	= 0;
+    mpsoc_vcu_dec_ctx *ctx = avctx->priv_data;
+
+    int retries = 0;
+    if (avpkt->data) {
+        if ((avpkt->pts == AV_NOPTS_VALUE) && (ctx->genpts == -1)) {
+            ctx->genpts = 0;
+        }
+        if ((avctx->codec_id == AV_CODEC_ID_H264) ? mpsoc_decode_is_h264_syncpoint (avctx, avpkt) : mpsoc_decode_is_hevc_idr (avpkt))
+            ctx->idr_count++;
+        else if (ctx->idr_count == 0)
+        {
+            *got_frame = 0;
+            return avpkt->size;
+        }
+
+        if (avctx->codec_id == AV_CODEC_ID_HEVC)
+        {
+            uint8_t nal_unit_type = mpsoc_decode_hevc_unit_type (avpkt);
+            if ((ctx->idr_count < 2) && ((nal_unit_type == HEVC_NAL_RASL_N) || (nal_unit_type == HEVC_NAL_RASL_R)))
+            {
+                *got_frame = 0;
+                return avpkt->size;
+            }
+        }
+
+        if (av_fifo_space(ctx->dts_fifo) < sizeof(int64_t)) {
+            av_fifo_realloc2(ctx->dts_fifo, av_fifo_size(ctx->dts_fifo) + (sizeof(int64_t) * DTS_FIFO_INC_SIZE));
+        }
+        av_fifo_generic_write(ctx->dts_fifo, &avpkt->dts, sizeof(int64_t), NULL);
+
+retry:
+        send_ret = mpsoc_send_data(ctx, avpkt->data, avpkt->size, avpkt->pts, 0);
+
+        if (send_ret == XMA_ERROR) {
+            *got_frame = 0;
+            return mpsoc_report_error(ctx, "failed to transfer data to decoder", AVERROR(EIO));
+        } else {
+            recv_ret = xma_dec_session_recv_frame(ctx->dec_session, &(ctx->xma_frame));
+            if (recv_ret != XMA_SUCCESS) {
+                *got_frame = 0;
+            } else {
+                if (vcu_dec_get_out_buffer(avctx, frame, 0)) {
+                    *got_frame = 0;
+                } else {
+                    *got_frame = 1;
+                    set_pts(avctx, frame);
+                }
+            }
+
+            if (send_ret == XMA_TRY_AGAIN) {
+                if(*got_frame == 1) {
+                    do {
+                        usleep(10);
+                        send_ret = mpsoc_send_data(ctx, avpkt->data, avpkt->size, avpkt->pts, 0);
+                    }while(send_ret == XMA_TRY_AGAIN);
+                } else {
+                    goto retry;
+                }
+            }
+        }
+
+        data_used =  avpkt->size;
+
+    } else { // EOF
+        while(true) {
+            /* flush not sent and queue is empty. send flush now */
+            if (!ctx->flush_sent) {
+                ctx->flush_sent = true;
+                ctx->buffer.is_eof = 1;
+                send_ret = xma_dec_session_send_data(ctx->dec_session, &(ctx->buffer), &data_used);
+            } else {
+                /* send free output buffer indexes, so that decoding can continue on device side */
+                XmaDataBuffer eos_buff;
+                eos_buff.data.buffer = NULL;
+                eos_buff.alloc_size = 0;
+                eos_buff.is_eof = 0;
+                eos_buff.pts = -1;
+                send_ret = xma_dec_session_send_data(ctx->dec_session, &eos_buff, &data_used);
+            }
+            if (send_ret == XMA_ERROR) {
+                *got_frame = 0;
+                return mpsoc_report_error(ctx, "failed to transfer data to decoder", AVERROR_UNKNOWN);
+            }
+
+            recv_ret = xma_dec_session_recv_frame(ctx->dec_session, &(ctx->xma_frame));
+            if (recv_ret != XMA_SUCCESS) {
+                *got_frame = 0;
+            } else {
+                if (vcu_dec_get_out_buffer(avctx, frame, 0)) {
+                    *got_frame = 0;
+                } else {
+                    *got_frame = 1;
+                    set_pts(avctx, frame);
+                }
+            }
+
+           if (!ctx->flush_sent) {
+             if (recv_ret == XMA_SUCCESS)
+              break;
+             else
+               continue;
+           } else {
+             if (recv_ret == XMA_TRY_AGAIN) {
+               continue;
+             } else {
+               break;
+             }
+           }
+       }
+     data_used = 0;
+
+   }
+
+    return data_used;
+}
+
+static const AVClass mpsoc_vcu_h264_class = {
+    .class_name    =    "MPSOC H.264 decoder",
+    .item_name     =    av_default_item_name,
+    .option        =    options,
+    .version       =    LIBAVUTIL_VERSION_INT,
+};
+
+FFCodec ff_h264_vcu_mpsoc_decoder = {
+    .p.name              =    "mpsoc_vcu_h264",
+    .p.long_name         =    NULL_IF_CONFIG_SMALL("MPSOC H.264 Decoder"),
+    .p.type              =    AVMEDIA_TYPE_VIDEO,
+    .p.id                =    AV_CODEC_ID_H264,
+    .init                =    mpsoc_vcu_decode_init,
+    FF_CODEC_DECODE_CB(mpsoc_vcu_decode),
+    .flush               =    mpsoc_vcu_flush,
+    .bsfs                =    "h264_mp4toannexb",
+    .close               =    mpsoc_vcu_decode_close,
+    .priv_data_size      =    sizeof(mpsoc_vcu_dec_ctx),
+    .p.priv_class          =    &mpsoc_vcu_h264_class,
+    .p.capabilities        =    AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AVOID_PROBING,
+    .p.pix_fmts            =    (const enum AVPixelFormat[]) { AV_PIX_FMT_XVBM_8,
+                                                             AV_PIX_FMT_XVBM_10,
+                                                             AV_PIX_FMT_NONE
+                                                           },
+    .caps_internal       = FF_CODEC_CAP_SETS_PKT_DTS,
+};
+
+static const AVClass mpsoc_vcu_hevc_class = {
+    .class_name    =    "MPSOC HEVC decoder",
+    .item_name     =    av_default_item_name,
+    .option        =    options,
+    .version       =    LIBAVUTIL_VERSION_INT,
+};
+
+FFCodec ff_hevc_vcu_mpsoc_decoder = {
+    .p.name                =    "mpsoc_vcu_hevc",
+    .p.long_name           =    NULL_IF_CONFIG_SMALL("MPSOC HEVC Decoder"),
+    .p.type                =    AVMEDIA_TYPE_VIDEO,
+    .p.id                  =    AV_CODEC_ID_HEVC,
+    .init                =    mpsoc_vcu_decode_init,
+    FF_CODEC_DECODE_CB(mpsoc_vcu_decode),
+    .flush               =    mpsoc_vcu_flush,
+    .bsfs                =    "hevc_mp4toannexb",
+    .close               =    mpsoc_vcu_decode_close,
+    .priv_data_size      =    sizeof(mpsoc_vcu_dec_ctx),
+    .p.priv_class          =    &mpsoc_vcu_hevc_class,
+    .p.capabilities        =    AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AVOID_PROBING,
+    .p.pix_fmts            =    (const enum AVPixelFormat[]) { AV_PIX_FMT_XVBM_8,
+                                                             AV_PIX_FMT_XVBM_10,
+                                                             AV_PIX_FMT_NONE
+                                                           },
+    .caps_internal       = FF_CODEC_CAP_SETS_PKT_DTS,
+};
diff --git a/libavcodec/mpsoc_vcu_enc.c b/libavcodec/mpsoc_vcu_enc.c
new file mode 100644
index 0000000000..d7ce4d49da
--- /dev/null
+++ b/libavcodec/mpsoc_vcu_enc.c
@@ -0,0 +1,1972 @@
+/*
+ * Modifications Copyright (C) 2024 Advanced Micro Devices, Inc.
+ * Copyright (C) 2018 Xilinx Inc.
+ * All rights reserved.
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include "libavutil/internal.h"
+#include "libavutil/common.h"
+#include "libavutil/opt.h"
+#include "libavutil/pixdesc.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/timestamp.h"
+#include "libavutil/macros.h"
+#include "libavutil/fifo.h"
+#include "libavcodec/mpsoc_vcu_hdr10.h"
+#include "avcodec.h"
+#include "encode.h"
+#include "internal.h"
+#include "codec_internal.h"
+#include <unistd.h>
+#include <stdio.h>
+#include <stdlib.h>
+#include <assert.h>
+#include <memory.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/mman.h>
+#include <fcntl.h>
+#include <xma.h>
+#include <xrm.h>
+#include <pthread.h>
+#include "mpsoc_vcu_enc.h"
+#include <xvbm.h>
+#include <dlfcn.h>
+#include "../xmaPropsTOjson.h"
+#include <errno.h>
+
+static int mpsoc_report_error(mpsoc_vcu_enc_ctx *ctx, const char *err_str, int32_t err_type)
+{
+    if (ctx)
+    {
+        av_log(ctx, AV_LOG_ERROR, "encoder error: %s : ffmpeg pid %d on device index =  %d cu index = %d\n",
+               err_str, getpid(), ctx->encode_cu_list_res.cuResources[0].deviceId,
+               ctx->encode_cu_list_res.cuResources[1].cuId);
+    }
+
+    return err_type;
+}
+
+static void
+mpsoc_vcu_encode_queue_pts (AVFifoBuffer* queue, int64_t pts)
+{
+    av_fifo_generic_write(queue, &pts, sizeof(pts), NULL);
+}
+
+static int64_t
+mpsoc_vcu_encode_dequeue_pts(AVFifoBuffer* queue)
+{
+    int64_t ts = AV_NOPTS_VALUE;
+    if (av_fifo_size(queue) > 0)
+        av_fifo_generic_read(queue, &ts, sizeof(ts), NULL);
+    return ts;
+}
+
+static bool mpsoc_encode_is_h264_idr(AVPacket *pkt)
+{
+    unsigned char* pt = pkt->data;
+    unsigned char* end = pkt->data + pkt->size - 3;
+    while (pt < end)
+    {
+        if ((pt[0] == 0x00) && (pt[1] == 0x00) && (pt[2] == 0x01) && ((pt[3] & 0x1F) == 0x05))
+            return true;
+        pt++;
+    }
+    return false;
+}
+
+static bool mpsoc_encode_is_hevc_idr(AVPacket *pkt)
+{
+    unsigned char* pt = pkt->data;
+    unsigned char* end = pkt->data + pkt->size - 3;
+    while (pt < end)
+    {
+        if ((pt[0] == 0x00) && (pt[1] == 0x00) && (pt[2] == 0x01))
+        {
+            unsigned char naluType = (pt[3] & 0x7E) >> 1;
+            if (naluType == 19 || naluType == 20)
+                return true;
+        }
+        pt++;
+    }
+    return false;
+}
+
+static void
+mpsoc_vcu_encode_prepare_out_timestamp (AVCodecContext *avctx, AVPacket *pkt)
+{
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+
+    // TODO: code is written based on nvenc, need to check legalities of this
+    if (ctx->pts_1 != AV_NOPTS_VALUE && ctx->b_frames > 0 && ctx->is_first_outframe) {
+        int64_t ts0 = ctx->pts_0, ts1 = ctx->pts_1;
+        int64_t delta;
+
+        if ((ts0 < 0 && ts1 > INT64_MAX + ts0) ||
+            (ts0 > 0 && ts1 < INT64_MIN + ts0))
+            return;
+        delta = ts1 - ts0;
+
+        if ((delta < 0 && ts0 > INT64_MAX + delta) ||
+            (delta > 0 && ts0 < INT64_MIN + delta))
+          return;
+        pkt->dts = ts0 - delta;
+
+        ctx->is_first_outframe = 0;
+        return;
+    }
+
+    pkt->dts = mpsoc_vcu_encode_dequeue_pts(ctx->pts_queue);
+}
+
+
+static void deinit_la(mpsoc_vcu_enc_ctx *ctx)
+{
+    if (!ctx->la) {
+        return;
+    }
+    destroy_xlnx_la(ctx->la);
+    ctx->la = NULL;
+}
+
+static int32_t init_la(AVCodecContext *avctx)
+{
+    xlnx_la_cfg_t la_cfg;
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+    la_cfg.width = avctx->width;
+    la_cfg.height = avctx->height;
+    la_cfg.framerate.numerator = avctx->framerate.num;
+    la_cfg.framerate.denominator = avctx->framerate.den;
+    //@TODO: Assume 256 aligned for now. Needs to be fixed later
+    la_cfg.stride = FFALIGN(avctx->width, VCU_STRIDE_ALIGN);
+    la_cfg.bits_per_pixel = ctx->bits_per_sample;
+    la_cfg.lxlnx_hwdev = ctx->lxlnx_hwdev;
+
+    if (avctx->gop_size <= 0) {
+        la_cfg.gop_size = 120;
+    } else {
+        la_cfg.gop_size = avctx->gop_size;
+    }
+
+    la_cfg.lookahead_depth = ctx->lookahead_depth;
+    la_cfg.spatial_aq_mode = ctx->spatial_aq;
+    la_cfg.spatial_aq_gain = ctx->spatial_aq_gain;
+    la_cfg.temporal_aq_mode = ctx->temporal_aq;
+    la_cfg.rate_control_mode = ctx->rate_control_mode;
+    la_cfg.b_frames = ctx->b_frames;
+    la_cfg.dynamic_gop = ctx->dynamic_gop;
+    la_cfg.framerate.numerator   = avctx->framerate.num;
+    la_cfg.framerate.denominator = avctx->framerate.den;
+    la_cfg.latency_logging = ctx->latency_logging;
+    switch (avctx->pix_fmt) {
+    case AV_PIX_FMT_NV12:
+        la_cfg.enableHwInBuf = 0;
+        la_cfg.fmt_type = XMA_VCU_NV12_FMT_TYPE;
+        break;
+    case AV_PIX_FMT_XV15:
+        la_cfg.enableHwInBuf = 0;
+        la_cfg.fmt_type = XMA_VCU_NV12_10LE32_FMT_TYPE;
+        break;
+    case AV_PIX_FMT_XVBM_8:
+        la_cfg.enableHwInBuf = 1;
+        la_cfg.fmt_type = XMA_VCU_NV12_FMT_TYPE;
+        break;
+    case AV_PIX_FMT_XVBM_10:
+        la_cfg.enableHwInBuf = 1;
+        la_cfg.fmt_type = XMA_VCU_NV12_10LE32_FMT_TYPE;
+        break;
+    case AV_PIX_FMT_YUV420P:
+        la_cfg.enableHwInBuf = 0;
+        la_cfg.fmt_type = XMA_YUV420_FMT_TYPE;
+        break;
+    }
+    switch (avctx->codec_id) {
+    case AV_CODEC_ID_H264:
+        la_cfg.codec_type = EXlnxAvc;
+        break;
+    case AV_CODEC_ID_HEVC:
+        la_cfg.codec_type = EXlnxHevc;
+        break;
+    }
+
+    ctx->la = create_xlnx_la(&la_cfg);
+    if (!ctx->la) {
+        av_log(NULL, AV_LOG_ERROR, "Error : init_la : create_xlnx_la Failed OOM\n");
+        return AVERROR(ENOMEM);
+    }
+    return 0;
+}
+
+static av_cold int mpsoc_vcu_encode_close(AVCodecContext *avctx)
+{
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+
+    av_fifo_freep(&ctx->pts_queue);
+    xma_enc_session_destroy(ctx->enc_session);
+    deinit_la(ctx);
+    if(ctx->la_in_frame) free(ctx->la_in_frame);
+	    ctx->la_in_frame = NULL;
+
+    //XRM encoder de-allocation
+    if (ctx->encode_res_inuse)
+    {
+        if (!(xrmCuListReleaseV2(ctx->xrm_ctx, &ctx->encode_cu_list_res)))
+           av_log(avctx, AV_LOG_ERROR, "XRM: failed to release encoder cu\n");
+    }
+
+    if (xrmDestroyContext(ctx->xrm_ctx) != XRM_SUCCESS)
+       av_log(NULL, AV_LOG_ERROR, "XRM : encoder destroy context failed\n");
+
+    if (ctx->enc_dyn_params.dyn_params_lib) {
+        (*(ctx->enc_dyn_params.dyn_params_obj.xlnx_enc_deinit_dyn_params))(ctx->enc_dyn_params.dynamic_param_handle);
+        dlclose(ctx->enc_dyn_params.dyn_params_lib);
+    }
+
+    return 0;
+}
+
+static int check_expert_value(AVDictionaryEntry *entry, int min, int max)
+{
+	int val = atoi(entry->value);
+
+	// Check for the case when atoi(x) returns 0 when the input is not a number
+	if (val == 0 && *(entry->value) != '0'){
+		av_log (NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is invalid; using default value instead\n", entry->key, entry->value);
+		return -1;
+	}
+
+	if (val >= min && val <= max)
+		return val;
+	else {
+		av_log (NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert option %s, value=%s is out of range, valid range is [%d, %d]; using default value instead\n", entry->key, entry->value, min, max);
+		return (min-1);
+	}
+}
+
+static int32_t xlnx_load_dyn_params_lib(EncDynParams* enc_dyn_params)
+{
+    char* dlret;
+    enc_dyn_params->dyn_params_lib = dlopen(DYN_PARAMS_LIB_NAME, RTLD_NOW);
+    if (!enc_dyn_params->dyn_params_lib) {
+        av_log(NULL, AV_LOG_ERROR, "Error loading : %s\n", dlerror());
+        av_log(NULL, AV_LOG_ERROR, "The dynamic params library is part of xma apps. Install xma apps to use dynamic params feature\n");
+        return -1;
+    }
+    av_log(NULL, AV_LOG_DEBUG, "Dynamic params plugin path:"
+        " %s \n", DYN_PARAMS_LIB_NAME);
+
+    enc_dyn_params->xlnx_enc_init_dyn_params_obj = (InitDynParams)
+        dlsym(enc_dyn_params->dyn_params_lib, XLNX_ENC_INIT_DYN_PARAMS_OBJ);
+
+    dlret = dlerror();
+    if(dlret != NULL) {
+        av_log(NULL, AV_LOG_ERROR, "Error loading symbol "
+            "%s from %s plugin: %s\n", XLNX_ENC_INIT_DYN_PARAMS_OBJ,
+            DYN_PARAMS_LIB_NAME, dlret);
+        return -1;
+    }
+
+    /* Initialize the dynamic params function pointers */
+    (*(enc_dyn_params->xlnx_enc_init_dyn_params_obj))(&enc_dyn_params->dyn_params_obj);
+
+    return 0;
+}
+
+static int32_t xlnx_enc_dyn_params_update(mpsoc_vcu_enc_ctx *ctx, XmaFrame *in_frame)
+{
+    EncDynParams *enc_dyn_params = &ctx->enc_dyn_params;
+    uint32_t dyn_frame_num = (*(enc_dyn_params->dyn_params_obj.xlnx_enc_get_dyn_param_frame_num))
+                                (enc_dyn_params->dynamic_param_handle,
+                                enc_dyn_params->dynamic_params_index);
+
+    if (dyn_frame_num == (ctx->enc_frame_cnt)) {
+        if(!ctx->dynamic_gop) {
+            uint32_t num_b_frames = (*(enc_dyn_params->dyn_params_obj.xlnx_enc_get_runtime_b_frames))
+                                    (enc_dyn_params->dynamic_param_handle,
+                                    enc_dyn_params->dynamic_params_index);
+            /* Dynamic b-frames have to be less than or equal to number of B-frames
+            specified on the command line or default value, whichever is set at the
+            beginning of encoding*/
+            if (num_b_frames > ctx->b_frames) {
+                av_log(NULL, AV_LOG_ERROR,
+                "Dynamic B-frames %d at frame num %d cannot be greater than initial number of b-frames (%d)\n",
+                num_b_frames, dyn_frame_num, ctx->b_frames);
+                return -1;
+            }
+        }
+
+        /* If tune-metrics is enabled, then reset all the AQ parameters */
+        if (ctx->tune_metrics) {
+            (*(enc_dyn_params->dyn_params_obj.xlnx_enc_reset_runtime_aq_params))
+                (enc_dyn_params->dynamic_param_handle,
+                enc_dyn_params->dynamic_params_index);
+        }
+
+        if((*(enc_dyn_params->dyn_params_obj.xlnx_enc_add_dyn_params))
+        (enc_dyn_params->dynamic_param_handle, in_frame, enc_dyn_params->dynamic_params_index) != XMA_SUCCESS) {
+            return -1;
+        }
+
+        enc_dyn_params->dynamic_params_index++;
+    }
+    return 0;
+}
+
+static int fill_options_file_h264 (AVCodecContext *avctx)
+{
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+
+	// Initialize default values for expert settings
+	ctx->cpb_size = 2.0;
+	ctx->initial_delay = 1.0;
+	ctx->gop_mode = 0;
+	ctx->gdr_mode = 0;
+	ctx->filler_data = 0;
+	ctx->slice_size = 0;
+	ctx->entropy_mode = 1;
+	ctx->loop_filter = 1;
+	ctx->constrained_intra_pred = 0;
+	ctx->prefetch_buffer = 1;
+	ctx->lookahead_rc_off = 0;
+	ctx->loop_filter_beta_offset = -1;
+	ctx->loop_filter_tc_offset = -1;
+	ctx->ip_delta = -1;
+	ctx->pb_delta = -1;
+	ctx->enc_dyn_params.dynamic_params_check = 0;
+
+	// Parse and store CLI expert settings
+	if (ctx->expert_options != NULL){
+		AVDictionary *dict = NULL;
+		AVDictionaryEntry *entry = NULL;
+
+		if (!av_dict_parse_string(&dict, ctx->expert_options, "=", ":", 0)) {
+			double fval;
+			int ret;
+			// Iterate through all the dictionary entries
+			while ((entry = av_dict_get(dict, "", entry, AV_DICT_IGNORE_SUFFIX))) {
+				if (strcmp(entry->key, "cpb-size") == 0){
+					fval = atof(entry->value);
+					if (fval == 0 && *(entry->value) != '0'){
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is invalid; using default value instead\n", entry->key, entry->value);
+					}
+					else if (fval > 0.0 && fval <= 100){
+						ctx->cpb_size = fval;
+						//printf("EXPERT SETTING: key=%s, value=%f\n", entry->key, ctx->cpb_size);
+					}
+					else
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is out of range, valid range is [0.0 < value <= 100.0]; using default value instead\n", entry->key, entry->value);
+				}
+				else if (strcmp(entry->key, "initial-delay") == 0){
+					fval = atof(entry->value);
+					if (fval == 0 && *(entry->value) != '0'){
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is invalid; using default value instead\n", entry->key, entry->value);
+					}
+					else if (fval >= 0 && fval <= 100){
+						ctx->initial_delay = fval;
+						//printf("Expert setting: key=%s, value=%f\n", entry->key, ctx->initial_delay);
+					}
+					else
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is out of range, valid range is [0 to 100]; using default value instead\n", entry->key, entry->value);
+				}
+				else if (strcmp(entry->key, "gop-mode") == 0){
+					if ((ret = check_expert_value(entry, 0, 3)) > -1){
+						ctx->gop_mode = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->gop_mode);
+					}
+				}
+				else if (strcmp(entry->key, "gdr-mode") == 0){
+					if ((ret = check_expert_value(entry, 0, 2)) > -1){
+						ctx->gdr_mode = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->gdr_mode);
+					}
+				}
+				else if (strcmp(entry->key, "filler-data") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->filler_data = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->filler_data);
+					}
+				}
+				else if (strcmp(entry->key, "slice-size") == 0){
+					if ((ret = check_expert_value(entry, 0, 65535)) > -1){
+						ctx->slice_size = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->slice_size);
+					}
+				}
+				else if (strcmp(entry->key, "entropy-mode") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->entropy_mode = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->entropy_mode);
+					}
+				}
+				else if (strcmp(entry->key, "loop-filter") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->loop_filter = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->loop_filter);
+					}
+				}
+				else if (strcmp(entry->key, "constrained-intra-pred") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->constrained_intra_pred = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->constrained_intra_pred);
+					}
+				}
+				else if (strcmp(entry->key, "prefetch-buffer") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->prefetch_buffer = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->prefetch_buffer);
+					}
+				}
+				else if (strcmp(entry->key, "lookahead-rc-off") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->lookahead_rc_off = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->lookahead_rc_off);
+					}
+				}
+				else if (strcmp(entry->key, "loop-filter-beta-offset") == 0){
+					if ((ret = check_expert_value(entry, -6, 6)) > -7){
+						ctx->loop_filter_beta_offset = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->loop_filter_beta_offset);
+					}
+				}
+				else if (strcmp(entry->key, "loop-filter-tc-offset") == 0){
+					if ((ret = check_expert_value(entry, -6, 6)) > -7){
+						ctx->loop_filter_tc_offset = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->loop_filter_tc_offset);
+					}
+				}
+				else if (strcmp(entry->key, "ip-delta") == 0){
+					if ((ret = check_expert_value(entry, 0, 51)) > -1){
+						ctx->ip_delta = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->ip_delta);
+					}
+				}
+				else if (strcmp(entry->key, "pb-delta") == 0){
+					if ((ret = check_expert_value(entry, 0, 51)) > -1){
+						ctx->pb_delta = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->pb_delta);
+					}
+				}
+                else if (strcmp(entry->key, "dynamic-params") == 0){
+                    struct stat dyn_buffer;
+                    if(stat (entry->value, &dyn_buffer) == 0) {
+                        strcpy(ctx->enc_dyn_params.dynamic_params_file, entry->value);
+                        ctx->enc_dyn_params.dynamic_params_check = 1;
+                        av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%s\n", entry->key, entry->value);
+                    }
+                    else {
+                        av_log(avctx, AV_LOG_ERROR, "EXPERT SETTING: Invalid dynamic params file: %s\n", entry->value);
+                        return AVERROR(EINVAL);
+                    }
+                }
+				else {
+					av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: Expert setting '%s' does not exist, check for spelling mistakes or the naming convention...\n", entry->key);
+                    return AVERROR(EINVAL);
+                }
+			}
+		}
+		av_dict_free(&dict);
+	}
+
+	// Enable Adaptive Quantization by default, if lookahead is enabled
+	if (ctx->lookahead_depth >= 1 && ctx->tune_metrics == 0){
+		ctx->qp_mode = 2;
+	}
+	else if (ctx->lookahead_depth == 0 || ctx->tune_metrics == 1)
+	{
+		if (ctx->temporal_aq)
+		    ctx->temporal_aq = 0;
+
+		if (ctx->spatial_aq)
+		    ctx->spatial_aq = 0;
+	}
+
+	// Tunes video quality for objective scores by setting flat scaling-list and uniform qp-mode
+	if (ctx->tune_metrics){
+		ctx->scaling_list = 0;
+		ctx->qp_mode = 0;
+	}
+
+    if(!ctx->disable_pipeline && ctx->avc_lowlat) {
+        av_log(avctx, AV_LOG_ERROR, "AVC low latency flag is not needed when pipeline is enabled \n");
+        return AVERROR(EINVAL);
+    } else if(ctx->disable_pipeline && !ctx->avc_lowlat) {
+        if(ctx->cores > 1) {
+            av_log(avctx, AV_LOG_ERROR, "More than one core given for with pipeline disabled! Set AVC low latency to allow for multiple cores with pipeline disabled! \n");
+            return AVERROR(EINVAL);
+        }
+        if ((avctx->width > 1920) || (avctx->height > 1920)) {
+            av_log(avctx, AV_LOG_ERROR, "Input is %d x %d, but H264 pipeline is disabled. Set AVC low latency to disable pipelining for higher resolutions \n",
+                   avctx->width, avctx->height);
+            return AVERROR(EINVAL);
+        }
+    }
+
+    const char* RateCtrlMode = "CONST_QP";
+    switch (ctx->control_rate) {
+        case 0: RateCtrlMode = "CONST_QP"; break;
+        case 1: RateCtrlMode = "CBR"; break;
+        case 2: RateCtrlMode = "VBR"; break;
+        case 3: RateCtrlMode = "LOW_LATENCY"; break;
+    }
+
+    char FrameRate[16];
+    sprintf(FrameRate, "%u/%u", avctx->framerate.num, avctx->framerate.den);
+
+    char SliceQP[8];
+    if (ctx->slice_qp == -1)
+        strcpy (SliceQP, "AUTO");
+    else
+        sprintf(SliceQP, "%d", ctx->slice_qp);
+
+    const char* GopCtrlMode = "DEFAULT_GOP";
+    switch (ctx->gop_mode) {
+        case 0: GopCtrlMode = "DEFAULT_GOP"; break;
+        case 1: GopCtrlMode = "PYRAMIDAL_GOP"; break;
+        case 2: GopCtrlMode = "LOW_DELAY_P"; break;
+        case 3: GopCtrlMode = "LOW_DELAY_B"; break;
+    }
+
+    const char* GDRMode = "DISABLE";
+    switch (ctx->gdr_mode) {
+        case 0: GDRMode = "DISABLE"; break;
+        case 1: GDRMode = "GDR_VERTICAL"; break;
+        case 2: GDRMode = "GDR_HORIZONTAL"; break;
+    }
+
+    const char* Profile = "AVC_BASELINE";
+    switch (ctx->profile) {
+        case FF_PROFILE_H264_BASELINE: Profile = "AVC_BASELINE"; break;
+        case FF_PROFILE_H264_MAIN: Profile = "AVC_MAIN"; break;
+        case FF_PROFILE_H264_HIGH: Profile = "AVC_HIGH"; break;
+        case FF_PROFILE_H264_HIGH_10: Profile = "AVC_HIGH10"; break;
+        case FF_PROFILE_H264_HIGH_10_INTRA: Profile = "AVC_HIGH10_INTRA"; break;
+        default:
+            av_log(ctx, AV_LOG_ERROR, "[FFMPEG] ERROR: Invalid H264 codec profile value %d \n", ctx->profile);
+            return AVERROR(EINVAL);
+    }
+
+    const char* Level = "1";
+    switch (ctx->level) {
+        case 10: Level = "1"; break;
+        case 11: Level = "1.1"; break;
+        case 12: Level = "1.2"; break;
+        case 13: Level = "1.3"; break;
+        case 20: Level = "2"; break;
+        case 21: Level = "2.1"; break;
+        case 22: Level = "2.2"; break;
+        case 30: Level = "3"; break;
+        case 31: Level = "3.1"; break;
+        case 32: Level = "3.2"; break;
+        case 40: Level = "4"; break;
+        case 41: Level = "4.1"; break;
+        case 42: Level = "4.2"; break;
+        case 50: Level = "5"; break;
+        case 51: Level = "5.1"; break;
+        case 52: Level = "5.2"; break;
+    }
+
+    const char* QPCtrlMode = "UNIFORM_QP";
+    switch (ctx->qp_mode) {
+        case 0: QPCtrlMode = "UNIFORM_QP"; break;
+        case 1: QPCtrlMode = "AUTO_QP"; break;
+        case 2: QPCtrlMode = "LOAD_QP | RELATIVE_QP"; break;
+    }
+
+    const char* FillerData = "DISABLE";
+    switch (ctx->filler_data) {
+        case 0: FillerData = "DISABLE"; break;
+        case 1: FillerData = "ENABLE"; break;
+    }
+
+    const char* AspectRatio = "ASPECT_RATIO_AUTO";
+    switch (ctx->aspect_ratio) {
+        case 0: AspectRatio = "ASPECT_RATIO_AUTO"; break;
+        case 1: AspectRatio = "ASPECT_RATIO_4_3"; break;
+        case 2: AspectRatio = "ASPECT_RATIO_16_9"; break;
+        case 3: AspectRatio = "ASPECT_RATIO_NONE"; break;
+    }
+
+    const char* ColorSpace = "COLOUR_DESC_UNSPECIFIED";
+    switch (avctx->colorspace) {
+        case AVCOL_SPC_BT709: ColorSpace = "COLOUR_DESC_BT_709"; break;
+        case AVCOL_SPC_UNSPECIFIED: ColorSpace = "COLOUR_DESC_UNSPECIFIED"; break;
+        case AVCOL_SPC_RESERVED: ColorSpace = "COLOUR_DESC_RESERVED"; break;
+        case AVCOL_SPC_BT470BG: ColorSpace = "COLOUR_DESC_BT_470_NTSC"; break;
+        case AVCOL_SPC_SMPTE170M: ColorSpace = "COLOUR_DESC_BT_601_PAL"; break;
+        case AVCOL_SPC_SMPTE240M: ColorSpace = "COLOUR_DESC_BT_601_NTSC"; break;
+        case AVCOL_SPC_BT2020_NCL: ColorSpace = "COLOUR_DESC_BT_2020"; break;
+        case AVCOL_SPC_BT2020_CL: ColorSpace = "COLOUR_DESC_BT_2020"; break;
+    }
+
+    const char* ScalingList = "FLAT";
+    switch (ctx->scaling_list) {
+        case 0: ScalingList = "FLAT"; break;
+        case 1: ScalingList = "DEFAULT"; break;
+    }
+
+    const char* EntropyMode = "MODE_CABAC";
+    switch (ctx->entropy_mode) {
+        case 0: EntropyMode = "MODE_CAVLC"; break;
+        case 1: EntropyMode = "MODE_CABAC"; break;
+    }
+
+    const char* LoopFilter = "ENABLE";
+    switch (ctx->loop_filter) {
+        case 0: LoopFilter = "DISABLE"; break;
+        case 1: LoopFilter = "ENABLE"; break;
+    }
+
+    const char* ConstIntraPred = "DISABLE";
+    switch (ctx->constrained_intra_pred) {
+        case 0: ConstIntraPred = "DISABLE"; break;
+        case 1: ConstIntraPred = "ENABLE"; break;
+    }
+
+    const char* LambdaCtrlMode = "DEFAULT_LDA";
+
+    const char* PrefetchBuffer = "ENABLE";
+    switch (ctx->prefetch_buffer) {
+        case 0: PrefetchBuffer = "DISABLE"; break;
+        case 1: PrefetchBuffer = "ENABLE"; break;
+    }
+
+	av_log(avctx, AV_LOG_DEBUG, "qp-mode = %d \n", ctx->qp_mode);
+	av_log(avctx, AV_LOG_DEBUG, "spatial-aq = %d \n", ctx->spatial_aq);
+	av_log(avctx, AV_LOG_DEBUG, "temporal-aq = %d \n", ctx->temporal_aq);
+
+	// Set IDR period to gop-size, when the user has not specified it on the command line
+	if (ctx->periodicity_idr == -1)
+	{
+		if (avctx->gop_size > 0){
+			ctx->periodicity_idr = avctx->gop_size;
+		}
+		av_log(avctx, AV_LOG_DEBUG, "ctx->periodicity_idr = %d \n", ctx->periodicity_idr);
+	}
+
+	// When lookahead is enabled and user hasn't specified min-qp value, set min-qp to 20 as this gives better R-D performance
+	if (ctx->lookahead_depth > 0 && ctx->min_qp == 0)
+	{
+		ctx->min_qp = 20;
+	}
+
+    const char* Format;
+    if (ctx->bits_per_sample == MPSOC_VCU_BITDEPTH_8BIT)
+        Format = "NV12";
+    else if(ctx->bits_per_sample == MPSOC_VCU_BITDEPTH_10BIT)
+        Format = "NV12_10LE32";
+    else
+        return AVERROR(EINVAL);
+
+    /* For H.264 encoder multi-core with disable pipeline, we need to enable low
+       latency flag in soft kernel */
+    const char* AvcLowLat = "DISABLE";
+    if(ctx->avc_lowlat) {
+        AvcLowLat = "ENABLE";
+    }
+
+    init_hdr10_vui_params();
+    HDR10_VUI_Params* pHDRVUI = get_hdr10_vui_params();
+    sprintf (ctx->enc_options, "[INPUT]\n"
+            "Width = %d\n"
+            "Height = %d\n"
+            "Format = %s\n"
+            "[RATE_CONTROL]\n"
+            "RateCtrlMode = %s\n"
+            "FrameRate = %s\n"
+            "BitRate = %ld\n"
+            "MaxBitRate = %ld\n"
+            "SliceQP = %s\n"
+            "MaxQP = %d\n"
+            "MinQP = %d\n"
+            "IPDelta = %d\n"
+            "PBDelta = %d\n"
+            "CPBSize = %f\n"
+            "InitialDelay = %f\n"
+            "[GOP]\n"
+            "GopCtrlMode = %s\n"
+            "Gop.GdrMode = %s\n"
+            "Gop.Length = %d\n"
+            "Gop.NumB = %d\n"
+            "Gop.FreqIDR = %d\n"
+            "[SETTINGS]\n"
+            "Profile = %s\n"
+            "Level = %s\n"
+            "ChromaMode = CHROMA_4_2_0\n"
+            "BitDepth = %d\n"
+            "NumSlices = %d\n"
+            "QPCtrlMode = %s\n"
+            "SliceSize = %d\n"
+            "EnableFillerData = %s\n"
+            "AspectRatio = %s\n"
+            "ColourDescription = %s\n"
+            "TransferCharac = %s\n"
+            "ColourMatrix = %s\n"
+            "ScalingList = %s\n"
+            "EntropyMode = %s\n"
+            "LoopFilter = %s\n"
+            "LoopFilter.BetaOffset = %d\n"
+            "LoopFilter.TcOffset = %d\n"
+            "ConstrainedIntraPred = %s\n"
+            "LambdaCtrlMode = %s\n"
+            "CacheLevel2 = %s\n"
+            "NumCore = %d\n"
+            "AvcLowLat = %s\n",
+            avctx->width, avctx->height, Format, RateCtrlMode, FrameRate, avctx->bit_rate / 1000,
+            ctx->max_bitrate / 1000, SliceQP, ctx->max_qp, ctx->min_qp, ctx->ip_delta, ctx->pb_delta,
+            ctx->cpb_size, ctx->initial_delay, GopCtrlMode, GDRMode, avctx->gop_size, ctx->b_frames,
+            ctx->periodicity_idr, Profile, Level, ctx->bits_per_sample, ctx->num_slices, QPCtrlMode, ctx->slice_size,
+            FillerData, AspectRatio, pHDRVUI->ColorDesc, pHDRVUI->TxChar, pHDRVUI->ColorMatrix,
+            ScalingList, EntropyMode, LoopFilter, ctx->loop_filter_beta_offset, ctx->loop_filter_tc_offset,
+            ConstIntraPred, LambdaCtrlMode, PrefetchBuffer, ctx->cores, AvcLowLat);
+
+    return 0;
+}
+
+static int fill_options_file_hevc (AVCodecContext *avctx)
+{
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+
+	// Initialize default values for expert settings
+	ctx->cpb_size = 2.0;
+	ctx->initial_delay = 1.0;
+	ctx->gop_mode = 0;
+	ctx->gdr_mode = 0;
+	ctx->filler_data = 0;
+	ctx->dependent_slice = 0;
+	ctx->slice_size = 0;
+	ctx->loop_filter = 1;
+	ctx->constrained_intra_pred = 0;
+	ctx->prefetch_buffer = 1;
+	ctx->lookahead_rc_off = 0;
+	ctx->loop_filter_beta_offset = -1;
+	ctx->loop_filter_tc_offset = -1;
+	ctx->ip_delta = -1;
+	ctx->pb_delta = -1;
+	ctx->enc_dyn_params.dynamic_params_check = 0;
+
+	// Parse and store CLI expert settings
+	if (ctx->expert_options != NULL){
+		AVDictionary *dict = NULL;
+		AVDictionaryEntry *entry = NULL;
+
+		if (!av_dict_parse_string(&dict, ctx->expert_options, "=", ":", 0)) {
+			// Iterate through all the dictionary entries
+			double fval;
+			int ret;
+			while ((entry = av_dict_get(dict, "", entry, AV_DICT_IGNORE_SUFFIX))) {
+				if (strcmp(entry->key, "cpb-size") == 0){
+					fval = atof(entry->value);
+					if (fval == 0 && *(entry->value) != '0'){
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is invalid; using default value instead\n", entry->key, entry->value);
+					}
+					else if (fval > 0.0 && fval <= 100){
+						ctx->cpb_size = fval;
+						//printf("EXPERT SETTING: key=%s, value=%f\n", entry->key, ctx->cpb_size);
+					}
+					else
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is out of range, valid range is [0.0 < value <= 100.0]; using default value instead\n", entry->key, entry->value);
+				}
+				else if (strcmp(entry->key, "initial-delay") == 0){
+					fval = atof(entry->value);
+					if (fval == 0 && *(entry->value) != '0'){
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is invalid; using default value instead\n", entry->key, entry->value);
+					}
+					else if (fval >= 0 && fval <= 100){
+						ctx->initial_delay = fval;
+						//printf("EXPERT SETTING: key=%s, value=%f\n", entry->key, ctx->initial_delay);
+					}
+					else
+						av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: For expert setting %s, value=%s is out of range, valid range is [0 to 100]; using default value instead\n", entry->key, entry->value);
+				}
+				else if (strcmp(entry->key, "gop-mode") == 0){
+					if ((ret = check_expert_value(entry, 0, 3)) > -1){
+						ctx->gop_mode = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->gop_mode);
+					}
+				}
+				else if (strcmp(entry->key, "gdr-mode") == 0){
+					if ((ret = check_expert_value(entry, 0, 2)) > -1){
+						ctx->gdr_mode = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->gdr_mode);
+					}
+				}
+				else if (strcmp(entry->key, "filler-data") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->filler_data = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->filler_data);
+					}
+				}
+				else if (strcmp(entry->key, "dependent-slice") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->dependent_slice = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->dependent_slice);
+					}
+				}
+				else if (strcmp(entry->key, "slice-size") == 0){
+					if ((ret = check_expert_value(entry, 0, 65535)) > -1){
+						ctx->slice_size = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->slice_size);
+					}
+				}
+				else if (strcmp(entry->key, "loop-filter") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->loop_filter = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->loop_filter);
+					}
+				}
+				else if (strcmp(entry->key, "constrained-intra-pred") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->constrained_intra_pred = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->constrained_intra_pred);
+					}
+				}
+				else if (strcmp(entry->key, "prefetch-buffer") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->prefetch_buffer = (int)ret;
+						//printf("EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->prefetch_buffer);
+					}
+				}
+				else if (strcmp(entry->key, "lookahead-rc-off") == 0){
+					if ((ret = check_expert_value(entry, 0, 1)) > -1){
+						ctx->lookahead_rc_off = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->lookahead_rc_off);
+					}
+				}
+				else if (strcmp(entry->key, "loop-filter-beta-offset") == 0){
+					if ((ret = check_expert_value(entry, -6, 6)) > -7){
+						ctx->loop_filter_beta_offset = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->loop_filter_beta_offset);
+					}
+				}
+				else if (strcmp(entry->key, "loop-filter-tc-offset") == 0){
+					if ((ret = check_expert_value(entry, -6, 6)) > -7){
+						ctx->loop_filter_tc_offset = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->loop_filter_tc_offset);
+					}
+				}
+				else if (strcmp(entry->key, "ip-delta") == 0){
+					if ((ret = check_expert_value(entry, 0, 51)) > -1){
+						ctx->ip_delta = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->ip_delta);
+					}
+				}
+				else if (strcmp(entry->key, "pb-delta") == 0){
+					if ((ret = check_expert_value(entry, 0, 51)) > -1){
+						ctx->pb_delta = (int)ret;
+						av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%d\n", entry->key, ctx->pb_delta);
+					}
+				}
+                else if (strcmp(entry->key, "dynamic-params") == 0){
+                    struct stat dyn_buffer;
+                    if(stat (entry->value, &dyn_buffer) == 0) {
+                        strcpy(ctx->enc_dyn_params.dynamic_params_file, entry->value);
+                        ctx->enc_dyn_params.dynamic_params_check = 1;
+                        av_log(avctx, AV_LOG_DEBUG, "EXPERT SETTING: key=%s, value=%s\n", entry->key, entry->value);
+                    }
+                    else {
+                        av_log(avctx, AV_LOG_ERROR, "EXPERT SETTING: Invalid dynamic params file: %s\n", entry->value);
+                        return AVERROR(EINVAL);
+                    }
+                }
+                else {
+					av_log(NULL, AV_LOG_ERROR, "[FFMPEG] ERROR: Expert setting '%s' does not exist, check for spelling mistakes or the naming convention...\n", entry->key);
+                    return AVERROR(EINVAL);
+                }
+			}
+		}
+		av_dict_free(&dict);
+	}
+
+	// Enable Adaptive Quantization by default, if lookahead is enabled
+	if (ctx->lookahead_depth >= 1 && ctx->tune_metrics == 0){
+		ctx->qp_mode = 2;
+	}
+	else if (ctx->lookahead_depth == 0 || ctx->tune_metrics == 1)
+	{
+		if (ctx->temporal_aq)
+		    ctx->temporal_aq = 0;
+
+		if (ctx->spatial_aq)
+		    ctx->spatial_aq = 0;
+	}
+
+	// Tunes video quality for objective scores by setting flat scaling-list and uniform qp-mode
+	if (ctx->tune_metrics){
+		ctx->scaling_list = 0;
+		ctx->qp_mode = 0;
+	}
+
+    const char* RateCtrlMode = "CONST_QP";
+    switch (ctx->control_rate) {
+        case 0: RateCtrlMode = "CONST_QP"; break;
+        case 1: RateCtrlMode = "CBR"; break;
+        case 2: RateCtrlMode = "VBR"; break;
+        case 3: RateCtrlMode = "LOW_LATENCY"; break;
+    }
+
+    char FrameRate[16];
+    sprintf(FrameRate, "%u/%u", avctx->framerate.num, avctx->framerate.den);
+
+    char SliceQP[8];
+    if (ctx->slice_qp == -1)
+        strcpy (SliceQP, "AUTO");
+    else
+        sprintf(SliceQP, "%d", ctx->slice_qp);
+
+    const char* GopCtrlMode = "DEFAULT_GOP";
+    switch (ctx->gop_mode) {
+        case 0: GopCtrlMode = "DEFAULT_GOP"; break;
+        case 1: GopCtrlMode = "PYRAMIDAL_GOP"; break;
+        case 2: GopCtrlMode = "LOW_DELAY_P"; break;
+        case 3: GopCtrlMode = "LOW_DELAY_B"; break;
+    }
+
+    const char* GDRMode = "DISABLE";
+    switch (ctx->gdr_mode) {
+        case 0: GDRMode = "DISABLE"; break;
+        case 1: GDRMode = "GDR_VERTICAL"; break;
+        case 2: GDRMode = "GDR_HORIZONTAL"; break;
+    }
+
+    const char* Profile = "HEVC_MAIN";
+    switch (ctx->profile) {
+        case 0: Profile = "HEVC_MAIN"; break;
+        case 1: Profile = "HEVC_MAIN_INTRA"; break;
+        case 2: Profile = "HEVC_MAIN10"; break;
+        case 3: Profile = "HEVC_MAIN10_INTRA"; break;
+    }
+
+    const char* Level = "1";
+    switch (ctx->level) {
+        case 10: Level = "1"; break;
+        case 20: Level = "2"; break;
+        case 21: Level = "2.1"; break;
+        case 30: Level = "3"; break;
+        case 31: Level = "3.1"; break;
+        case 40: Level = "4"; break;
+        case 41: Level = "4.1"; break;
+        case 50: Level = "5"; break;
+        case 51: Level = "5.1"; break;
+        case 52: Level = "5.2"; break;
+    }
+
+    const char* Tier = "MAIN_TIER";
+    switch (ctx->tier) {
+        case 0: Tier = "MAIN_TIER"; break;
+        case 1: Tier = "HIGH_TIER"; break;
+    }
+
+    const char* QPCtrlMode = "UNIFORM_QP";
+    switch (ctx->qp_mode) {
+        case 0: QPCtrlMode = "UNIFORM_QP"; break;
+        case 1: QPCtrlMode = "AUTO_QP"; break;
+        case 2: QPCtrlMode = "LOAD_QP | RELATIVE_QP"; break;
+    }
+
+    const char* DependentSlice = "FALSE";
+    switch (ctx->dependent_slice) {
+        case 0: DependentSlice = "FALSE"; break;
+        case 1: DependentSlice = "TRUE"; break;
+    }
+
+    const char* FillerData = "DISABLE";
+    switch (ctx->filler_data) {
+        case 0: FillerData = "DISABLE"; break;
+        case 1: FillerData = "ENABLE"; break;
+    }
+
+    const char* AspectRatio = "ASPECT_RATIO_AUTO";
+    switch (ctx->aspect_ratio) {
+        case 0: AspectRatio = "ASPECT_RATIO_AUTO"; break;
+        case 1: AspectRatio = "ASPECT_RATIO_4_3"; break;
+        case 2: AspectRatio = "ASPECT_RATIO_16_9"; break;
+        case 3: AspectRatio = "ASPECT_RATIO_NONE"; break;
+    }
+
+    const char* ColorSpace = "COLOUR_DESC_UNSPECIFIED";
+    switch (avctx->colorspace) {
+        case AVCOL_SPC_BT709: ColorSpace = "COLOUR_DESC_BT_709"; break;
+        case AVCOL_SPC_UNSPECIFIED: ColorSpace = "COLOUR_DESC_UNSPECIFIED"; break;
+        case AVCOL_SPC_RESERVED: ColorSpace = "COLOUR_DESC_RESERVED"; break;
+        case AVCOL_SPC_BT470BG: ColorSpace = "COLOUR_DESC_BT_470_NTSC"; break;
+        case AVCOL_SPC_SMPTE170M: ColorSpace = "COLOUR_DESC_BT_601_PAL"; break;
+        case AVCOL_SPC_SMPTE240M: ColorSpace = "COLOUR_DESC_BT_601_NTSC"; break;
+        case AVCOL_SPC_BT2020_NCL: ColorSpace = "COLOUR_DESC_BT_2020"; break;
+        case AVCOL_SPC_BT2020_CL: ColorSpace = "COLOUR_DESC_BT_2020"; break;
+    }
+
+    const char* ScalingList = "FLAT";
+    switch (ctx->scaling_list) {
+        case 0: ScalingList = "FLAT"; break;
+        case 1: ScalingList = "DEFAULT"; break;
+    }
+
+    const char* LoopFilter = "ENABLE";
+    switch (ctx->loop_filter) {
+        case 0: LoopFilter = "DISABLE"; break;
+        case 1: LoopFilter = "ENABLE"; break;
+    }
+
+    const char* ConstIntraPred = "DISABLE";
+    switch (ctx->constrained_intra_pred) {
+        case 0: ConstIntraPred = "DISABLE"; break;
+        case 1: ConstIntraPred = "ENABLE"; break;
+    }
+
+    const char* LambdaCtrlMode = "DEFAULT_LDA";
+
+    const char* PrefetchBuffer = "ENABLE";
+    switch (ctx->prefetch_buffer) {
+        case 0: PrefetchBuffer = "DISABLE"; break;
+        case 1: PrefetchBuffer = "ENABLE"; break;
+    }
+
+	av_log(avctx, AV_LOG_DEBUG, "qp-mode = %d \n", ctx->qp_mode);
+	av_log(avctx, AV_LOG_DEBUG, "spatial-aq = %d \n", ctx->spatial_aq);
+	av_log(avctx, AV_LOG_DEBUG, "temporal-aq = %d \n", ctx->temporal_aq);
+
+	// Set IDR period to gop-size, when the user has not specified it on the command line
+	if (ctx->periodicity_idr == -1)
+	{
+		if (avctx->gop_size > 0){
+			ctx->periodicity_idr = avctx->gop_size;
+		}
+		av_log(avctx, AV_LOG_DEBUG, "ctx->periodicity_idr = %d \n", ctx->periodicity_idr);
+	}
+
+	// When lookahead is enabled and user hasn't specified min-qp value, set min-qp to 20 as this gives better R-D performance
+	if (ctx->lookahead_depth > 0 && ctx->min_qp == 0)
+	{
+		ctx->min_qp = 20;
+	}
+
+    const char* Format;
+    if (ctx->bits_per_sample == MPSOC_VCU_BITDEPTH_8BIT)
+        Format = "NV12";
+    else if(ctx->bits_per_sample == MPSOC_VCU_BITDEPTH_10BIT)
+        Format = "NV12_10LE32";
+    else
+        return AVERROR(EINVAL);
+
+    init_hdr10_vui_params();
+    HDR10_VUI_Params* pHDRVUI = get_hdr10_vui_params();
+    sprintf (ctx->enc_options, "[INPUT]\n"
+            "Width = %d\n"
+            "Height = %d\n"
+            "Format = %s\n"
+            "[RATE_CONTROL]\n"
+            "RateCtrlMode = %s\n"
+            "FrameRate = %s\n"
+            "BitRate = %ld\n"
+            "MaxBitRate = %ld\n"
+            "SliceQP = %s\n"
+            "MaxQP = %d\n"
+            "MinQP = %d\n"
+            "IPDelta = %d\n"
+            "PBDelta = %d\n"
+            "CPBSize = %f\n"
+            "InitialDelay = %f\n"
+            "[GOP]\n"
+            "GopCtrlMode = %s\n"
+            "Gop.GdrMode = %s\n"
+            "Gop.Length = %d\n"
+            "Gop.NumB = %d\n"
+            "Gop.FreqIDR = %d\n"
+            "[SETTINGS]\n"
+            "Profile = %s\n"
+            "Level = %s\n"
+            "Tier = %s\n"
+            "ChromaMode = CHROMA_4_2_0\n"
+            "BitDepth = %d\n"
+            "NumSlices = %d\n"
+            "QPCtrlMode = %s\n"
+            "SliceSize = %d\n"
+            "DependentSlice = %s\n"
+            "EnableFillerData = %s\n"
+            "AspectRatio = %s\n"
+            "ColourDescription = %s\n"
+            "TransferCharac = %s\n"
+            "ColourMatrix = %s\n"
+            "ScalingList = %s\n"
+            "LoopFilter = %s\n"
+            "LoopFilter.BetaOffset = %d\n"
+            "LoopFilter.TcOffset = %d\n"
+            "ConstrainedIntraPred = %s\n"
+            "LambdaCtrlMode = %s\n"
+            "CacheLevel2 = %s\n"
+            "NumCore = %d\n",
+            avctx->width, avctx->height, Format, RateCtrlMode, FrameRate, avctx->bit_rate / 1000,
+            ctx->max_bitrate / 1000, SliceQP, ctx->max_qp, ctx->min_qp, ctx->ip_delta, ctx->pb_delta,
+            ctx->cpb_size, ctx->initial_delay, GopCtrlMode, GDRMode, avctx->gop_size, ctx->b_frames,
+            ctx->periodicity_idr, Profile, Level, Tier, ctx->bits_per_sample, ctx->num_slices, QPCtrlMode,
+            ctx->slice_size, DependentSlice, FillerData, AspectRatio, pHDRVUI->ColorDesc, pHDRVUI->TxChar, pHDRVUI->ColorMatrix,
+            ScalingList, LoopFilter, ctx->loop_filter_beta_offset, ctx->loop_filter_tc_offset,
+            ConstIntraPred, LambdaCtrlMode, PrefetchBuffer, ctx->cores);
+
+    return 0;
+}
+
+static int _calc_enc_load(xrmContext *xrm_ctx, XmaEncoderProperties *enc_props, int32_t func_id, int32_t *enc_load)
+{
+   char pluginName[XRM_MAX_NAME_LEN];
+
+    xrmPluginFuncParam param;
+    char *err;
+    void *handle;
+    void (*convertXmaPropsToJson)(void* props, char* funcName, char* jsonJob);
+
+    memset(&param, 0, sizeof(xrmPluginFuncParam));
+    handle = dlopen("/opt/xilinx/xrm/plugin/libxmaPropsTOjson.so", RTLD_NOW );
+    if (!handle) {
+        av_log(NULL, AV_LOG_ERROR, "Unable to load libxmaPropsTOjson.so  - %s\n", dlerror());
+        return XMA_ERROR;
+    }
+    dlerror(); /* clear error code */
+
+    convertXmaPropsToJson = dlsym(handle, "convertXmaPropsToJson");
+    if ((err = dlerror()) != NULL) {
+        av_log(NULL, AV_LOG_ERROR, "convertXmaPropsToJson symbol not found\n");
+        return XMA_ERROR;
+    }
+
+    (*convertXmaPropsToJson) (enc_props, "ENCODER",param.input);
+    dlclose(handle);
+
+    strcpy(pluginName, "xrmU30EncPlugin");
+
+    if (xrmExecPluginFunc(xrm_ctx, pluginName, func_id, &param) != XRM_SUCCESS)
+    {
+        av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: encoder plugin function %d, fail to run the function\n", func_id);
+        return XMA_ERROR;
+    }
+    else
+    {
+         *enc_load = atoi((char*)(strtok(param.output, " ")));
+         if (*enc_load <= 0)
+         {
+            av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: encoder plugin function %d, calculated load %d .\n", *enc_load);
+            return XMA_ERROR;
+         }
+         else if (*enc_load > XRM_MAX_CU_LOAD_GRANULARITY_1000000)
+         {
+            av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: encoder plugin function %d, calculated load %d is greater than maximum supported.\n", *enc_load);
+            return XMA_ERROR;
+         }
+    }
+    return 0;
+}
+
+static int _xrm_enc_cuListAlloc(mpsoc_vcu_enc_ctx *ctx, int32_t enc_load, int32_t xrm_reserve_id, XmaEncoderProperties *enc_props)
+{
+    xrmCuListPropertyV2 encode_cu_list_prop;
+    int ret = -1;
+    uint64_t deviceInfoDeviceIndex = 0;
+    uint64_t deviceInfoContraintType = XRM_DEVICE_INFO_CONSTRAINT_TYPE_HARDWARE_DEVICE_INDEX;
+    char* endptr;
+
+    memset(&encode_cu_list_prop, 0, sizeof(xrmCuListPropertyV2));
+    memset(&ctx->encode_cu_list_res, 0, sizeof(xrmCuListResourceV2));
+
+    encode_cu_list_prop.cuNum = 2;
+    strcpy(encode_cu_list_prop.cuProps[0].kernelName, "encoder");
+    strcpy(encode_cu_list_prop.cuProps[0].kernelAlias, "ENCODER_MPSOC");
+    encode_cu_list_prop.cuProps[0].devExcl = false;
+    encode_cu_list_prop.cuProps[0].requestLoad = XRM_PRECISION_1000000_BIT_MASK(enc_load);
+
+    strcpy(encode_cu_list_prop.cuProps[1].kernelName, "kernel_vcu_encoder");
+    encode_cu_list_prop.cuProps[1].devExcl = false;
+    encode_cu_list_prop.cuProps[1].requestLoad = XRM_PRECISION_1000000_BIT_MASK(XRM_MAX_CU_LOAD_GRANULARITY_1000000);
+
+    if ((ctx->lxlnx_hwdev > -1) && (xrm_reserve_id > -1)) //2dev mode launcher
+    {
+        deviceInfoDeviceIndex = ctx->lxlnx_hwdev;
+        encode_cu_list_prop.cuProps[0].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+       encode_cu_list_prop.cuProps[0].poolId = xrm_reserve_id;
+
+        encode_cu_list_prop.cuProps[1].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+       encode_cu_list_prop.cuProps[1].poolId = xrm_reserve_id;
+    }
+    else if (xrm_reserve_id > -1) //1dev mode launcher
+    {
+       encode_cu_list_prop.cuProps[0].poolId = xrm_reserve_id;
+       encode_cu_list_prop.cuProps[1].poolId = xrm_reserve_id;
+    }
+    else if ((ctx->lxlnx_hwdev > -1) || (getenv("XRM_DEVICE_ID")))  //explicit ffmpeg device command
+    {
+       if (ctx->lxlnx_hwdev > -1)
+           deviceInfoDeviceIndex = ctx->lxlnx_hwdev;
+       else
+       {
+           errno=0;
+           deviceInfoDeviceIndex =  strtol(getenv("XRM_DEVICE_ID"), &endptr, 0);
+           if (errno != 0)
+           {
+              av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_DEVICE_ID in encoder plugin\n");
+              return -1;
+           }
+        }
+
+        encode_cu_list_prop.cuProps[0].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+
+        encode_cu_list_prop.cuProps[1].deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+    }
+
+    ret = xrmCuListAllocV2(ctx->xrm_ctx, &encode_cu_list_prop, &ctx->encode_cu_list_res);
+
+    if (ret != 0)
+    {
+        av_log(NULL, AV_LOG_ERROR, "xrm_allocation: failed to allocate encoder cu  from reserve\n");
+        return XMA_ERROR;
+    }
+    else
+    {
+        ctx->encode_res_inuse = true;
+#if 0
+        for (int i = 0; i < ctx->encode_cu_list_res.cuNum; i++) {
+            printf("Allocated encoder cu list: cu %d\n", i);
+            printf("   xclbinFileName is:  %s\n", ctx->encode_cu_list_res.cuResources[i].xclbinFileName);
+            printf("   kernelPluginFileName is:  %s\n", ctx->encode_cu_list_res.cuResources[i].kernelPluginFileName);
+            printf("   kernelName is:  %s\n", ctx->encode_cu_list_res.cuResources[i].kernelName);
+            printf("   kernelAlias is:  %s\n", ctx->encode_cu_list_res.cuResources[i].kernelAlias);
+            printf("   instanceName is:  %s\n", ctx->encode_cu_list_res.cuResources[i].instanceName);
+            printf("   cuName is:  %s\n", ctx->encode_cu_list_res.cuResources[i].cuName);
+            printf("   deviceId is:  %d\n", ctx->encode_cu_list_res.cuResources[i].deviceId);
+            printf("   cuId is:  %d\n", ctx->encode_cu_list_res.cuResources[i].cuId);
+            printf("   channelId is:  %d\n", ctx->encode_cu_list_res.cuResources[i].channelId);
+            printf("   cuType is:  %d\n", ctx->encode_cu_list_res.cuResources[i].cuType);
+            printf("   baseAddr is:  0x%lx\n", ctx->encode_cu_list_res.cuResources[i].baseAddr);
+            printf("   membankId is:  %d\n", ctx->encode_cu_list_res.cuResources[i].membankId);
+            printf("   membankType is:  %d\n", ctx->encode_cu_list_res.cuResources[i].membankType);
+            printf("   membankSize is:  0x%lx\n", ctx->encode_cu_list_res.cuResources[i].membankSize);
+            printf("   membankBaseAddr is:  0x%lx\n", ctx->encode_cu_list_res.cuResources[i].membankBaseAddr);
+            printf("   allocServiceId is:  %lu\n", ctx->encode_cu_list_res.cuResources[i].allocServiceId);
+            printf("   poolId is:  %lu\n", ctx->encode_cu_list_res.cuResources[i].poolId);
+            printf("   channelLoad is:  %d\n", ctx->encode_cu_list_res.cuResources[i].channelLoad);
+        }
+#endif
+    }
+
+    //Set XMA plugin SO and device index
+    enc_props->plugin_lib = ctx->encode_cu_list_res.cuResources[0].kernelPluginFileName;
+    enc_props->dev_index = ctx->encode_cu_list_res.cuResources[0].deviceId;
+    enc_props->ddr_bank_index = -1;//XMA to select the ddr bank based on xclbin meta data
+    enc_props->cu_index = ctx->encode_cu_list_res.cuResources[1].cuId;
+    enc_props->channel_id = ctx->encode_cu_list_res.cuResources[1].channelId;
+
+    return 0;
+}
+
+static int  _allocate_xrm_enc_cu(mpsoc_vcu_enc_ctx *ctx, XmaEncoderProperties *enc_props)
+{
+    int xrm_reserve_id = -1;
+    int ret =-1;
+    char* endptr;
+
+    //create XRM local context
+    ctx->xrm_ctx = (xrmContext *)xrmCreateContext(XRM_API_VERSION_1);
+    if (ctx->xrm_ctx == NULL)
+    {
+        av_log(NULL, AV_LOG_ERROR, "create local XRM context failed\n");
+        return XMA_ERROR;
+    }
+
+    //XRM encoder plugin load calculation
+    int func_id = 0, enc_load=0;
+    ret = _calc_enc_load(ctx->xrm_ctx, enc_props, func_id, &enc_load);
+    if (ret < 0) return ret;
+
+    if (getenv("XRM_RESERVE_ID"))
+    {
+       errno=0;
+       xrm_reserve_id =  strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);
+       if (errno != 0)
+       {
+          av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_RESERVE_ID in encoder plugin\n");
+          return -1;
+       }
+    }
+
+    ret = _xrm_enc_cuListAlloc(ctx, enc_load, xrm_reserve_id, enc_props);
+    if (ret < 0) return ret;
+
+    av_log(NULL, AV_LOG_DEBUG, "---encoder xrm out: enc_load=%d, plugin=%s, device=%d, cu=%d, ch=%d\n",
+    enc_load, enc_props->plugin_lib, enc_props->dev_index, enc_props->cu_index, enc_props->channel_id );
+
+    return ret;
+}
+
+
+
+static av_cold int mpsoc_vcu_encode_init(AVCodecContext *avctx)
+{
+    XmaEncoderProperties enc_props;
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+
+    if ((avctx->width > MAX_ENC_WIDTH) || (avctx->height > MAX_ENC_WIDTH) ||
+        ((avctx->width * avctx->height) > MAX_ENC_PIXELS)) {
+        av_log(avctx, AV_LOG_ERROR, "input resolution %dx%d exceeds maximum supported resolution (%dx%d)\n",
+               avctx->width, avctx->height, MAX_ENC_WIDTH, MAX_ENC_HEIGHT);
+        return AVERROR(EINVAL);
+    }
+
+    if (ctx->dynamic_gop) {
+        if (ctx->b_frames != UNSET_NUM_B_FRAMES) {
+            av_log(avctx, AV_LOG_ERROR, "B-Frames set as %d, but dynamic GOP is enabled! Dynamic GOP cannot be enabled "
+                   "with a set number of B-Frames!\n", ctx->b_frames);
+            return AVERROR(EINVAL);
+        }
+        if (ctx->lookahead_depth == 0) {
+            av_log(avctx, AV_LOG_WARNING, "Dynamic gop enabled, setting lookahead depth to %d\n", DYNAMIC_GOP_MIN_LOOKAHEAD_DEPTH);
+            ctx->lookahead_depth = DYNAMIC_GOP_MIN_LOOKAHEAD_DEPTH;
+        } else if (ctx->lookahead_depth < DYNAMIC_GOP_MIN_LOOKAHEAD_DEPTH) {
+            av_log(avctx, AV_LOG_ERROR, "Dynamic GOP enabled, but lookahead depth is %d! Lookahead depth must be at least %d "
+                   "to run dynamic GOP!\n", ctx->lookahead_depth, DYNAMIC_GOP_MIN_LOOKAHEAD_DEPTH);
+            return AVERROR(EINVAL);
+        }
+        if (ctx->disable_pipeline) {
+            av_log(avctx, AV_LOG_ERROR, "Encoder pipeline is disabled, but dynamic GOP is enabled! Encoder pipelining "
+                   "cannot be disabled with dynamic GOP!\n");
+            return AVERROR(EINVAL);
+        }
+        if ((ctx->profile == FF_PROFILE_H264_BASELINE) || (ctx->profile == FF_PROFILE_H264_HIGH_10_INTRA) ||
+           (ctx->profile == 1) || (ctx->profile == 3)) { // 1 - HEVC_MAIN_INTRA, 3 - HEVC_MAIN10_INTRA
+            av_log(avctx, AV_LOG_ERROR, "Encoder profile is I and/or P only, enabling dynamic GOP results in incorrect "
+                   "delta QPs \n");
+            return AVERROR(EINVAL);
+        }
+    }
+    if(ctx->disable_pipeline) {
+        if(ctx->b_frames == UNSET_NUM_B_FRAMES) {
+            av_log(avctx, AV_LOG_WARNING, "Pipeline disabled, setting B-Frames to 0\n");
+            ctx->b_frames = 0;
+        } else if(ctx->b_frames != 0) {
+            av_log(avctx, AV_LOG_ERROR, "Pipeline cannot be disabled when encoding b-frames! "
+                   "Change encoder parameters to encode only I and P frames. Ie -bf 0\n");
+            return AVERROR(EINVAL);
+        }
+        float fps = (avctx->framerate.num + 0.0) / avctx->framerate.den;
+        if(avctx->width * avctx->height == MAX_ENC_PIXELS && fps > 30.0) {
+            av_log(avctx, AV_LOG_WARNING, "Performance may not run at realtime past 4k 30 fps with encoder pipeline disabled!\n");
+        }
+    }
+    /* For dynamic gop, we let b-frames to use default b-frames. This caps the number of
+    b-frames dynamic gop can choose. */
+    ctx->b_frames = ctx->b_frames == UNSET_NUM_B_FRAMES ? DEFAULT_NUM_B_FRAMES : ctx->b_frames;
+    if (avctx->gop_size < 0) {
+      av_log(avctx, AV_LOG_ERROR, "The group of picture (GOP) size should be greater than or equal to 0 \n");
+      return AVERROR(ENOTSUP);
+    }
+    if ((ctx->lookahead_depth > avctx->gop_size) || ((ctx->periodicity_idr >= 0) && (ctx->lookahead_depth > ctx->periodicity_idr))) {
+        av_log(avctx, AV_LOG_ERROR,
+	"Error : mpsoc_vcu_encode_frame : Invalid arguments. gop size(%d)/IDR period(%d) must be greater than lookahead_depth(%d)\n",
+	avctx->gop_size, ctx->periodicity_idr, ctx->lookahead_depth);
+        return AVERROR(EINVAL);
+    }
+
+    if((avctx->pix_fmt == AV_PIX_FMT_NV12) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_8)){
+        ctx->bits_per_sample = MPSOC_VCU_BITDEPTH_8BIT;
+    } else if((avctx->pix_fmt == AV_PIX_FMT_XV15) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_10)){
+        ctx->bits_per_sample = MPSOC_VCU_BITDEPTH_10BIT;
+    } else {
+        av_log(avctx, AV_LOG_ERROR,
+               "Unsupported input pixel format! format %s\n",
+               av_pix_fmt_desc_get(avctx->pix_fmt)->name);
+        return AVERROR(ENOTSUP);
+    }
+    if ((ctx->bits_per_sample != MPSOC_VCU_BITDEPTH_8BIT) &&
+        (ctx->bits_per_sample != MPSOC_VCU_BITDEPTH_10BIT)) {
+      av_log(avctx, AV_LOG_ERROR,
+             "Unsupported input pixel format! bpp: %d format %s\n",
+             ctx->bits_per_sample, av_pix_fmt_desc_get(avctx->pix_fmt)->name);
+      return AVERROR(ENOTSUP);
+    }
+    enc_props.format = ctx->bits_per_sample == MPSOC_VCU_BITDEPTH_8BIT ? XMA_VCU_NV12_FMT_TYPE : XMA_VCU_NV12_10LE32_FMT_TYPE;
+
+    if (avctx->gop_size > 1000) {
+        av_log(avctx, AV_LOG_ERROR, "GOP size cannot be greater than 1000 \n");
+        return AVERROR(EINVAL);
+    }
+
+    int ret;
+    if (avctx->codec_id == AV_CODEC_ID_H264)
+    {
+        ret = fill_options_file_h264 (avctx);
+    }
+    else if (avctx->codec_id == AV_CODEC_ID_HEVC) {
+        ret = fill_options_file_hevc (avctx);
+    } else {
+        av_log(NULL, AV_LOG_ERROR, "Unknown codec id!\n");
+        ret = AVERROR_ENCODER_NOT_FOUND;
+    }
+    if (ret)
+        return ret;
+
+    if(ctx->enc_dyn_params.dynamic_params_check) {
+        if(xlnx_load_dyn_params_lib(&ctx->enc_dyn_params)) {
+            return AVERROR_EXIT;
+        }
+        ctx->enc_dyn_params.dynamic_param_handle = (DynparamsHandle)(*(ctx->enc_dyn_params.dyn_params_obj.xlnx_enc_get_dyn_params))
+                                   (ctx->enc_dyn_params.dynamic_params_file, &ctx->enc_dyn_params.dynamic_params_count);
+        if(ctx->enc_dyn_params.dynamic_param_handle == NULL) {
+            return AVERROR_EXIT;
+        }
+    }
+
+    enc_props.hwencoder_type = XMA_MULTI_ENCODER_TYPE;
+    strcpy(enc_props.hwvendor_string, "MPSoC");
+
+    enc_props.bits_per_pixel = ctx->bits_per_sample;
+    enc_props.param_cnt = 0;
+    enc_props.params = ctx->enc_params;
+    enc_props.width = avctx->width;
+    enc_props.height = avctx->height;
+
+	// Enable custom rate control when rate control is set to CBR and lookahead is set, disable when expert option lookahead-rc-off is set.
+	if (ctx->control_rate == 1 && ctx->lookahead_depth > 1 && ctx->lookahead_rc_off == 0){
+		ctx->rate_control_mode = 1;
+	}
+	else if (ctx->control_rate == 1 && ctx->lookahead_depth > 1 && ctx->lookahead_rc_off == 1){
+		ctx->rate_control_mode = 0;
+	}
+
+    if (ctx->rate_control_mode && ctx->filler_data) {
+        av_log (ctx, AV_LOG_ERROR, "Encoder does not support filler-data, when Lookahead rate control is enabled.\n"
+                "Please check options : lookahead_depth=%d, lookahead-rc-off=%d, filler-data=%d\n",
+                ctx->lookahead_depth, ctx->lookahead_rc_off, ctx->filler_data);
+        return XMA_ERROR;
+    }
+
+    enc_props.rc_mode =  ctx->rate_control_mode;
+
+    switch(enc_props.rc_mode) {
+      case 0 : av_log(avctx, AV_LOG_INFO, "Custom Rate Control Mode is Disabled\n");
+               break;
+      case 1 : if (ctx->lookahead_depth < MIN_LOOKAHEAD_DEPTH ||
+                   ctx->lookahead_depth > MAX_LOOKAHEAD_DEPTH) {
+                 av_log(avctx, AV_LOG_ERROR, "Error: Provided LA Depth %d is invalid !\n", ctx->lookahead_depth);
+                 av_log(avctx, AV_LOG_ERROR, "To enable lookahead based Custom Rate Control: %d < lookahead_depth < %d\n",
+                        MIN_LOOKAHEAD_DEPTH, MAX_LOOKAHEAD_DEPTH);
+                 return AVERROR(EINVAL);
+               } else {
+                 enc_props.lookahead_depth = ctx->lookahead_depth;
+               }
+               av_log(avctx, AV_LOG_INFO, "#### Custom Rate Control Mode is Enabled with LA Depth = %d ####\n", enc_props.lookahead_depth);
+               break;
+      default: enc_props.rc_mode = 0;
+               av_log(avctx, AV_LOG_INFO, "Rate Control Mode is default\n");
+               break;
+    }
+
+	// Check for valid number of b-frames in different gop-modes
+	switch(ctx->gop_mode){
+		case 0: if (ctx->b_frames < 0 || ctx->b_frames > 4){
+		           av_log(avctx, AV_LOG_ERROR, "Error: For gop-mode = default_gop(0), supported number of b-frames is between 0 and 4\n");
+		           return AVERROR(EINVAL);
+			   } else
+			       break;
+	    case 1: if (!(ctx->b_frames == 3 || ctx->b_frames == 5 || ctx->b_frames ==7 || ctx->b_frames == 15 )){
+		           av_log(avctx, AV_LOG_ERROR, "Error: For gop-mode = pyramidal-gop(1), supported number of b-frames is 3, 5, 7 or 15 \n");
+			       return AVERROR(EINVAL);
+			   } else
+			       break;
+	}
+
+	// Check if gop-mode=low_delay_p or low_delay_b, when GDR mode is enabled
+	if ((ctx->gdr_mode == 1 || ctx->gdr_mode == 2) && (ctx->gop_mode == 0 || ctx->gop_mode == 1)){
+		av_log(avctx, AV_LOG_ERROR, "Error: When gdr-mode = vertical (1) or horizontal(2) is enabled, gop-mode should be set to low_delay_p or low_delay_b \n");
+		return AVERROR(EINVAL);
+	}
+
+	// Check if b-frames=0 when control_rate = low_latency(3)
+	if (ctx->control_rate == 3 && ctx->b_frames != 0){
+		av_log(avctx, AV_LOG_ERROR, "Error: For control_rate = low_latency(3), number of b-frames should be set to 0 \n");
+		return AVERROR(EINVAL);
+	}
+
+    enc_props.framerate.numerator   = avctx->framerate.num;
+    enc_props.framerate.denominator = avctx->framerate.den;
+    ctx->frame.frame_props.format   = enc_props.format;
+    ctx->frame.frame_props.width    = FFALIGN(avctx->width, VCU_STRIDE_ALIGN);
+    ctx->frame.frame_props.height   = FFALIGN(avctx->height, VCU_HEIGHT_ALIGN);
+    ctx->frame.frame_props.bits_per_pixel = ctx->bits_per_sample;
+
+    const char* enc_options = ctx->enc_options;
+    if ((avctx->pix_fmt == AV_PIX_FMT_XVBM_8) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_10)) {
+        ctx->frame.data[0].buffer_type = XMA_DEVICE_BUFFER_TYPE;
+    } else {
+        ctx->frame.data[0].buffer_type = XMA_HOST_BUFFER_TYPE;
+    }
+    ctx->enc_params[enc_props.param_cnt].name   = "enc_options";
+    ctx->enc_params[enc_props.param_cnt].type   = XMA_STRING;
+    ctx->enc_params[enc_props.param_cnt].length = strlen(ctx->enc_options);
+    ctx->enc_params[enc_props.param_cnt].value  = &(enc_options);
+    enc_props.param_cnt++;
+
+    ctx->enc_params[enc_props.param_cnt].name   = "latency_logging";
+    ctx->enc_params[enc_props.param_cnt].type   = XMA_UINT32;
+    ctx->enc_params[enc_props.param_cnt].length = sizeof(ctx->latency_logging);
+    ctx->enc_params[enc_props.param_cnt].value  = &(ctx->latency_logging);
+    enc_props.param_cnt++;
+
+    ctx->enc_params[enc_props.param_cnt].name   = "disable_pipeline";
+    ctx->enc_params[enc_props.param_cnt].type   = XMA_UINT32;
+    ctx->enc_params[enc_props.param_cnt].length = sizeof(ctx->disable_pipeline);
+    ctx->enc_params[enc_props.param_cnt].value  = &(ctx->disable_pipeline);
+    enc_props.param_cnt++;
+
+    if (!avctx->extradata_size) {
+        /* will be freed by ffmpeg */
+        avctx->extradata = av_mallocz(MAX_EXTRADATA_SIZE);
+        if (avctx->extradata) {
+          ctx->enc_params[enc_props.param_cnt].name   = "extradata";
+          ctx->enc_params[enc_props.param_cnt].type   = XMA_STRING;
+          ctx->enc_params[enc_props.param_cnt].length = MAX_EXTRADATA_SIZE;
+          ctx->enc_params[enc_props.param_cnt].value  = &(avctx->extradata);
+          enc_props.param_cnt++;
+
+          /* let xma plugin assign the size of valid extradata */
+          ctx->enc_params[enc_props.param_cnt].name   = "extradata_size";
+          ctx->enc_params[enc_props.param_cnt].type   = XMA_UINT32;
+          ctx->enc_params[enc_props.param_cnt].length = 0;
+          ctx->enc_params[enc_props.param_cnt].value  = &(avctx->extradata_size);
+          enc_props.param_cnt++;
+        }
+    }
+
+    ctx->sent_flush = false;
+
+    ctx->la = NULL;
+    if(init_la(avctx)) {
+        av_log(avctx, AV_LOG_ERROR, "Error: Unable to init_la Invalid params\n");
+        return AVERROR(EINVAL);
+    }
+    ctx->la_in_frame = NULL;
+
+    uint32_t enableHwInBuf = 0;
+    if ((avctx->pix_fmt == AV_PIX_FMT_XVBM_8) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_10) ||
+        (xlnx_la_in_bypass_mode(ctx->la) == 0)) {
+        enableHwInBuf = 1;
+    }
+    ctx->enc_params[enc_props.param_cnt].name   = "enable_hw_in_buf";
+    ctx->enc_params[enc_props.param_cnt].type   = XMA_UINT32;
+    ctx->enc_params[enc_props.param_cnt].length = sizeof(enableHwInBuf);
+    ctx->enc_params[enc_props.param_cnt].value  = &enableHwInBuf;
+    enc_props.param_cnt++;
+    /*----------------------------------------------------
+      Allocate encoder resource from XRM reserved resource
+      ----------------------------------------------------*/
+    ctx->encode_res_inuse = false;
+    if(_allocate_xrm_enc_cu(ctx, &enc_props) < 0) {
+            av_log(ctx, AV_LOG_ERROR, "xrm_allocation: resource allocation failed\n");
+            return XMA_ERROR;
+    }
+
+    ctx->enc_session = xma_enc_session_create(&enc_props);
+    if (!ctx->enc_session)
+        return mpsoc_report_error(ctx, "ERROR: Unable to allocate MPSoC encoder session", AVERROR_EXTERNAL);
+
+    /* TODO:temporary workaround for 4K HEVC MP4, not decodable by VCU decoder.
+     * When size is 0, ffmpeg will not consider the already populated extradata */
+    if (avctx->codec_id == AV_CODEC_ID_HEVC)
+      avctx->extradata_size = 0;
+
+    if (!avctx->extradata_size)
+      av_log(avctx, AV_LOG_WARNING, "! output stream might not be playable by some media players !\n");
+
+    ctx->pts_0 = AV_NOPTS_VALUE;
+    ctx->pts_1 = AV_NOPTS_VALUE;
+    ctx->is_first_outframe = 1;
+    ctx->enc_frame_cnt = 0;
+
+    // TODO: find a proper way to find pts_queue size
+    ctx->pts_queue = av_fifo_alloc(64 * sizeof(int64_t));
+    if (!ctx->pts_queue)
+        return mpsoc_report_error(ctx, "out of memory", AVERROR(ENOMEM));
+    // The max encoded frame size should be less than the raw video frame.
+    // Keeping it same for 8-bit and 10-bit channels
+    ctx->out_packet_size = (avctx->width * avctx->height * 3) >> 1;
+    return 0;
+}
+
+static void vcu_enc_free_out_buffer(void *opaque, uint8_t *data)
+{
+    /*do nothing, if this CB is not provided, ffmpeg tries to free xrt buffer */
+}
+
+int vcu_alloc_ff_packet(mpsoc_vcu_enc_ctx *ctx, AVPacket *pkt)
+{
+    pkt->buf = av_buffer_create(ctx->xma_buffer.data.buffer, pkt->size, vcu_enc_free_out_buffer,  NULL,
+                                AV_GET_BUFFER_FLAG_REF);
+    if (!pkt->buf)
+        return mpsoc_report_error(ctx, "out of memory", AVERROR(ENOMEM));
+
+    pkt->data = ctx->xma_buffer.data.buffer;
+    pkt->size = pkt->size;
+    if(!pkt->size)
+        return mpsoc_report_error(ctx, "invalid pkt size", AVERROR(ENOMEM));
+    return 0;
+}
+
+static XmaFrame* xframe_from_avframe(const AVFrame *pic, AVCodecContext *avctx)
+{
+    XmaFrameProperties *frame_props = NULL;
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+    int32_t num_planes = 0;
+
+    if (pic == NULL) {
+        return NULL;
+    }
+    XmaFrame *frame = (XmaFrame*) calloc(1, sizeof(XmaFrame));
+    if (frame == NULL) {
+        return NULL;
+    }
+
+    memset(frame, 0, sizeof(XmaFrame));
+    frame_props = &frame->frame_props;
+
+    frame_props->width  = pic->width;
+    frame_props->height = pic->height;
+    frame_props->bits_per_pixel = ctx->bits_per_sample;
+    frame_props->format = frame_props->bits_per_pixel == MPSOC_VCU_BITDEPTH_8BIT ? XMA_VCU_NV12_FMT_TYPE : XMA_VCU_NV12_10LE32_FMT_TYPE;
+    num_planes = av_pix_fmt_count_planes(pic->format);
+
+    for (int32_t i = 0; i < num_planes; i++) {
+        frame->data[i].refcount++;
+        frame->data[i].buffer_type = XMA_HOST_BUFFER_TYPE;
+
+        frame->data[i].is_clone = true;
+        frame->data[i].xma_device_buf = NULL;
+        frame->data[i].buffer = NULL;
+    }
+
+    return frame;
+}
+
+static int mpsoc_vcu_enc_flush_frame(AVCodecContext *avctx, AVPacket *pkt, const AVFrame *pic, int *got_packet)
+{
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+    int recv_size = 0;
+    int ret;
+    ctx->frame.is_last_frame = 1;
+    if (ctx->sent_flush == false) {
+        ctx->sent_flush = true;
+        ctx->frame.pts = -1;
+        ret = xma_enc_session_send_frame(ctx->enc_session, &ctx->frame);
+        if (ret != XMA_SUCCESS && ret != XMA_FLUSH_AGAIN) {
+            return ret;
+        }
+        if (ret == XMA_FLUSH_AGAIN) {
+            ctx->sent_flush = false; //force flush to clear pipeline in next iteration
+        }
+    }
+
+    // Allocate ouput data packet
+    if (pkt->data == NULL) {
+        // min_size should be less than half of out_packet_size, for re-use of buffers
+        ret = ff_alloc_packet(avctx, pkt, ctx->out_packet_size);
+        if (ret < 0) {
+            av_log(NULL, AV_LOG_ERROR, "ERROR: Failed to allocate ff_packet\n");
+            return ret;
+        }
+        ctx->xma_buffer.data.buffer = pkt->data;
+        ctx->xma_buffer.alloc_size = ctx->out_packet_size;
+    }
+
+    ret = xma_enc_session_recv_data(ctx->enc_session, &(ctx->xma_buffer), &recv_size);
+    if (ret != XMA_SUCCESS || recv_size == 0) {
+        *got_packet = 0;
+        return ret;
+    }
+
+    pkt->size = recv_size;
+    pkt->pts = ctx->xma_buffer.pts;
+    mpsoc_vcu_encode_prepare_out_timestamp(avctx, pkt);
+    pkt->flags |= ((avctx->codec_id == AV_CODEC_ID_H264) ?
+                    mpsoc_encode_is_h264_idr(pkt) :
+                    mpsoc_encode_is_hevc_idr(pkt)) ? AV_PKT_FLAG_KEY : 0;
+    *got_packet = 1;
+    return ret;
+}
+
+static int mpsoc_vcu_encode_frame(AVCodecContext *avctx, AVPacket *pkt, const AVFrame *pic, int *got_packet)
+{
+    mpsoc_vcu_enc_ctx *ctx = avctx->priv_data;
+    int recv_size, ret;
+    XmaFrame *la_in_frame = NULL;
+    XmaFrame *enc_in_frame = NULL;
+    *got_packet = 0;
+    recv_size = 0;
+
+    if (pic && pic->data) {
+        if ((avctx->pix_fmt == AV_PIX_FMT_XVBM_8) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_10)) {
+            if (ctx->la_in_frame == NULL) {
+                ctx->la_in_frame = (XmaFrame*) calloc(1, sizeof(XmaFrame));
+                if (ctx->la_in_frame == NULL)
+                    return mpsoc_report_error(ctx, "Error: mpsoc_vcu_encode_frame OOM failed!!", AVERROR(EIO));
+            }
+            la_in_frame = ctx->la_in_frame;
+            XmaSideDataHandle *side_data = la_in_frame->side_data;
+            memcpy (la_in_frame, pic->data[0], sizeof (XmaFrame));
+            la_in_frame->side_data = side_data;
+
+	        if (!la_in_frame->data[0].buffer)
+                return mpsoc_report_error(ctx, "Error: invalid input buffer to encode", AVERROR(EIO));
+            xvbm_buffer_refcnt_inc(la_in_frame->data[0].buffer);
+            la_in_frame->pts = pic->pts;
+            mpsoc_vcu_encode_queue_pts(ctx->pts_queue, la_in_frame->pts);
+        } else {
+            if (ctx->la_in_frame == NULL) {
+                ctx->la_in_frame = xframe_from_avframe(pic, avctx);
+                if (ctx->la_in_frame == NULL)
+                    return mpsoc_report_error(ctx, "Error: mpsoc_vcu_encode_frame OOM failed!!", AVERROR(EIO));
+            }
+
+            la_in_frame = ctx->la_in_frame;
+            XmaFrameProperties* la_in_fprops = &la_in_frame->frame_props;
+            for (int plane_id = 0; plane_id < av_pix_fmt_count_planes (pic->format); plane_id++) {
+                la_in_frame->data[plane_id].buffer = pic->data[plane_id];
+                la_in_fprops->linesize[plane_id] = pic->linesize[plane_id]; // need this as at sometimes changes from one frame to another
+            }
+            la_in_frame->pts = pic->pts;
+            mpsoc_vcu_encode_queue_pts(ctx->pts_queue, la_in_frame->pts);
+        }
+
+        if(pic->side_data){
+	    // Check for HDR side data in AVFrame and transfer it to XMAFrame
+            AVFrameSideData *avframe_sidedata = av_frame_get_side_data(pic, AV_FRAME_XLNX_HDR_SIDEBAND_DATA);
+            if (avframe_sidedata)
+            {
+                uint8_t *sd_ptr = (uint8_t*)avframe_sidedata->data;
+                size_t  sd_size = avframe_sidedata->size;
+                XmaSideDataHandle hdr_sd = xma_side_data_alloc(sd_ptr, XMA_FRAME_HDR, sd_size, 0);
+                if(hdr_sd == NULL) {
+                    return mpsoc_report_error(ctx, "Error: HDR side data alloc failed!!", AVERROR(EIO));
+                }
+                xma_frame_add_side_data(ctx->la_in_frame, hdr_sd);
+                xma_side_data_dec_ref(hdr_sd);
+                av_frame_remove_side_data(pic, AV_FRAME_XLNX_HDR_SIDEBAND_DATA);
+            }
+        }
+
+        if (ctx->pts_0 == AV_NOPTS_VALUE)
+            ctx->pts_0 = la_in_frame->pts;
+        else if (ctx->pts_1 == AV_NOPTS_VALUE)
+            ctx->pts_1 = la_in_frame->pts;
+
+        la_in_frame->is_idr = 0;
+        /* Set frame to be encoded as IDR, if picture type is INTRA */
+        if(pic->pict_type == AV_PICTURE_TYPE_I) {
+            la_in_frame->is_idr = 1;
+        }
+
+        /* Check if dynamic encoder parameters are present and add them as frame side data */
+        if((ctx->enc_dyn_params.dynamic_params_count > 0) &&
+            (ctx->enc_dyn_params.dynamic_params_index < ctx->enc_dyn_params.dynamic_params_count)) {
+            if(xlnx_enc_dyn_params_update(ctx, la_in_frame)) {
+                return AVERROR_EXIT;
+            }
+        }
+    }
+
+    if (la_in_frame && la_in_frame->data[0].buffer == NULL) {
+        la_in_frame->is_last_frame = 1;
+    }
+    ret = xlnx_la_send_recv_frame(ctx->la, la_in_frame, &enc_in_frame);
+    if (ret <= XMA_ERROR) {
+        if ((avctx->pix_fmt == AV_PIX_FMT_XVBM_8) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_10)) {
+            XvbmBufferHandle handle = (XvbmBufferHandle)(la_in_frame->data[0].buffer);
+            if (handle) {
+                xvbm_buffer_pool_entry_free(handle);
+            }
+	}
+        return mpsoc_report_error(ctx, "Error: mpsoc_vcu_encode_frame xlnx_la_send_recv_frame failed!!", AVERROR(EIO));
+    } else if ((ret == XMA_SEND_MORE_DATA) && (la_in_frame && la_in_frame->data[0].buffer != NULL)) {
+        goto end;
+    }
+    if (enc_in_frame && enc_in_frame->data[0].buffer) {
+        ret = xma_enc_session_send_frame(ctx->enc_session, enc_in_frame);
+        if (enc_in_frame) {
+            if (ret == XMA_ERROR) {
+                XvbmBufferHandle xvbm_handle = (XvbmBufferHandle)(enc_in_frame->data[0].buffer);
+                if (xvbm_handle) {
+                    xvbm_buffer_pool_entry_free(xvbm_handle);
+                }
+            }
+            xlnx_la_release_frame(ctx->la, enc_in_frame);
+            enc_in_frame = NULL;
+        }
+        if(ret == XMA_SEND_MORE_DATA) {
+            goto end;
+        }
+        if (ret == XMA_SUCCESS) {
+            while (1) {
+                // Allocate ouput data packet
+                if (pkt->data == NULL) {
+                    // min_size should be less than half of out_packet_size, for re-use of buffers
+                    ret = ff_alloc_packet(avctx, pkt, ctx->out_packet_size);
+                    if (ret < 0) {
+                        av_log(NULL, AV_LOG_ERROR, "ERROR: Failed to allocate ff_packet\n");
+                        return ret;
+                    }
+                    ctx->xma_buffer.data.buffer = pkt->data;
+                    ctx->xma_buffer.alloc_size = ctx->out_packet_size;
+                }
+
+                ret = xma_enc_session_recv_data(ctx->enc_session, &(ctx->xma_buffer), &recv_size);
+                if (ret == XMA_SUCCESS) {
+                    if (recv_size == 0) {
+                        *got_packet = 0;
+                        goto end;
+                    }
+                    pkt->size = recv_size;
+                    /* valid data received */
+                    *got_packet = 1;
+                    pkt->pts = ctx->xma_buffer.pts;
+                    mpsoc_vcu_encode_prepare_out_timestamp (avctx, pkt);
+                    pkt->flags |= ((avctx->codec_id == AV_CODEC_ID_H264) ? mpsoc_encode_is_h264_idr (pkt) : mpsoc_encode_is_hevc_idr (pkt)) ? AV_PKT_FLAG_KEY : 0;
+                    break;
+                } else if (ret == XMA_TRY_AGAIN) {
+                    if (pic && pic->data) {
+                        /* vcu not ready with an output buffer */
+                        *got_packet = 0;
+                        goto end;
+                    } else {
+                        ret = xlnx_la_send_recv_frame(ctx->la, NULL, &enc_in_frame);
+                        if (ret <= XMA_ERROR) {
+                            if ((avctx->pix_fmt == AV_PIX_FMT_XVBM_8) || (avctx->pix_fmt == AV_PIX_FMT_XVBM_10)) {
+                                XvbmBufferHandle handle = (XvbmBufferHandle)(la_in_frame->data[0].buffer);
+                                if (handle) {
+                                    xvbm_buffer_pool_entry_free(handle);
+                                }
+                            }
+                            return mpsoc_report_error(ctx, "Error: mpsoc_vcu_encode_frame xlnx_la_send_recv_frame failed!!", AVERROR(EIO));
+                        }
+                        if (enc_in_frame && enc_in_frame->data[0].buffer) {
+                            ret = xma_enc_session_send_frame(ctx->enc_session, enc_in_frame);
+                            if (enc_in_frame) {
+                                if (ret == XMA_ERROR) {
+                                    XvbmBufferHandle xvbm_handle = (XvbmBufferHandle)(enc_in_frame->data[0].buffer);
+                                    if (xvbm_handle) {
+                                        xvbm_buffer_pool_entry_free(xvbm_handle);
+                                    }
+                                }
+                                xlnx_la_release_frame(ctx->la, enc_in_frame);
+                                enc_in_frame = NULL;
+                            }
+                            if(ret == XMA_SEND_MORE_DATA) {
+                                goto start_flush;
+                            }
+                        } else {
+                            goto start_flush;
+                        }
+                    }
+                } else {
+                    /* vcu not ready with an output buffer */
+                    *got_packet = 0;
+                    if (ret == XMA_EOS)
+                        return AVERROR_EOF;
+		    else
+                        goto end;
+                }
+            }
+        } else {
+            /* send raw data failed */
+            *got_packet = 0;
+            return mpsoc_report_error(ctx, "Error : mpsoc_vcu_encode_frame send raw data failed", AVERROR(EIO));
+        }
+    } else { /* end of input data */
+start_flush:
+        /* Skip going to flush logic if number of frames to be encoded is 0 */
+        if(!avctx->frame_number) {
+            av_log(NULL, AV_LOG_ERROR, "ERROR: Trying to flush encoder without sending any input frame \n");
+            return AVERROR_EXIT;
+        }
+        do {
+            ret = mpsoc_vcu_enc_flush_frame(avctx, pkt, pic, got_packet);
+            if (*got_packet == 0) {
+                usleep(5);
+            }
+        } while(ret != XMA_EOS && ret >= 0 && *got_packet == 0);
+        if (ret < 0) {
+            return mpsoc_report_error(ctx, "Error : mpsoc_vcu_encode_frame "
+                                      "flush encoder failed", AVERROR(EIO));
+        }
+    }
+end:
+    ctx->enc_frame_cnt++;
+    return 0;
+}
+
+static const FFCodecDefault mpsoc_defaults[] = {
+    { "b", "5M" },
+    { "g", "120" },
+    { NULL },
+};
+
+static const AVClass mpsoc_h264_class = {
+    .class_name = "MPSOC VCU H264 encoder",
+    .item_name = av_default_item_name,
+    .option = h264Options,
+    .version = LIBAVUTIL_VERSION_INT,
+};
+
+FFCodec ff_h264_vcu_mpsoc_encoder = {
+    .p.name = "mpsoc_vcu_h264",
+    .p.long_name = NULL_IF_CONFIG_SMALL("MPSOC H.264 Encoder"),
+    .p.type = AVMEDIA_TYPE_VIDEO,
+    .p.id = AV_CODEC_ID_H264,
+    .init = mpsoc_vcu_encode_init,
+    FF_CODEC_ENCODE_CB(mpsoc_vcu_encode_frame),
+    .close = mpsoc_vcu_encode_close,
+    .priv_data_size = sizeof(mpsoc_vcu_enc_ctx),
+    .p.priv_class = &mpsoc_h264_class,
+    .defaults = mpsoc_defaults,
+    .p.pix_fmts = (const enum AVPixelFormat[]) { AV_PIX_FMT_XVBM_8,
+                                               AV_PIX_FMT_XVBM_10,
+                                               AV_PIX_FMT_NV12,
+                                               AV_PIX_FMT_XV15,
+                                               AV_PIX_FMT_NONE },
+    .p.capabilities = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AUTO_THREADS,
+};
+
+static const AVClass mpsoc_hevc_vcu_class = {
+    .class_name = "MPSOC VCU HEVC encoder",
+    .item_name = av_default_item_name,
+    .option = hevcOptions,
+    .version = LIBAVUTIL_VERSION_INT,
+};
+
+FFCodec ff_hevc_vcu_mpsoc_encoder = {
+    .p.name = "mpsoc_vcu_hevc",
+    .p.long_name = NULL_IF_CONFIG_SMALL("MPSOC VCU HEVC Encoder"),
+    .p.type  = AVMEDIA_TYPE_VIDEO,
+    .p.id = AV_CODEC_ID_HEVC,
+    .init = mpsoc_vcu_encode_init,
+    FF_CODEC_ENCODE_CB(mpsoc_vcu_encode_frame),
+    .close = mpsoc_vcu_encode_close,
+    .priv_data_size = sizeof(mpsoc_vcu_enc_ctx),
+    .p.priv_class = &mpsoc_hevc_vcu_class,
+    .defaults = mpsoc_defaults,
+    .p.pix_fmts = (const enum AVPixelFormat[]) { AV_PIX_FMT_XVBM_8,
+                                               AV_PIX_FMT_XVBM_10,
+                                               AV_PIX_FMT_NV12,
+                                               AV_PIX_FMT_XV15,
+                                               AV_PIX_FMT_NONE },
+    .p.capabilities = AV_CODEC_CAP_DELAY | AV_CODEC_CAP_AUTO_THREADS | AV_CODEC_CAP_AVOID_PROBING,
+};
diff --git a/libavcodec/mpsoc_vcu_enc.h b/libavcodec/mpsoc_vcu_enc.h
new file mode 100644
index 0000000000..cdda13578b
--- /dev/null
+++ b/libavcodec/mpsoc_vcu_enc.h
@@ -0,0 +1,323 @@
+/*
+ * Modifications Copyright (C) 2024 Advanced Micro Devices, Inc.
+ * Copyright (C) 2018 Xilinx Inc.
+ * All rights reserved.
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef XLNX_ENCODER_H
+#define XLNX_ENCODER_H
+
+#include "xlnx_lookahead.h"
+#include <inttypes.h>
+#include <xma.h>
+
+#define SCLEVEL1 2
+
+#define MAX_ENC_PARAMS      (6)
+/* MAX_EXTRADATA_SIZE should be consistent with AL_ENC_MAX_CONFIG_HEADER_SIZE on device */
+#define MAX_EXTRADATA_SIZE   (2 * 1024)
+#define MAX_ENC_WIDTH        3840
+#define MAX_ENC_HEIGHT       2160
+#define MAX_ENC_PIXELS       (MAX_ENC_WIDTH * MAX_ENC_HEIGHT)
+
+#define OFFSET(x) offsetof(mpsoc_vcu_enc_ctx, x)
+#define VE AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_ENCODING_PARAM
+
+#define VCU_STRIDE_ALIGN    32
+#define VCU_HEIGHT_ALIGN    32
+
+#define XRM_PRECISION_1000000_BIT_MASK(load) ((load << 8))
+
+#define DYN_PARAMS_LIB_NAME  "/opt/xilinx/ffmpeg/lib/libu30_enc_dyn_params.so"
+#define XLNX_ENC_INIT_DYN_PARAMS_OBJ  "xlnx_enc_init_dyn_params_obj"
+
+#define DEFAULT_NUM_B_FRAMES 2
+#define UNSET_NUM_B_FRAMES   -1
+#define DYNAMIC_GOP_MIN_LOOKAHEAD_DEPTH 5
+
+typedef void *DynparamsHandle;
+
+/* Functions pointers for loading functions from dynamic params library */
+typedef DynparamsHandle (*fp_xlnx_enc_get_dyn_params)(char*, uint32_t*);
+typedef uint32_t(*fp_xlnx_enc_get_dyn_param_frame_num) (DynparamsHandle, uint32_t);
+typedef uint32_t(*fp_xlnx_enc_get_runtime_b_frames) (DynparamsHandle, uint32_t);
+typedef void(*fp_xlnx_enc_reset_runtime_aq_params) (DynparamsHandle, uint32_t);
+typedef int32_t(*fp_xlnx_enc_add_dyn_params) (DynparamsHandle, XmaFrame*, uint32_t);
+typedef void (*fp_xlnx_enc_deinit_dyn_params) (DynparamsHandle dynamic_params_handle);
+
+typedef struct XlnxDynParamsObj
+{
+    fp_xlnx_enc_get_dyn_params            xlnx_enc_get_dyn_params;
+    fp_xlnx_enc_get_dyn_param_frame_num   xlnx_enc_get_dyn_param_frame_num;
+    fp_xlnx_enc_get_runtime_b_frames      xlnx_enc_get_runtime_b_frames;
+    fp_xlnx_enc_reset_runtime_aq_params   xlnx_enc_reset_runtime_aq_params;
+    fp_xlnx_enc_add_dyn_params            xlnx_enc_add_dyn_params;
+    fp_xlnx_enc_deinit_dyn_params         xlnx_enc_deinit_dyn_params;
+} XlnxDynParamsObj;
+
+typedef void(*InitDynParams) (XlnxDynParamsObj*);
+
+// Dynamic params structure
+typedef struct EncDynParams {
+    char dynamic_params_file[256];
+    bool dynamic_params_check;
+    DynparamsHandle dynamic_param_handle;
+    uint32_t dynamic_params_count;
+    uint32_t dynamic_params_index;
+    void* dyn_params_lib;
+    XlnxDynParamsObj dyn_params_obj;
+    InitDynParams xlnx_enc_init_dyn_params_obj;
+} EncDynParams;
+
+enum mpsoc_vcu_enc_supported_bitdepth {
+	MPSOC_VCU_BITDEPTH_8BIT = 8,
+	MPSOC_VCU_BITDEPTH_10BIT = 10,
+};
+
+#define MIN_LOOKAHEAD_DEPTH	(1)
+#define MAX_LOOKAHEAD_DEPTH	(30)
+
+typedef struct {
+    AVFrame *pic;
+    XmaFrame *xframe;
+} mpsoc_enc_req;
+
+typedef struct mpsoc_vcu_enc_ctx {
+    const AVClass     *class;
+    XmaEncoderSession *enc_session;
+    XmaParameter       enc_params[MAX_ENC_PARAMS];
+    xrmContext        *xrm_ctx;
+    xrmCuListResourceV2  encode_cu_list_res;
+    bool               encode_res_inuse;
+    int ideal_latency;
+    XmaFrame frame;
+    XmaDataBuffer xma_buffer;
+    bool sent_flush;
+    int  lxlnx_hwdev;
+    int bits_per_sample;
+    int control_rate;
+    int64_t max_bitrate;
+    int slice_qp;
+    int min_qp;
+    int max_qp;
+    int ip_delta;
+    int pb_delta;
+    double cpb_size;
+    double initial_delay;
+    int gop_mode;
+    int gdr_mode;
+    int b_frames;
+    int dynamic_gop;
+    int periodicity_idr;
+    int profile;
+    int level;
+    int tier;
+    int num_slices;
+    int qp_mode;
+    int filler_data;
+    int aspect_ratio;
+    int dependent_slice;
+    int slice_size;
+    int scaling_list;
+    int entropy_mode;
+    int loop_filter;
+    int constrained_intra_pred;
+    int prefetch_buffer;
+    int cores;
+    int latency_logging;
+    int disable_pipeline;
+    int avc_lowlat;
+    char enc_options[2048];
+    AVFifoBuffer *pts_queue;
+    int64_t pts_0;
+    int64_t pts_1;
+    int is_first_outframe;
+    int loop_filter_beta_offset;
+    int loop_filter_tc_offset;
+    int32_t out_packet_size;
+    uint32_t enc_frame_cnt;
+    //LA
+    xlnx_lookahead_t la;
+    int32_t lookahead_depth;
+    int32_t spatial_aq;
+    int32_t temporal_aq;
+    int32_t rate_control_mode;
+    int32_t spatial_aq_gain;
+    XmaFrame* la_in_frame;
+    //Expert options
+    char *expert_options;
+    int32_t tune_metrics;
+    int32_t lookahead_rc_off;
+    EncDynParams enc_dyn_params;
+} mpsoc_vcu_enc_ctx;
+
+static const AVOption h264Options[] = {
+    { "lxlnx_hwdev", "set local device ID for encoder if it needs to be different from global xlnx_hwdev", OFFSET(lxlnx_hwdev), AV_OPT_TYPE_INT, {.i64 = -1}, -1, INT_MAX, VE, "lxlnx_hwdev"},
+    { "control-rate", "Rate Control Mode", OFFSET(control_rate), AV_OPT_TYPE_INT, { .i64 = 1}, 0,  3, VE, "control-rate"},
+    { "max-bitrate", "Maximum Bit Rate", OFFSET(max_bitrate), AV_OPT_TYPE_INT64, { .i64 = 5000000}, 0,  35000000000, VE, "max-bitrate"},
+    { "slice-qp", "Slice QP", OFFSET(slice_qp), AV_OPT_TYPE_INT, { .i64 = -1}, -1,  51, VE, "slice-qp"},
+    { "min-qp", "Minimum QP value allowed for the rate control", OFFSET(min_qp), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 51, VE, "min-qp"},
+    { "max-qp", "Maximum QP value allowed for the rate control", OFFSET(max_qp), AV_OPT_TYPE_INT, { .i64 = 51}, 0, 51, VE, "max-qp"},
+    { "bf", "Number of B-frames Default 2", OFFSET(b_frames), AV_OPT_TYPE_INT, { .i64 = UNSET_NUM_B_FRAMES}, UNSET_NUM_B_FRAMES, 4294967295, VE, "b-frames"},
+    { "dynamic-gop", "Automatically change B-frame structure based on motion vectors. Requires Lookahead_depth of at least 5.", OFFSET(dynamic_gop), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 1, VE, "dynamic-gop"},
+    { "periodicity-idr", "IDR Picture Frequency", OFFSET(periodicity_idr), AV_OPT_TYPE_INT, { .i64 = -1}, -1, 4294967295, VE, "periodicity-idr"},
+    { "profile", "Set the encoding profile", OFFSET(profile), AV_OPT_TYPE_INT, { .i64 = FF_PROFILE_H264_HIGH }, FF_PROFILE_H264_BASELINE, FF_PROFILE_H264_HIGH_10_INTRA, VE, "profile" },
+    { "level", "Set the encoding level restriction", OFFSET(level), AV_OPT_TYPE_INT, { .i64 = 10 }, 10, 52, VE, "level" },
+    { "slices", "Number of Slices", OFFSET(num_slices), AV_OPT_TYPE_INT, { .i64 = 1}, 1, 68, VE, "slices"},
+    { "qp-mode", "QP Control Mode", OFFSET(qp_mode), AV_OPT_TYPE_INT, { .i64 = 1}, 0, 2, VE, "qp-mode"},
+    { "aspect-ratio", "Aspect-Ratio", OFFSET(aspect_ratio), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 3, VE, "aspect-ratio"},
+    { "scaling-list", "Scaling List Mode", OFFSET(scaling_list), AV_OPT_TYPE_INT, { .i64 = 1}, 0, 1, VE, "scaling-list"},
+    { "cores", "Number of cores to use", OFFSET(cores), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 4, VE, "cores"},
+    { "lookahead_depth", "Number of frames to lookahead for qp maps generation or custom rate control. Up to 20", OFFSET(lookahead_depth), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 20, VE, "lookahead_depth"},
+    { "temporal-aq", "Enable Temporal AQ.", OFFSET(temporal_aq), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, VE, "temporal-aq-mode"},
+    { "spatial-aq", "Enable Spatial AQ.", OFFSET(spatial_aq), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, VE, "spatial-aq-mode"},
+    { "spatial-aq-gain", "Percentage of spatial AQ gain", OFFSET(spatial_aq_gain), AV_OPT_TYPE_INT, {.i64 = 50}, 0, 100, VE, "spatial-aq-gain"},
+	{ "latency_logging", "Log latency information to syslog", OFFSET(latency_logging), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE, "latency_logging" },
+    { "disable-pipeline", "Disable pipelining for encoder. Serializes encoding (does not affect lookahead)", OFFSET(disable_pipeline), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE, "disable-pipeline" },
+	{ "avc-lowlat", "Enable AVC low latency flag for H264 to run on multiple cores incase of pipeline disabled", OFFSET(avc_lowlat), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE, "avc-lowlat" },
+    { "expert-options", "Expert options for MPSoC H264 Encoder", OFFSET(expert_options), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 1024, VE, "expert_options"},
+    { "tune-metrics", "Tunes MPSoC H.264 Encoder's video quality for objective metrics", OFFSET(tune_metrics), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 1, VE, "tune-metrics"},
+
+    { "const-qp", "Constant QP (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "control-rate"},
+    { "cbr", "Constant Bitrate (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "control-rate"},
+    { "vbr", "Variable Bitrate (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "control-rate"},
+    { "low-latency", "Low Latency (3)", 0, AV_OPT_TYPE_CONST, { .i64 = 3}, 0, 0, VE, "control-rate"},
+    { "auto", "Auto (-1)", 0, AV_OPT_TYPE_CONST, { .i64 = -1}, 0, 0, VE, "slice-qp"},
+    { "unset", "Unset (-1)", 0, AV_OPT_TYPE_CONST, { .i64 = UNSET_NUM_B_FRAMES}, 0, 0, VE, "b-frames"},
+    { "baseline", "Baseline profile (66)", 0, AV_OPT_TYPE_CONST, { .i64 = FF_PROFILE_H264_BASELINE}, 0, 0, VE, "profile"},
+    { "main", "Main profile (77)", 0, AV_OPT_TYPE_CONST, { .i64 = FF_PROFILE_H264_MAIN}, 0, 0, VE, "profile"},
+    { "high", "High profile (100)", 0, AV_OPT_TYPE_CONST, { .i64 = FF_PROFILE_H264_HIGH}, 0, 0, VE, "profile"},
+    { "high-10", "High 10 profile (110)", 0, AV_OPT_TYPE_CONST, {.i64 = FF_PROFILE_H264_HIGH_10}, 0, 0, VE, "profile"},
+    { "high-10-intra", "High 10 Intra profile (110 with constraint set 3, 2158)", 0, AV_OPT_TYPE_CONST, { .i64 = FF_PROFILE_H264_HIGH_10_INTRA}, 0, 0, VE, "profile"},
+    { "1", "1 level (10)", 0, AV_OPT_TYPE_CONST, { .i64 = 10}, 0, 0, VE, "level"},
+    { "1.1", "1.1 level (11)", 0, AV_OPT_TYPE_CONST, { .i64 = 11}, 0, 0, VE, "level"},
+    { "1.2", "1.2 level (12)", 0, AV_OPT_TYPE_CONST, { .i64 = 12}, 0, 0, VE, "level"},
+    { "1.3", "1.3 level (13)", 0, AV_OPT_TYPE_CONST, { .i64 = 13}, 0, 0, VE, "level"},
+    { "2", "2 level (20)", 0, AV_OPT_TYPE_CONST, { .i64 = 20}, 0, 0, VE, "level"},
+    { "2.1", "2.1 level (21)", 0, AV_OPT_TYPE_CONST, { .i64 = 21}, 0, 0, VE, "level"},
+    { "2.2", "2.2 level (22)", 0, AV_OPT_TYPE_CONST, { .i64 = 22}, 0, 0, VE, "level"},
+    { "3", "3 level (30)", 0, AV_OPT_TYPE_CONST, { .i64 = 30}, 0, 0, VE, "level"},
+    { "3.1", "3.1 level (31)", 0, AV_OPT_TYPE_CONST, { .i64 = 31}, 0, 0, VE, "level"},
+    { "3.2", "3.2 level (32)", 0, AV_OPT_TYPE_CONST, { .i64 = 32}, 0, 0, VE, "level"},
+    { "4", "4 level (40)", 0, AV_OPT_TYPE_CONST, { .i64 = 40}, 0, 0, VE, "level"},
+    { "4.1", "4.1 level (41)", 0, AV_OPT_TYPE_CONST, { .i64 = 41}, 0, 0, VE, "level"},
+    { "4.2", "4.2 level (42)", 0, AV_OPT_TYPE_CONST, { .i64 = 42}, 0, 0, VE, "level"},
+    { "5", "5 level (50)", 0, AV_OPT_TYPE_CONST, { .i64 = 50}, 0, 0, VE, "level"},
+    { "5.1", "5.1 level (51)", 0, AV_OPT_TYPE_CONST, { .i64 = 51}, 0, 0, VE, "level"},
+    { "5.2", "5.2 level (52)", 0, AV_OPT_TYPE_CONST, { .i64 = 52}, 0, 0, VE, "level"},
+    { "uniform", "Use the same QP for all coding units of the frame (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "qp-mode"},
+    { "auto", "Let the VCU encoder change the QP for each coding unit according to its content (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "qp-mode"},
+    { "relative-load", "Use the information gathered in the lookahead to calculate the best QP (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "qp-mode"},
+    { "auto", "4:3 for SD video, 16:9 for HD video, unspecified for unknown format (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "aspect-ratio"},
+    { "4:3", "4:3 aspect ratio (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "aspect-ratio"},
+    { "16:9", "16:9 aspect ratio (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "aspect-ratio"},
+    { "none", "Aspect ratio information is not present in the stream (3)", 0, AV_OPT_TYPE_CONST, { .i64 = 3}, 0, 0, VE, "aspect-ratio"},
+    { "flat", "Flat scaling list mode (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "scaling-list"},
+    { "default", "Default scaling list mode (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "scaling-list"},
+    { "auto", "Automatic (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "cores"},
+    { "disable", "Disable Temporal AQ (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "temporal-aq-mode"},
+    { "enable", "Enable Temporal AQ (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "temporal-aq-mode"},
+    { "disable", "Disable Spatial AQ (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "spatial-aq-mode"},
+    { "enable", "Enable Spatial AQ (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "spatial-aq-mode"},
+    { "disable", "Enable encoder pipelining (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "disable-pipeline"},
+    { "enable", "Disable encoder pipelining (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "disable-pipeline"},
+    { "disable", "Disable AVC low latency (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "avc-lowlat"},
+    { "enable", "Enable AVC low latency (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "avc-lowlat"},
+    { "disable", "Disable dynamic gop (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "dynamic-gop"},
+	{ "enable", "Enable dynamic gop (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "dynamic-gop"},
+    { "disable", "Disable tune metrics (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "tune-metrics"},
+    { "enable", "Enable tune metrics (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "tune-metrics"},
+    {NULL},
+};
+
+static const AVOption hevcOptions[] = {
+    { "lxlnx_hwdev", "set local device ID for encoder if it needs to be different from global xlnx_hwdev", OFFSET(lxlnx_hwdev), AV_OPT_TYPE_INT, {.i64 = -1}, -1, INT_MAX, VE, "lxlnx_hwdev"},
+    { "control-rate", "Rate Control Mode", OFFSET(control_rate), AV_OPT_TYPE_INT, { .i64 = 1}, 0,  3, VE, "control-rate"},
+    { "max-bitrate", "Maximum Bit Rate", OFFSET(max_bitrate), AV_OPT_TYPE_INT64, { .i64 = 5000000}, 0,  35000000000, VE, "max-bitrate"},
+    { "slice-qp", "Slice QP", OFFSET(slice_qp), AV_OPT_TYPE_INT, { .i64 = -1}, -1,  51, VE, "slice-qp"},
+    { "min-qp", "Minimum QP value allowed for the rate control", OFFSET(min_qp), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 51, VE, "min-qp"},
+    { "max-qp", "Maximum QP value allowed for the rate control", OFFSET(max_qp), AV_OPT_TYPE_INT, { .i64 = 51}, 0, 51, VE, "max-qp"},
+    { "bf", "Number of B-frames Default 2", OFFSET(b_frames), AV_OPT_TYPE_INT, { .i64 = UNSET_NUM_B_FRAMES}, UNSET_NUM_B_FRAMES, 4294967295, VE, "b-frames"},
+    { "dynamic-gop", "Automatically change B-frame structure based on motion vectors. Requires Lookahead_depth of at least 5.", OFFSET(dynamic_gop), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 1, VE, "dynamic-gop"},
+    { "periodicity-idr", "IDR Picture Frequency", OFFSET(periodicity_idr), AV_OPT_TYPE_INT, { .i64 = -1}, -1, 4294967295, VE, "periodicity-idr"},
+    { "profile", "Set the encoding profile", OFFSET(profile), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 3, VE, "profile" },
+    { "level", "Set the encoding level restriction", OFFSET(level), AV_OPT_TYPE_INT, { .i64 = 10 }, 10, 52, VE, "level" },
+    { "tier", "Set the encoding tier", OFFSET(tier), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 1, VE, "tier" },
+    { "slices", "Number of Slices", OFFSET(num_slices), AV_OPT_TYPE_INT, { .i64 = 1}, 1, 68, VE, "slices"},
+    { "qp-mode", "QP Control Mode", OFFSET(qp_mode), AV_OPT_TYPE_INT, { .i64 = 1}, 0, 2, VE, "qp-mode"},
+    { "aspect-ratio", "Aspect-Ratio", OFFSET(aspect_ratio), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 3, VE, "aspect-ratio"},
+    { "scaling-list", "Scaling List Mode", OFFSET(scaling_list), AV_OPT_TYPE_INT, { .i64 = 1}, 0, 1, VE, "scaling-list"},
+    { "cores", "Number of cores to use", OFFSET(cores), AV_OPT_TYPE_INT, { .i64 = 0}, 0, 4, VE, "cores"},
+    { "lookahead_depth", "Number of frames to lookahead for qp maps generation or custom rate control. Up to 20", OFFSET(lookahead_depth), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 20, VE, "lookahead_depth"},
+    { "temporal-aq", "Enable Temporal AQ.", OFFSET(temporal_aq), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, VE, "temporal-aq-mode"},
+    { "spatial-aq", "Enable Spatial AQ.", OFFSET(spatial_aq), AV_OPT_TYPE_INT, {.i64 = 1}, 0, 1, VE, "spatial-aq-mode"},
+    { "spatial-aq-gain", "Percentage of spatial AQ gain", OFFSET(spatial_aq_gain), AV_OPT_TYPE_INT, {.i64 = 50}, 0, 100, VE, "spatial-aq-gain"},
+	{ "latency_logging", "Log latency information to syslog", OFFSET(latency_logging), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE, "latency_logging" },
+    { "disable-pipeline", "Disable pipelining for encoder. Serializes encoding (does not affect lookahead)", OFFSET(disable_pipeline), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, VE, "disable-pipeline" },
+    { "expert-options", "Expert options for MPSoC HEVC Encoder", OFFSET(expert_options), AV_OPT_TYPE_STRING, {.str = NULL}, 0, 1024, VE, "expert_options"},
+	{ "tune-metrics", "Tunes MPSoC HEVC Encoder's video quality for objective metrics", OFFSET(tune_metrics), AV_OPT_TYPE_INT, {.i64 = 0}, 0, 1, VE, "tune-metrics"},
+
+    { "const-qp", "Constant QP (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "control-rate"},
+    { "cbr", "Constant Bitrate (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "control-rate"},
+    { "vbr", "Variable Bitrate (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "control-rate"},
+    { "low-latency", "Low Latency (3)", 0, AV_OPT_TYPE_CONST, { .i64 = 3}, 0, 0, VE, "control-rate"},
+    { "auto", "Auto (-1)", 0, AV_OPT_TYPE_CONST, { .i64 = -1}, 0, 0, VE, "slice-qp"},
+    { "unset", "Unset (-1)", 0, AV_OPT_TYPE_CONST, { .i64 = UNSET_NUM_B_FRAMES}, 0, 0, VE, "b-frames"},
+    { "main", "Main profile (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "profile"},
+    { "main-intra", "Main Intra profile (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "profile"},
+    { "main-10", "Main 10 profile (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "profile"},
+    { "main-10-intra", "Main 10 Intra profile (3)", 0, AV_OPT_TYPE_CONST, { .i64 = 3}, 0, 0, VE, "profile"},
+    { "1", "1 level (10)", 0, AV_OPT_TYPE_CONST, { .i64 = 10}, 0, 0, VE, "level"},
+    { "2", "2 level (20)", 0, AV_OPT_TYPE_CONST, { .i64 = 20}, 0, 0, VE, "level"},
+    { "2.1", "2.1 level (21)", 0, AV_OPT_TYPE_CONST, { .i64 = 21}, 0, 0, VE, "level"},
+    { "3", "3 level (30)", 0, AV_OPT_TYPE_CONST, { .i64 = 30}, 0, 0, VE, "level"},
+    { "3.1", "3.1 level (31)", 0, AV_OPT_TYPE_CONST, { .i64 = 31}, 0, 0, VE, "level"},
+    { "4", "4 level (40)", 0, AV_OPT_TYPE_CONST, { .i64 = 40}, 0, 0, VE, "level"},
+    { "4.1", "4.1 level (41)", 0, AV_OPT_TYPE_CONST, { .i64 = 41}, 0, 0, VE, "level"},
+    { "5", "5 level (50)", 0, AV_OPT_TYPE_CONST, { .i64 = 50}, 0, 0, VE, "level"},
+    { "5.1", "5.1 level (51)", 0, AV_OPT_TYPE_CONST, { .i64 = 51}, 0, 0, VE, "level"},
+    { "5.2", "5.2 level (52)", 0, AV_OPT_TYPE_CONST, { .i64 = 52}, 0, 0, VE, "level"},
+    { "main", "Main tier (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "tier"},
+    { "high", "High tier (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "tier"},
+    { "uniform", "Use the same QP for all coding units of the frame (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "qp-mode"},
+    { "auto", "Let the VCU encoder change the QP for each coding unit according to its content (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "qp-mode"},
+    { "relative-load", "Use the information gathered in the lookahead to calculate the best QP (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "qp-mode"},
+    { "auto", "4:3 for SD video, 16:9 for HD video, unspecified for unknown format (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "aspect-ratio"},
+    { "4:3", "4:3 aspect ratio (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "aspect-ratio"},
+    { "16:9", "16:9 aspect ratio (2)", 0, AV_OPT_TYPE_CONST, { .i64 = 2}, 0, 0, VE, "aspect-ratio"},
+    { "none", "Aspect ratio information is not present in the stream (3)", 0, AV_OPT_TYPE_CONST, { .i64 = 3}, 0, 0, VE, "aspect-ratio"},
+    { "flat", "Flat scaling list mode (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "scaling-list"},
+    { "default", "Default scaling list mode (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "scaling-list"},
+    { "auto", "Automatic (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "cores"},
+    { "disable", "Disable Temporal AQ (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "temporal-aq-mode"},
+    { "enable", "Enable Temporal AQ (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "temporal-aq-mode"},
+    { "disable", "Disable Spatial AQ (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "spatial-aq-mode"},
+    { "enable", "Enable Spatial AQ (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "spatial-aq-mode"},
+    { "disable", "Disable encoder pipelining (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "disable-pipeline"},
+    { "enable", "Enable encoder pipelining (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "disable-pipeline"},
+    { "disable", "Disable dynamic gop (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "dynamic-gop"},
+	{ "enable", "Enable dynamic gop (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "dynamic-gop"},
+    { "disable", "Disable tune metrics (0)", 0, AV_OPT_TYPE_CONST, { .i64 = 0}, 0, 0, VE, "tune-metrics"},
+    { "enable", "Enable tune metrics (1)", 0, AV_OPT_TYPE_CONST, { .i64 = 1}, 0, 0, VE, "tune-metrics"},
+    {NULL},
+};
+
+int vcu_alloc_ff_packet(mpsoc_vcu_enc_ctx *ctx, AVPacket *pkt);
+
+#endif //XLNX_ENCODER_H
diff --git a/libavcodec/mpsoc_vcu_hdr10.h b/libavcodec/mpsoc_vcu_hdr10.h
new file mode 100644
index 0000000000..f30adff7c9
--- /dev/null
+++ b/libavcodec/mpsoc_vcu_hdr10.h
@@ -0,0 +1,41 @@
+/*
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef MPSOC_VCU_HDR10
+#define MPSOC_VCU_HDR10
+
+#include <sys/types.h>
+
+//HDR10 VUI parameters
+typedef struct HDR10_VUI_Params
+{
+    char    ColorDesc[30];
+    char    TxChar[30];
+    char    ColorMatrix[30];
+    uint8_t isInitialized;
+}HDR10_VUI_Params;
+
+//Global singleton for HDR VUI data, that is populated by the decoder
+//and can be accessed by any element in transcode pipeline
+static HDR10_VUI_Params g_hdr10_vui_params;
+
+void init_hdr10_vui_params();
+void print_hdr10_vui_params();
+HDR10_VUI_Params* get_hdr10_vui_params();
+
+#endif /* MPSOC_VCU_HDR10 */
diff --git a/libavcodec/parsers.c b/libavcodec/parsers.c
index b59388835d..b055d36acb 100644
--- a/libavcodec/parsers.c
+++ b/libavcodec/parsers.c
@@ -73,7 +73,6 @@ extern const AVCodecParser ff_vp8_parser;
 extern const AVCodecParser ff_vp9_parser;
 extern const AVCodecParser ff_webp_parser;
 extern const AVCodecParser ff_xbm_parser;
-extern const AVCodecParser ff_xma_parser;
 
 #include "libavcodec/parser_list.c"
 
diff --git a/libavcodec/rawenc.c b/libavcodec/rawenc.c
index 34d7a1bef4..0a8a080725 100644
--- a/libavcodec/rawenc.c
+++ b/libavcodec/rawenc.c
@@ -37,6 +37,16 @@
 static av_cold int raw_encode_init(AVCodecContext *avctx)
 {
     const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(avctx->pix_fmt);
+#if CONFIG_LIBXVBM
+    if (avctx->pix_fmt == AV_PIX_FMT_XVBM_8) {
+        av_log (avctx, AV_LOG_ERROR, "XVBM_8 export to rawvideo not supported! Use xvbm_convert filter!\n");
+        return AVERROR(EINVAL);
+    }
+    if (avctx->pix_fmt == AV_PIX_FMT_XVBM_10) {
+        av_log (avctx, AV_LOG_ERROR, "XVBM_10 export to rawvideo not supported! Use xvbm_convert filter!\n");
+        return AVERROR(EINVAL);
+    }
+#endif
 
     avctx->bits_per_coded_sample = av_get_bits_per_pixel(desc);
     if(!avctx->codec_tag)
diff --git a/libavcodec/xlnx_lookahead.c b/libavcodec/xlnx_lookahead.c
new file mode 100644
index 0000000000..9242549136
--- /dev/null
+++ b/libavcodec/xlnx_lookahead.c
@@ -0,0 +1,624 @@
+/*
+ * Modifications Copyright (C) 2024 Advanced Micro Devices, Inc.
+ * Copyright (C) 2018 Xilinx Inc.
+ * All rights reserved.
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#include <stdlib.h>
+#include <string.h>
+#include "xlnx_lookahead.h"
+#include "libavutil/internal.h"
+#include "xvbm.h"
+#include <xrm.h>
+#include <dlfcn.h>
+#include <errno.h>
+#include "../xmaPropsTOjson.h"
+
+//From #include "xlnx_la_plg_ext.h"
+#define XLNX_LA_PLG_NUM_EXT_PARAMS 11
+#define XRM_PRECISION_1000000_BIT_MASK(load) ((load << 8))
+
+typedef enum
+{
+    EParamIntraPeriod,
+    EParamLADepth,
+    EParamEnableHwInBuf,
+    EParamSpatialAQMode,
+    EParamTemporalAQMode,
+    EParamRateControlMode,
+    EParamSpatialAQGain,
+    EParamNumBFrames,
+    EParamCodecType,
+    EParamLatencyLogging,
+    EParamDynamicGop
+} xlnx_la_ext_params_t;
+
+static const char *XLNX_LA_EXT_PARAMS[] = {
+    "ip",
+    "lookahead_depth",
+    "enable_hw_in_buf",
+    "spatial_aq_mode",
+    "temporal_aq_mode",
+    "rate_control_mode",
+    "spatial_aq_gain",
+    "num_b_frames",
+    "codec_type",
+    "latency_logging",
+    "dynamic_gop"
+};
+
+///////////////////////////////////////////////////////////////////////////////
+
+#define SCLEVEL1 2
+#define XLNX_MAX_LOOKAHEAD_DEPTH 20
+#define XLNX_ALIGN(x,LINE_SIZE) (((((size_t)x) + ((size_t)LINE_SIZE - 1)) & (~((size_t)LINE_SIZE - 1))))
+
+static const char *XLNX_LOOKAHEAD_NAME = "xlnx_lookahead";
+
+#define XLNX_LA_LOG(LOG_TYPE, ...)                               \
+    do {                                                         \
+        xma_logmsg(LOG_TYPE, XLNX_LOOKAHEAD_NAME, __VA_ARGS__);  \
+    } while (0)
+
+typedef struct xlnx_la_ctx
+{
+    XmaFilterSession *filter_session;
+    uint8_t           bypass;
+    uint32_t          enableHwInBuf;
+    uint32_t          lookahead_depth;
+    uint32_t          spatial_aq_mode;
+    uint32_t          temporal_aq_mode;
+    uint32_t          rate_control_mode;
+    uint32_t          spatial_aq_gain;
+    XmaFormatType     fmt_type;
+    xlnx_codec_type_t codec_type;
+    XmaParameter      extn_params[XLNX_LA_PLG_NUM_EXT_PARAMS];
+    XmaFrame         *out_frame;
+    xrmContext       *xrm_ctx;
+    xrmCuResourceV2   lookahead_cu_res;
+    bool              lookahead_res_inuse;
+    int               lxlnx_hwdev;
+} xlnx_la_ctx;
+
+static void free_frame(XmaFrame *xframe)
+{
+    XvbmBufferHandle handle;
+    int32_t num_planes;
+    if (xframe == NULL) {
+        return;
+    }
+    if (xframe->data[0].buffer_type == XMA_DEVICE_BUFFER_TYPE) {
+        handle = (XvbmBufferHandle)(xframe->data[0].buffer);
+        if (handle) {
+            xvbm_buffer_pool_entry_free(handle);
+        }
+        xframe->data[0].buffer = NULL;
+    } else {
+        num_planes = xma_frame_planes_get(&xframe->frame_props);
+
+        for (int32_t i = 0; i < num_planes; i++) {
+            xframe->data[i].refcount--;
+        }
+
+        if (xframe->data[0].refcount > 0) {
+            return;
+        }
+
+        for (int32_t i = 0; i < num_planes && !xframe->data[i].is_clone; i++) {
+            if (xframe->data[i].buffer) {
+                free(xframe->data[i].buffer);
+                xframe->data[i].buffer = NULL;
+            }
+        }
+    }
+    xma_frame_clear_all_side_data(xframe);
+    free(xframe);
+}
+
+static int32_t free_res(xlnx_la_ctx *la_ctx)
+{
+    char* endptr;
+
+    if (!la_ctx) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "free_res : free_res la_ctx = NULL\n");
+        return XMA_ERROR;
+    }
+
+    // Close lookahead session
+    if (la_ctx->filter_session) {
+        xma_filter_session_destroy(la_ctx->filter_session);
+        la_ctx->filter_session = NULL;
+    }
+    free_frame(la_ctx->out_frame);
+    la_ctx->out_frame = NULL;
+
+    if (getenv("XRM_RESERVE_ID")) {
+        errno=0;
+        int xrm_reserve_id =  strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);
+        if (errno != 0)
+        {
+           av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_RESERVE_ID in lookahead plugin\n");
+           return -1;
+        }
+
+        //XRM lookahead de-allocation
+        if (la_ctx->lookahead_res_inuse) {
+            if (!(xrmCuReleaseV2(la_ctx->xrm_ctx, &la_ctx->lookahead_cu_res))) {
+                av_log(NULL, AV_LOG_ERROR, "XRM: failed to release lookahead resources\n");
+            }
+            if (xrmDestroyContext(la_ctx->xrm_ctx) != XRM_SUCCESS) {
+                av_log(NULL, AV_LOG_ERROR, "XRM : lookahead destroy context failed\n");
+            }
+        }
+    }
+
+    return XMA_SUCCESS;
+}
+
+static int _calc_la_load(xrmContext *xrm_ctx, XmaFilterProperties *filter_props,
+                         int32_t func_id, int32_t *la_load)
+{
+    char pluginName[XRM_MAX_NAME_LEN];
+    int skip_value=0;
+    xrmPluginFuncParam param;
+    char *err;
+    void *handle;
+    void (*convertXmaPropsToJson)(void *props, char *funcName, char *jsonJob);
+
+    memset(&param, 0, sizeof(xrmPluginFuncParam));
+    handle = dlopen("/opt/xilinx/xrm/plugin/libxmaPropsTOjson.so", RTLD_NOW );
+    if (!handle) {
+        av_log(NULL, AV_LOG_ERROR, "Unable to load libxmaPropsTOjson.so  - %s\n",
+               dlerror());
+        return XMA_ERROR;
+    }
+    dlerror(); /* clear error code */
+
+    convertXmaPropsToJson = dlsym(handle, "convertXmaPropsToJson");
+    if ((err = dlerror()) != NULL) {
+        av_log(NULL, AV_LOG_ERROR, "convertXmaPropsToJson symbol not found\n");
+        return XMA_ERROR;
+    }
+
+    (*convertXmaPropsToJson) (filter_props, "LOOKAHEAD", param.input);
+    dlclose(handle);
+
+    strcpy(pluginName, "xrmU30EncPlugin");
+    if (xrmExecPluginFunc(xrm_ctx, pluginName, func_id, &param) != XRM_SUCCESS) {
+        av_log(NULL, AV_LOG_ERROR,
+               "xrm_load_calculation: lookahead plugin function %d, failed to run the function\n",
+               func_id);
+        return XMA_ERROR;
+    } else {
+        skip_value = atoi((char *)(strtok(param.output, " ")));
+        skip_value = atoi((char *)(strtok(NULL, " ")));
+        *la_load = atoi((char *)(strtok(NULL, " ")));
+
+        if (*la_load <= 0) {
+            av_log(NULL, AV_LOG_ERROR,
+                   "xrm_load_calculation: enc plugin function %d, calculated wrong lookahead load %d .\n",
+                   *la_load);
+            return XMA_ERROR;
+        } else if (*la_load > XRM_MAX_CU_LOAD_GRANULARITY_1000000) {
+            av_log(NULL, AV_LOG_ERROR,
+                   "xrm_load_calculation: enc plugin function %d, calculated lookahead load %d is greater than maximum supported.\n",
+                   *la_load);
+            return XMA_ERROR;
+        }
+    }
+
+    return 0;
+}
+
+static int _allocate_xrm_la_cu(xlnx_la_ctx *ctx,
+                               XmaFilterProperties *filter_props)
+{
+    int xrm_reserve_id = -1;
+    int ret =-1;
+    char pluginName[XRM_MAX_NAME_LEN];
+    uint64_t deviceInfoDeviceIndex = 0;
+    uint64_t deviceInfoContraintType = XRM_DEVICE_INFO_CONSTRAINT_TYPE_HARDWARE_DEVICE_INDEX;
+    char* endptr;
+
+    //create XRM local context
+    ctx->xrm_ctx = (xrmContext *)xrmCreateContext(XRM_API_VERSION_1);
+    if (ctx->xrm_ctx == NULL) {
+        av_log(NULL, AV_LOG_ERROR, "create local XRM context failed\n");
+        return XMA_ERROR;
+    }
+
+    //XRM encoder plugin load calculation
+    int32_t func_id = 0, la_load=0;
+    ret = _calc_la_load(ctx->xrm_ctx, filter_props, func_id, &la_load);
+    if (ret < 0) {
+        return ret;
+    }
+
+    //XRM lookahead allocation
+    xrmCuPropertyV2 lookahead_cu_prop;
+
+    memset(&lookahead_cu_prop, 0, sizeof(xrmCuPropertyV2));
+    memset(&ctx->lookahead_cu_res, 0, sizeof(xrmCuResourceV2));
+
+    strcpy(lookahead_cu_prop.kernelName, "lookahead");
+    strcpy(lookahead_cu_prop.kernelAlias, "LOOKAHEAD_MPSOC");
+
+    if (getenv("XRM_RESERVE_ID")) {
+       errno = 0;
+       xrm_reserve_id =  strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);
+       if (errno != 0)
+       {
+          av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_RESERVE_ID in lookahead plugin\n");
+          return -1;
+       }
+    }
+
+    lookahead_cu_prop.devExcl = false;
+    lookahead_cu_prop.requestLoad = XRM_PRECISION_1000000_BIT_MASK(la_load);
+
+    if ((ctx->lxlnx_hwdev > -1) && (xrm_reserve_id > -1)) //2dev mode launcher
+    {
+        deviceInfoDeviceIndex = ctx->lxlnx_hwdev;
+        lookahead_cu_prop.deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+        lookahead_cu_prop.poolId = xrm_reserve_id;
+    }
+    else if (xrm_reserve_id > -1) //1dev mode launcher
+    {
+        lookahead_cu_prop.poolId = xrm_reserve_id;
+    }
+    else if (ctx->lxlnx_hwdev > -1) //explicit ffmpeg local device command
+    {
+        deviceInfoDeviceIndex = ctx->lxlnx_hwdev;
+        lookahead_cu_prop.deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+    }
+    else
+    {
+        errno=0;
+        deviceInfoDeviceIndex =  strtol(getenv("XRM_DEVICE_ID"), &endptr, 0);
+        if (errno != 0)
+        {
+            av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_DEVICE_ID in lookahead plugin\n");
+            return -1;
+        }
+
+        lookahead_cu_prop.deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) | (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+    }
+
+    ret = xrmCuAllocV2(ctx->xrm_ctx, &lookahead_cu_prop, &ctx->lookahead_cu_res);
+
+    if (ret != 0) {
+        av_log(NULL, AV_LOG_ERROR,
+                "xrm_allocation: failed to allocate lookahead resources from reserve id=%d or device=%d\n",
+                 xrm_reserve_id, deviceInfoDeviceIndex);
+        return XMA_ERROR;
+    } else {
+        ctx->lookahead_res_inuse = true;
+    }
+
+    //Set XMA plugin SO and device index
+    filter_props->plugin_lib = ctx->lookahead_cu_res.kernelPluginFileName;
+    filter_props->dev_index = ctx->lookahead_cu_res.deviceId;
+    filter_props->ddr_bank_index =
+        -1;//XMA to select the ddr bank based on xclbin meta data
+    filter_props->cu_index = ctx->lookahead_cu_res.cuId;
+    filter_props->channel_id = ctx->lookahead_cu_res.channelId;
+
+    av_log(NULL, AV_LOG_DEBUG,
+           "---lookahead xrm out: la_load=%d, plugin=%s, device=%d, cu=%d, ch=%d  \n",
+           la_load, filter_props->plugin_lib, filter_props->dev_index,
+           filter_props->cu_index, filter_props->channel_id);
+
+    return ret;
+}
+
+xlnx_lookahead_t create_xlnx_la(xlnx_la_cfg_t *cfg)
+{
+    XmaFilterProperties filter_props;
+    XmaFilterPortProperties *in_props;
+    XmaFilterPortProperties *out_props;
+    uint32_t param_cnt = 0;
+    //XmaFrameProperties f_in_props;
+    //XmaFrameProperties f_out_props;
+    xlnx_la_ctx *la_ctx;
+    XmaParameter *extn_params = NULL;
+    int ret = -1;
+
+    if (!cfg) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "No config received\n");
+        return NULL;
+    }
+    if ((cfg->lookahead_depth == 0) && (cfg->temporal_aq_mode == 1)) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "Invalid params: Lookahead = 0, temporal aq=%u\n",
+                    cfg->temporal_aq_mode);
+        return NULL;
+    }
+
+    la_ctx = calloc(1, sizeof(xlnx_la_ctx));
+    if (!la_ctx) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "OOM la_ctx\n");
+        return NULL;
+    }
+    la_ctx->lookahead_depth = cfg->lookahead_depth;
+    if ((cfg->lookahead_depth == 0) && (cfg->spatial_aq_mode == 0)) {
+        la_ctx->bypass = 1;
+        return la_ctx;
+    }
+    la_ctx->spatial_aq_mode = cfg->spatial_aq_mode;
+    la_ctx->temporal_aq_mode = cfg->temporal_aq_mode;
+    la_ctx->spatial_aq_gain = cfg->spatial_aq_gain;
+    la_ctx->enableHwInBuf = cfg->enableHwInBuf;
+    la_ctx->fmt_type = cfg->fmt_type;
+    la_ctx->rate_control_mode = cfg->rate_control_mode;
+    la_ctx->bypass = 0;
+    la_ctx->codec_type = cfg->codec_type;
+    la_ctx->lxlnx_hwdev = cfg->lxlnx_hwdev;
+
+    // Setup lookahead properties
+    //filter_props = &la_ctx->filter_props;
+    memset(&filter_props, 0, sizeof(XmaFilterProperties));
+    filter_props.hwfilter_type = XMA_2D_FILTER_TYPE;
+    strcpy(filter_props.hwvendor_string, "Xilinx");
+
+    // Setup lookahead input port properties
+    in_props = &filter_props.input;
+    memset(in_props, 0, sizeof(XmaFilterPortProperties));
+    in_props->format = cfg->fmt_type;
+    in_props->bits_per_pixel = cfg->bits_per_pixel;
+    in_props->width = cfg->width;
+    in_props->height = cfg->height;
+    in_props->stride = cfg->stride;
+    in_props->framerate.numerator = cfg->framerate.numerator;
+    in_props->framerate.denominator = cfg->framerate.denominator;
+
+    // Setup lookahead output port properties
+    out_props = &filter_props.output;
+    memset(out_props, 0, sizeof(XmaFilterPortProperties));
+    out_props->format = cfg->fmt_type;
+    out_props->bits_per_pixel = cfg->bits_per_pixel;
+    out_props->width = XLNX_ALIGN((in_props->width), 64)>>SCLEVEL1;
+    out_props->height = XLNX_ALIGN((in_props->height), 64)>>SCLEVEL1;
+    out_props->framerate.numerator = cfg->framerate.numerator;
+    out_props->framerate.denominator = cfg->framerate.denominator;
+
+    extn_params = &la_ctx->extn_params[0];
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamIntraPeriod];
+    extn_params[param_cnt].user_type = EParamIntraPeriod;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &cfg->gop_size;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamLADepth];
+    extn_params[param_cnt].user_type = EParamLADepth;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->lookahead_depth;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamEnableHwInBuf];
+    extn_params[param_cnt].user_type = EParamEnableHwInBuf;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->enableHwInBuf;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamSpatialAQMode];
+    extn_params[param_cnt].user_type = EParamSpatialAQMode;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->spatial_aq_mode;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamTemporalAQMode];
+    extn_params[param_cnt].user_type = EParamTemporalAQMode;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->temporal_aq_mode;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamRateControlMode];
+    extn_params[param_cnt].user_type = EParamRateControlMode;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->rate_control_mode;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamSpatialAQGain];
+    extn_params[param_cnt].user_type = EParamSpatialAQGain;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->spatial_aq_gain;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamNumBFrames];
+    extn_params[param_cnt].user_type = EParamNumBFrames;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &cfg->b_frames;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamCodecType];
+    extn_params[param_cnt].user_type = EParamCodecType;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &la_ctx->codec_type;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamLatencyLogging];
+    extn_params[param_cnt].user_type = EParamLatencyLogging;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &cfg->latency_logging;
+    param_cnt++;
+
+    extn_params[param_cnt].name = (char *)XLNX_LA_EXT_PARAMS[EParamDynamicGop];
+    extn_params[param_cnt].user_type = EParamDynamicGop;
+    extn_params[param_cnt].type = XMA_UINT32;
+    extn_params[param_cnt].length = sizeof(int);
+    extn_params[param_cnt].value = &cfg->dynamic_gop;
+    param_cnt++;
+
+    filter_props.param_cnt = param_cnt;
+    filter_props.params = &extn_params[0];
+
+    /*----------------------------------------------------
+      Allocate lookahead resource from XRM reserved resource
+      ----------------------------------------------------*/
+    la_ctx->lookahead_res_inuse = false;
+    ret = _allocate_xrm_la_cu(la_ctx, &filter_props);
+    if (ret < 0) {
+        av_log(la_ctx, AV_LOG_ERROR, "xrm_allocation: resource allocation failed\n");
+        return XMA_ERROR;
+    }
+
+    // Create lookahead session based on the requested properties
+    la_ctx->filter_session = xma_filter_session_create(&filter_props);
+    if (!la_ctx->filter_session) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "Failed to create lookahead session\n");
+        destroy_xlnx_la(la_ctx);
+        return NULL;
+    }
+    la_ctx->out_frame = (XmaFrame *) calloc(1, sizeof(XmaFrame));
+    if (la_ctx->out_frame == NULL) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "OOM la_ctx\n");
+        destroy_xlnx_la(la_ctx);
+        return NULL;
+    }
+    return (xlnx_lookahead_t)la_ctx;
+}
+
+int32_t destroy_xlnx_la(xlnx_lookahead_t la)
+{
+    xlnx_la_ctx *la_ctx;
+    if (!la) {
+        return XMA_ERROR;
+    }
+    la_ctx = (xlnx_la_ctx *)la;
+    if (la_ctx->bypass == 0) {
+        free_res(la_ctx);
+    }
+    free(la_ctx);
+    return XMA_SUCCESS;
+}
+
+static int32_t xlnx_la_send_frame(xlnx_la_ctx *la_ctx, XmaFrame *in_frame)
+{
+    int32_t rc;
+    if (!la_ctx) {
+        XLNX_LA_LOG(XMA_ERROR_LOG, "xlnx_la_send_frame : XMA_ERROR\n");
+        return XMA_ERROR;
+    }
+
+    if (in_frame && in_frame->do_not_encode) {
+        if (in_frame->data[0].buffer) {
+            if (in_frame->data[0].buffer_type == XMA_DEVICE_BUFFER_TYPE) {
+                XvbmBufferHandle handle = (XvbmBufferHandle)(in_frame->data[0].buffer);
+                if (handle) {
+                    xvbm_buffer_pool_entry_free(handle);
+                }
+            }
+        }
+        rc = XMA_SUCCESS;
+    } else {
+        rc = xma_filter_session_send_frame(la_ctx->filter_session,
+                                           in_frame);
+    }
+    if (rc <= XMA_ERROR) {
+        XLNX_LA_LOG(XMA_ERROR_LOG,
+                    "xlnx_la_send_frame : Send frame to LA xma plg Failed!!\n");
+        rc = XMA_ERROR;
+    }
+    return rc;
+}
+
+int32_t xlnx_la_send_recv_frame(xlnx_lookahead_t la, XmaFrame *in_frame,
+                                XmaFrame **out_frame)
+{
+    int32_t ret = 0;
+    xlnx_la_ctx *la_ctx = (xlnx_la_ctx *)la;
+    if (out_frame == NULL) {
+        return XMA_ERROR;
+    }
+    if (la_ctx->bypass == 1) {
+        *out_frame = in_frame;
+        return XMA_SUCCESS;
+    }
+    if (la_ctx->out_frame == NULL) {
+        return XMA_ERROR;
+    }
+
+    ret = xlnx_la_send_frame(la, in_frame);
+    switch (ret) {
+        case XMA_SUCCESS:
+            ret = xma_filter_session_recv_frame(la_ctx->filter_session, la_ctx->out_frame);
+            if (ret == XMA_TRY_AGAIN) {
+                ret = XMA_SEND_MORE_DATA;
+            }
+            break;
+        case XMA_SEND_MORE_DATA:
+            break;
+        case XMA_TRY_AGAIN:
+            // If the user is receiving output, this condition should not be hit.
+            ret = xma_filter_session_recv_frame(la_ctx->filter_session, la_ctx->out_frame);
+            if (ret == XMA_SUCCESS) {
+                ret = xlnx_la_send_frame(la, in_frame);
+            }
+            break;
+        case XMA_ERROR:
+        default:
+            *out_frame = NULL;
+            break;
+    }
+    if (ret == XMA_SUCCESS) {
+        *out_frame = la_ctx->out_frame;
+        la_ctx->out_frame = NULL;
+    }
+    return ret;
+}
+
+int32_t xlnx_la_release_frame(xlnx_lookahead_t la, XmaFrame *received_frame)
+{
+    if (!la) {
+        return XMA_ERROR;
+    }
+
+    xlnx_la_ctx *la_ctx = (xlnx_la_ctx *)la;
+    if (la_ctx->bypass) {
+        return XMA_SUCCESS;
+    }
+    if (!received_frame || la_ctx->out_frame) {
+        return XMA_ERROR;
+    }
+    la_ctx->out_frame = received_frame;
+    XmaSideDataHandle *side_data = la_ctx->out_frame->side_data;
+    memset(la_ctx->out_frame, 0, sizeof(XmaFrame));
+    la_ctx->out_frame->side_data = side_data;
+    return XMA_SUCCESS;
+}
+
+int32_t xlnx_la_in_bypass_mode(xlnx_lookahead_t la)
+{
+    int32_t ret = 0;
+    if (!la) {
+        return XMA_ERROR;
+    }
+    xlnx_la_ctx *la_ctx = (xlnx_la_ctx *)la;
+    ret = la_ctx->bypass;
+    return ret;
+}
diff --git a/libavcodec/xlnx_lookahead.h b/libavcodec/xlnx_lookahead.h
new file mode 100644
index 0000000000..9fec8d2208
--- /dev/null
+++ b/libavcodec/xlnx_lookahead.h
@@ -0,0 +1,65 @@
+/*
+ * Modifications Copyright (C) 2024 Advanced Micro Devices, Inc.
+ * Copyright (C) 2018 Xilinx Inc.
+ * All rights reserved.
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef XLNX_LOOKAHEAD_H
+#define XLNX_LOOKAHEAD_H
+
+#include <inttypes.h>
+#include <xma.h>
+
+typedef void *xlnx_lookahead_t;
+
+typedef enum
+{
+    EXlnxAvc,
+    EXlnxHevc
+} xlnx_codec_type_t;
+
+typedef struct
+{
+    int32_t            width; /**< width in pixels of data */
+    int32_t            height; /**< height in pixels of data */
+    int32_t            stride;
+    int32_t            bits_per_pixel; /**< bits per pixel of video format */
+    int32_t            gop_size;
+    uint32_t           lookahead_depth;
+    uint32_t           spatial_aq_mode;
+    uint32_t           temporal_aq_mode;
+    uint32_t           rate_control_mode;
+    uint32_t           spatial_aq_gain;
+    uint32_t           b_frames;
+    uint32_t           dynamic_gop;
+    XmaFormatType      fmt_type;
+    XmaFraction        framerate;
+    xlnx_codec_type_t  codec_type;
+    uint8_t            enableHwInBuf;
+    int32_t            latency_logging;
+    int               lxlnx_hwdev;
+} xlnx_la_cfg_t;
+
+xlnx_lookahead_t create_xlnx_la(xlnx_la_cfg_t *cfg);
+int32_t destroy_xlnx_la(xlnx_lookahead_t la);
+int32_t xlnx_la_send_recv_frame(xlnx_lookahead_t la, XmaFrame *in_frame,
+                                XmaFrame **out_frame);
+int32_t xlnx_la_release_frame(xlnx_lookahead_t la, XmaFrame *received_frame);
+int32_t xlnx_la_in_bypass_mode(xlnx_lookahead_t la);
+#endif //XLNX_LOOKAHEAD_H
diff --git a/libavcodec/xma_parser.c b/libavcodec/xma_parser.c
deleted file mode 100644
index dc8a197c67..0000000000
--- a/libavcodec/xma_parser.c
+++ /dev/null
@@ -1,62 +0,0 @@
-/*
- * This file is part of FFmpeg.
- *
- * FFmpeg is free software; you can redistribute it and/or
- * modify it under the terms of the GNU Lesser General Public
- * License as published by the Free Software Foundation; either
- * version 2.1 of the License, or (at your option) any later version.
- *
- * FFmpeg is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * Lesser General Public License for more details.
- *
- * You should have received a copy of the GNU Lesser General Public
- * License along with FFmpeg; if not, write to the Free Software
- * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
- */
-
-/**
- * @file
- * XMA2 audio parser
- */
-
-#include "parser.h"
-
-typedef struct XMAParserContext{
-    int skip_packets;
-} XMAParserContext;
-
-static int xma_parse(AVCodecParserContext *s1, AVCodecContext *avctx,
-                     const uint8_t **poutbuf, int *poutbuf_size,
-                     const uint8_t *buf, int buf_size)
-{
-    XMAParserContext *s = s1->priv_data;
-
-    if (buf_size % 2048 == 0) {
-        int duration = 0, packet, nb_packets = buf_size / 2048;
-
-        for (packet = 0; packet < nb_packets; packet++) {
-            if (s->skip_packets == 0) {
-                duration += buf[packet * 2048] * 128;
-                s->skip_packets = buf[packet * 2048 + 3] + 1;
-            }
-            s->skip_packets--;
-        }
-
-        s1->duration = duration;
-        s1->key_frame = !!duration;
-    }
-
-    /* always return the full packet. this parser isn't doing any splitting or
-       combining, only packet analysis */
-    *poutbuf      = buf;
-    *poutbuf_size = buf_size;
-    return buf_size;
-}
-
-const AVCodecParser ff_xma_parser = {
-    .codec_ids      = { AV_CODEC_ID_XMA2 },
-    .priv_data_size = sizeof(XMAParserContext),
-    .parser_parse   = xma_parse,
-};
diff --git a/libavfilter/Makefile b/libavfilter/Makefile
index 30cc329fb6..0b9ad07e5e 100644
--- a/libavfilter/Makefile
+++ b/libavfilter/Makefile
@@ -441,6 +441,7 @@ OBJS-$(CONFIG_SCALE_NPP_FILTER)              += vf_scale_npp.o scale_eval.o
 OBJS-$(CONFIG_SCALE_QSV_FILTER)              += vf_scale_qsv.o
 OBJS-$(CONFIG_SCALE_VAAPI_FILTER)            += vf_scale_vaapi.o scale_eval.o vaapi_vpp.o
 OBJS-$(CONFIG_SCALE_VULKAN_FILTER)           += vf_scale_vulkan.o vulkan.o vulkan_filter.o
+OBJS-$(CONFIG_MULTISCALE_XMA_FILTER)         += vf_multiscale_xma.o scale_eval.o
 OBJS-$(CONFIG_SCALE2REF_FILTER)              += vf_scale.o scale_eval.o
 OBJS-$(CONFIG_SCALE2REF_NPP_FILTER)          += vf_scale_npp.o scale_eval.o
 OBJS-$(CONFIG_SCDET_FILTER)                  += vf_scdet.o
@@ -538,6 +539,7 @@ OBJS-$(CONFIG_XFADE_FILTER)                  += vf_xfade.o
 OBJS-$(CONFIG_XFADE_OPENCL_FILTER)           += vf_xfade_opencl.o opencl.o opencl/xfade.o
 OBJS-$(CONFIG_XMEDIAN_FILTER)                += vf_xmedian.o framesync.o
 OBJS-$(CONFIG_XSTACK_FILTER)                 += vf_stack.o framesync.o
+OBJS-$(CONFIG_XVBM_CONVERT_FILTER)           += vf_xvbm_convert.o
 OBJS-$(CONFIG_YADIF_FILTER)                  += vf_yadif.o yadif_common.o
 OBJS-$(CONFIG_YADIF_CUDA_FILTER)             += vf_yadif_cuda.o vf_yadif_cuda.ptx.o \
                                                 yadif_common.o cuda/load_helper.o
diff --git a/libavfilter/allfilters.c b/libavfilter/allfilters.c
index 5ebacfde27..817fb4e52d 100644
--- a/libavfilter/allfilters.c
+++ b/libavfilter/allfilters.c
@@ -509,6 +509,7 @@ extern const AVFilter ff_vf_xfade;
 extern const AVFilter ff_vf_xfade_opencl;
 extern const AVFilter ff_vf_xmedian;
 extern const AVFilter ff_vf_xstack;
+extern const AVFilter ff_vf_xvbm_convert;
 extern const AVFilter ff_vf_yadif;
 extern const AVFilter ff_vf_yadif_cuda;
 extern const AVFilter ff_vf_yadif_videotoolbox;
@@ -516,6 +517,7 @@ extern const AVFilter ff_vf_yaepblur;
 extern const AVFilter ff_vf_zmq;
 extern const AVFilter ff_vf_zoompan;
 extern const AVFilter ff_vf_zscale;
+extern const AVFilter ff_vf_multiscale_xma;
 
 extern const AVFilter ff_vsrc_allrgb;
 extern const AVFilter ff_vsrc_allyuv;
diff --git a/libavfilter/avfilter.c b/libavfilter/avfilter.c
index 965f5d0f63..211102e34f 100644
--- a/libavfilter/avfilter.c
+++ b/libavfilter/avfilter.c
@@ -413,6 +413,12 @@ int ff_request_frame(AVFilterLink *link)
             /* Acknowledge status change. Filters using ff_request_frame() will
                handle the change automatically. Filters can also check the
                status directly but none do yet. */
+#if CONFIG_LIBXMA2API
+            if (strcmp(link->dst->filter->name,"multiscale_xma") ==0)
+               xma_multiscaler_filter_flush(link);   //Flush Multiscaler filter pipeline
+            else if (strcmp(link->dst->filter->name,"xvbm_convert") ==0)
+               xvbm_convert_filter_flush(link);     //Flush xvmb_convert filter pipeline
+#endif
             ff_avfilter_link_set_out_status(link, link->status_in, link->status_in_pts);
             return link->status_out;
         }
diff --git a/libavfilter/avfilter.h b/libavfilter/avfilter.h
index 2e8197c9a6..15e8685ea8 100644
--- a/libavfilter/avfilter.h
+++ b/libavfilter/avfilter.h
@@ -424,6 +424,7 @@ struct AVFilterContext {
 
     struct AVFilterGraph *graph;    ///< filtergraph this filter belongs to
 
+
     /**
      * Type of multithreading being allowed/used. A combination of
      * AVFILTER_THREAD_* flags.
@@ -1189,6 +1190,32 @@ char *avfilter_graph_dump(AVFilterGraph *graph, const char *options);
  */
 int avfilter_graph_request_oldest(AVFilterGraph *graph);
 
+/**
+ * Flush XMA abrscaler filter.
+ *
+ * @param AVFilter link to pass on to filter frame to flush device buffers.
+ *
+ */
+#if CONFIG_LIBXMA2API
+void xma_abrscaler_filter_flush(AVFilterLink *link);
+
+/**
+ * Flush XMA multiscaler filter.
+ *
+ * @param AVFilter link to pass on to filter frame to flush device buffers.
+ *
+ */
+void xma_multiscaler_filter_flush(AVFilterLink *link);
+
+/**
+ * Flush xvbm_convert filter.
+ *
+ * @param AVFilter link to pass on to filter frame to flush device buffers.
+ *
+ */
+void xvbm_convert_filter_flush(AVFilterLink *link);
+#endif
+
 /**
  * @}
  */
diff --git a/libavfilter/formats.c b/libavfilter/formats.c
index e8c2888c0c..9b110f78de 100644
--- a/libavfilter/formats.c
+++ b/libavfilter/formats.c
@@ -115,6 +115,13 @@ static int merge_formats_internal(AVFilterFormats *a, AVFilterFormats *b,
             const AVPixFmtDescriptor *const adesc = av_pix_fmt_desc_get(a->formats[i]);
             for (j = 0; j < b->nb_formats; j++) {
                 const AVPixFmtDescriptor *bdesc = av_pix_fmt_desc_get(b->formats[j]);
+                #if CONFIG_LIBXMA2API
+                if(!adesc || !bdesc) {
+                    av_log(NULL, AV_LOG_ERROR, "Unable to merge pixel formats %d, %d\n",
+                           a->formats[i], b->formats[j]);
+                    return AVERROR(EINVAL);
+                }
+                #endif
                 alpha2 |= adesc->flags & bdesc->flags & AV_PIX_FMT_FLAG_ALPHA;
                 chroma2|= adesc->nb_components > 1 && bdesc->nb_components > 1;
                 if (a->formats[i] == b->formats[j]) {
diff --git a/libavfilter/vf_multiscale_xma.c b/libavfilter/vf_multiscale_xma.c
new file mode 100644
index 0000000000..842f05dedd
--- /dev/null
+++ b/libavfilter/vf_multiscale_xma.c
@@ -0,0 +1,1075 @@
+/*
+ * Modifications Copyright (C) 2024 Advanced Micro Devices, Inc.
+ * Copyright (C) 2018 Xilinx Inc.
+ * All rights reserved.
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 3.0 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * video Multi Scaler IP (in ABR mode) with Xilinx Media Accelerator
+ */
+
+#include <stdio.h>
+#include <unistd.h>
+#include <xma.h>
+#include <xmaplugin.h>
+#include <xrm.h>
+
+#include "libavutil/attributes.h"
+#include "libavutil/internal.h"
+#include "libavutil/mem.h"
+#include "libavutil/opt.h"
+#include "libavutil/imgutils.h"
+#include "libavutil/pixfmt.h"
+
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+#include "video.h"
+#include <xvbm.h>
+#include <dlfcn.h>
+#include <errno.h>
+
+#include "../xmaPropsTOjson.h"
+
+#define MAX_OUTS            8
+#define MAX_PARAMS          3
+#define SCL_IN_STRIDE_ALIGN    256
+#define SCL_IN_HEIGHT_ALIGN    64
+
+#define SCL_OUT_STRIDE_ALIGN    32
+#define SCL_OUT_HEIGHT_ALIGN    32
+
+#define MAX_INPUT_WIDTH     3840
+#define MAX_INPUT_HEIGHT    2160
+#define MAX_INPUT_PIXELS    (MAX_INPUT_WIDTH * MAX_INPUT_HEIGHT)
+#define XRM_PRECISION_1000000_BIT_MASK(load) ((load << 8))
+
+#define ALIGN(width,align) (((width) + (align) - 1) & ~((align) - 1))
+
+#undef DUMP_OUT_FRAMES
+#undef DUMP_FRAME_PARAM
+
+#ifdef DUMP_OUT_FRAMES
+FILE *outfp = NULL;
+FILE *yfp = NULL;
+#endif
+
+typedef enum {
+    SC_SESSION_ALL_RATE = 0,
+    SC_SESSION_FULL_RATE,
+    SC_MAX_SESSIONS
+} MultiScalerSessionType;
+
+typedef enum MultiScalerSupportedBitdepth {
+	SC_BITDEPTH_8BIT = 8,
+	SC_BITDEPTH_10BIT = 10,
+};
+
+typedef struct MultiScalerContext {
+    const AVClass    *class;
+    int               nb_outputs;
+    int               lxlnx_hwdev;
+    int               out_width[MAX_OUTS];
+    int               out_height[MAX_OUTS];
+    char             *out_format[MAX_OUTS];
+    char             *out_rate[MAX_OUTS];
+    unsigned int      fps;
+    AVRational        in_frame_rate;
+    AVRational        out_frame_rate[MAX_OUTS];
+    int              *copyOutLink;
+    int               flush;
+    int               send_status;
+    int               frames_out;
+    int               enable_pipeline;
+    int               latency_logging;
+    int               num_sessions;
+    int               session_frame;
+    uint64_t          p_mixrate_session;
+    int               session_nb_outputs[SC_MAX_SESSIONS];
+    char              sc_param_name[MAX_PARAMS][50];
+    XmaParameter      sc_params[MAX_PARAMS];
+    XmaScalerSession *session[SC_MAX_SESSIONS];
+    xrmContext       *xrm_ctx;
+    xrmCuResourceV2   scalerCuRes[SC_MAX_SESSIONS];
+    bool              scaler_res_inuse;
+    int               xrm_scalres_count;
+    int               xrm_reserve_id;
+    int               xrm_alloc_st[SC_MAX_SESSIONS];
+    int               bits_per_sample;
+} MultiScalerContext;
+
+
+static int multiscale_xma_filter_frame(AVFilterLink *link, AVFrame *frame);
+static int output_config_props(AVFilterLink *outlink);
+static int validate_rate_config(MultiScalerContext *ctx);
+static int get_num_scaler_sessions(MultiScalerContext *ctx);
+static int get_num_full_rate_outputs(MultiScalerContext *ctx);
+static void write_session_log(MultiScalerContext *ctx);
+
+static int mpsoc_report_error(MultiScalerContext *ctx, const char *err_str, int32_t err_type)
+{
+    if (ctx)
+        av_log(NULL, AV_LOG_ERROR, "scaler error: %s: ffmpeg pid %d on device index =  %d cu index = %d\n",
+               err_str, getpid(), ctx->scalerCuRes[ctx->session_frame].deviceId,
+               ctx->scalerCuRes[ctx->session_frame].cuId);
+
+    return err_type;
+}
+
+static int validate_rate_config(MultiScalerContext *ctx)
+{
+    int i, ret;
+    int count = 0;
+
+    //All outputs @half-rate not supported
+    for (i = 0; i < ctx->nb_outputs; ++i) {
+        if (strcmp(ctx->out_rate[i], "half") == 0) {
+            count += 1;
+            ctx->out_frame_rate[i].num = ctx->in_frame_rate.num /2 ;
+            ctx->out_frame_rate[i].den = ctx->in_frame_rate.den ;
+        }
+        else if (strcmp(ctx->out_rate[i], "full") == 0)
+        {
+            ctx->out_frame_rate[i].num = ctx->in_frame_rate.num ;
+            ctx->out_frame_rate[i].den = ctx->in_frame_rate.den ;
+        }
+        else if (strcmp(ctx->out_rate[i], "full") != 0)
+        {
+          return -2;
+        }
+    }
+    ret = ((ctx->nb_outputs == count) ? -1 : 0);
+    return (ret);
+}
+
+static int get_num_scaler_sessions(MultiScalerContext *ctx)
+{
+    int i;
+    int count = 1;
+
+    /* default = 1 session - full rate
+       However if Mix out_rate is found then 2 sessions will
+       be created to allow for frame drops.
+    */
+    for (i = 0; i < ctx->nb_outputs; ++i) {
+        if (strcmp(ctx->out_rate[i], "full") != 0) {
+            count = 2;
+            break;
+        }
+    }
+    return (count);
+}
+
+static int get_num_full_rate_outputs(MultiScalerContext *ctx)
+{
+    int i;
+    int count = 0;
+    bool have_gotten_half_rate = 0;
+    for (i = 0; i < ctx->nb_outputs; ++i) {
+        if (strcmp(ctx->out_rate[i], "full") == 0) {
+            if(have_gotten_half_rate) {
+                av_log (NULL, AV_LOG_ERROR, "[%s][%d]ERROR : Full rate "
+                        "specified after half rate! Full rate outputs must "
+                        "preceed half rates. Output id %d\n", __func__,
+                        __LINE__, i);
+                return AVERROR(EINVAL);
+            }
+            count += 1;
+        } else {
+            have_gotten_half_rate = 1;
+        }
+    }
+    return (count);
+}
+
+static void write_session_log(MultiScalerContext *ctx)
+{
+    int i, count;
+
+    av_log(NULL, AV_LOG_DEBUG, "  Multi-Scaler Session Configuration\n");
+    av_log(NULL, AV_LOG_DEBUG, "---------------------------------------\n");
+    av_log(NULL, AV_LOG_DEBUG, "Num Sessions = %d\n\n", ctx->num_sessions);
+
+    for (count = 0; count < ctx->num_sessions; ++count) {
+        av_log(NULL, AV_LOG_DEBUG, "Session:  %d\n", count);
+        if (ctx->num_sessions > 1) {
+            av_log(NULL, AV_LOG_DEBUG, "Type   :  %s\n", ((count) ? "FULL RATE ONLY" : "HALF RATE"));
+        } else {
+            av_log(NULL, AV_LOG_DEBUG, "Type   :  %s\n", "ALL RATE");
+        }
+        av_log(NULL, AV_LOG_DEBUG, "Num Out:  %d\n", ctx->session_nb_outputs[count]);
+        for (i = 0; i < ctx->session_nb_outputs[count]; ++i) {
+            av_log(NULL, AV_LOG_DEBUG, "out_%d :  (%4d x %4d) @%d fps\n", i, ctx->out_width[i], ctx->out_height[i], ctx->fps);
+        }
+        av_log(NULL, AV_LOG_DEBUG, "--------------------------\n");
+    }
+}
+
+static enum AVPixelFormat multiscale_xma_get_pix_fmt (enum AVPixelFormat av_src_format, const char *name)
+{
+    if (strcmp (name, "xlnx_xvbm") == 0) {
+        switch (av_src_format) {
+            case AV_PIX_FMT_NV12:
+            case AV_PIX_FMT_XVBM_8:
+                return AV_PIX_FMT_XVBM_8;
+            case AV_PIX_FMT_XV15:
+            case AV_PIX_FMT_XVBM_10:
+                return AV_PIX_FMT_XVBM_10;
+            default:
+                return AV_PIX_FMT_XVBM_8;
+        }
+    } else return av_get_pix_fmt (name);
+}
+
+static XmaFormatType get_xma_format (enum AVPixelFormat av_format)
+{
+    const AVPixFmtDescriptor *desc;
+    switch (av_format) {
+        case AV_PIX_FMT_NV12:
+        case AV_PIX_FMT_XVBM_8:
+            return XMA_VCU_NV12_FMT_TYPE;
+        case AV_PIX_FMT_XV15:
+        case AV_PIX_FMT_XVBM_10:
+            return XMA_VCU_NV12_10LE32_FMT_TYPE;
+        case AV_PIX_FMT_BGR24:
+            return XMA_RGB888_FMT_TYPE;
+        default:
+            desc = av_pix_fmt_desc_get(av_format);
+            if (desc != NULL)
+                av_log (NULL, AV_LOG_ERROR, "[%s][%d]ERROR : unsupported format %s\n", __func__, __LINE__, desc->name);
+            else
+                av_log (NULL, AV_LOG_ERROR, "[%s][%d]ERROR : unsupported format\n", __func__, __LINE__);
+            return XMA_NONE_FMT_TYPE;
+    }
+}
+
+//XRM scaler plugin load calculation
+static int _calc_scal_load(AVFilterContext *ctx, xrmContext *xrm_ctx, XmaScalerProperties *props, int32_t func_id, int32_t *scal_load)
+{
+    char pluginName[XRM_MAX_NAME_LEN];
+    char *err;
+
+    xrmPluginFuncParam param;
+    void *handle;
+    void (*convertXmaPropsToJson)(void* props, char* funcName, char* jsonJob);
+
+    memset(&param, 0, sizeof(xrmPluginFuncParam));
+    handle = dlopen("/opt/xilinx/xrm/plugin/libxmaPropsTOjson.so", RTLD_NOW );
+    if (!handle) {
+        av_log(ctx, AV_LOG_ERROR, "Unable to load libxmaPropsTOjson.so  - %s\n", dlerror());
+        return XMA_ERROR;
+    }
+    dlerror(); /* clear error code */
+    convertXmaPropsToJson = dlsym(handle, "convertXmaPropsToJson");
+    if ((err = dlerror()) != NULL) {
+         av_log(ctx, AV_LOG_ERROR, "convertXmaPropsToJson symbol not found\n");
+         return XMA_ERROR;
+    }
+    (*convertXmaPropsToJson) (props, (char *)"SCALER", param.input);
+    dlclose(handle);
+
+    strcpy(pluginName, "xrmU30ScalPlugin");
+    if (xrmExecPluginFunc(xrm_ctx, pluginName, func_id, &param) != XRM_SUCCESS)
+    {
+        av_log(ctx, AV_LOG_ERROR, "xrm_load_calculation: scaler plugin function %d, fail to run the function\n", func_id);
+        return XMA_ERROR;
+    }
+    else {
+         *scal_load = atoi((char*)(strtok(param.output, " ")));
+         if (*scal_load <= 0)
+         {
+            av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: scaler plugin function %d, calculated wrong load %d .\n", *scal_load);
+            return XMA_ERROR;
+         }
+         else if (*scal_load > XRM_MAX_CU_LOAD_GRANULARITY_1000000)
+         {
+            av_log(NULL, AV_LOG_ERROR, "xrm_load_calculation: scaler plugin function %d, calculated load %d is greater than maximum supported.\n", *scal_load);
+            return XMA_ERROR;
+         }
+
+    }
+
+    return 0;
+
+}
+
+static int _allocate_xrm_scaler_cu(AVFilterContext *ctx, XmaScalerProperties *props)
+{
+    int32_t scal_load=0, func_id = 0;
+    int ret = -1;
+    int xrm_reserve_id = -1;
+    char* endptr;
+
+    uint64_t deviceInfoDeviceIndex = 0;
+    uint64_t deviceInfoContraintType = XRM_DEVICE_INFO_CONSTRAINT_TYPE_HARDWARE_DEVICE_INDEX;
+
+    MultiScalerContext  *s = ctx->priv;
+    xrmCuPropertyV2 scalerCuProp;
+
+    if (getenv("XRM_RESERVE_ID")) {
+        errno = 0;
+         xrm_reserve_id = strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);
+        if (errno != 0)
+        {
+           av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_RESERVE_ID in scaler filter plugin\n");
+           return -1;
+        }
+    }
+
+    ret = _calc_scal_load(ctx, s->xrm_ctx, props, func_id, &scal_load);
+    if (ret < 0) return ret;
+
+    //XRM scaler cu allocation
+    memset(&scalerCuProp,                        0, sizeof(xrmCuPropertyV2));
+    memset(&s->scalerCuRes[s->xrm_scalres_count], 0, sizeof(xrmCuResourceV2));
+
+    strcpy(scalerCuProp.kernelName,  "scaler");
+    strcpy(scalerCuProp.kernelAlias, "SCALER_MPSOC");
+
+    scalerCuProp.devExcl     = false;
+    scalerCuProp.requestLoad = XRM_PRECISION_1000000_BIT_MASK(scal_load);
+
+    if ((s->lxlnx_hwdev > -1) && (xrm_reserve_id > -1)) { //2dev mode launcher
+        deviceInfoDeviceIndex = s->lxlnx_hwdev;
+        scalerCuProp.deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) |
+                                  (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+        scalerCuProp.poolId = xrm_reserve_id;
+    }
+    else if (xrm_reserve_id > -1) { //1dev mode launcher
+        scalerCuProp.poolId = xrm_reserve_id;
+    }
+    else if((s->lxlnx_hwdev > -1) || getenv("XRM_DEVICE_ID")) { //explicit ffmpeg device command
+        if(s->lxlnx_hwdev > -1) {
+            deviceInfoDeviceIndex = s->lxlnx_hwdev;
+        }
+        else {
+            errno = 0;
+            deviceInfoDeviceIndex =  strtol(getenv("XRM_DEVICE_ID"), &endptr, 0);
+            if (errno != 0)
+            {
+                av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_DEVICE_ID in scaler plugin\n");
+                return -1;
+            }
+        }
+        scalerCuProp.deviceInfo = (deviceInfoDeviceIndex << XRM_DEVICE_INFO_DEVICE_INDEX_SHIFT) |
+                                  (deviceInfoContraintType << XRM_DEVICE_INFO_CONSTRAINT_TYPE_SHIFT);
+    }
+
+    ret = xrmCuAllocV2(s->xrm_ctx, &scalerCuProp, &s->scalerCuRes[s->xrm_scalres_count]);
+    if (ret != 0) {
+        av_log(ctx, AV_LOG_ERROR, "xrm_allocation: fail (err_code=%d) to allocate scaler cu from reserve id=%d or device=%d \n",
+                          ret, s->xrm_reserve_id, deviceInfoDeviceIndex);
+        return XMA_ERROR;
+    }
+
+    //Set XMA plugin SO and device index
+    props->plugin_lib     = s->scalerCuRes[s->xrm_scalres_count].kernelPluginFileName;
+    props->dev_index      = s->scalerCuRes[s->xrm_scalres_count].deviceId;
+    props->cu_index       = s->scalerCuRes[s->xrm_scalres_count].cuId;
+    props->channel_id     = s->scalerCuRes[s->xrm_scalres_count].channelId;
+    props->ddr_bank_index = -1;//XMA to select the ddr bank based on xclbin meta data
+
+    s->xrm_alloc_st[s->xrm_scalres_count]= 1;
+
+    av_log(NULL, AV_LOG_DEBUG, "---scaler[%d] xrm out: scal_load=%d, plugin=%s, device=%d, cu=%d, ch=%d  \n",
+    s->xrm_scalres_count, scal_load, props->plugin_lib, props->dev_index, props->cu_index, props->channel_id);
+
+    return 0;
+}
+
+static av_cold int multiscale_xma_init(AVFilterContext *ctx)
+{
+    int i = 0;
+    MultiScalerContext *s = ctx->priv;
+    s->frames_out = 0;
+
+    memset (s->xrm_alloc_st, 0, SC_MAX_SESSIONS*sizeof(int));
+#ifdef DUMP_OUT_FRAMES
+    outfp = fopen ("outframes.yuv", "w+");
+    yfp = fopen ("outframes_y.yuv", "w+");
+#endif
+
+    for (i = 0; i < s->nb_outputs; i++) {
+        char name[32];
+        AVFilterPad pad = { 0 };
+
+        snprintf(name, sizeof(name), "output%d", i);
+        pad.type = ctx->filter->inputs[0].type;
+        pad.name = av_strdup(name);
+        if (!pad.name) {
+            av_log(ctx, AV_LOG_ERROR, "out of memory\n");
+            return AVERROR(ENOMEM);
+        }
+        pad.config_props = output_config_props;
+        ff_append_outpad(ctx, &pad);
+    }
+    return 0;
+}
+
+static av_cold void multiscale_xma_uninit(AVFilterContext *ctx)
+{
+    int i;
+    MultiScalerContext *s = ctx->priv;
+
+#ifdef DUMP_OUT_FRAMES
+    fclose (outfp);
+    fclose (yfp);
+#endif
+    for (i = 0; i < ctx->nb_outputs; i++)
+        av_freep(&ctx->output_pads[i].name);
+
+       for (int idx=0; idx < s->num_sessions; idx++) {
+          if (s->session[idx])
+            xma_scaler_session_destroy(s->session[idx]);
+       }
+    if (s->xrm_ctx) {
+
+       //XRM scaler de-allocation
+       for (int idx=0; idx <= s->xrm_scalres_count; idx++) {
+             if (s->xrm_alloc_st[idx]==1) //Release only when resource is allocated
+             {
+                if (!(xrmCuReleaseV2(s->xrm_ctx, &s->scalerCuRes[idx])))
+                   av_log(NULL, AV_LOG_ERROR, "XRM: fail to release scaler HW cu idx=%d\n",idx);
+             }
+       }
+
+       if (xrmDestroyContext(s->xrm_ctx) != XRM_SUCCESS)
+        av_log(NULL, AV_LOG_ERROR, "XRM : scaler destroy context failed\n");
+    }
+}
+
+int output_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->src;
+    MultiScalerContext *s = ctx->priv;
+    const int outlink_idx = FF_OUTLINK_IDX(outlink);
+    AVFilterLink *out = outlink->src->outputs[outlink_idx];
+
+    out->w = s->out_width[outlink_idx];
+    out->h = s->out_height[outlink_idx];
+    outlink->sample_aspect_ratio = (AVRational) {1, 1};
+
+    //Set correct out fps for each channel
+    outlink->frame_rate.num = s->out_frame_rate[outlink_idx].num;
+    outlink->frame_rate.den = s->out_frame_rate[outlink_idx].den;
+    //av_log(ctx, AV_LOG_INFO, "---channelid[%d]:  fps set as %d/%d\n", outlink_idx, outlink->frame_rate.num,outlink->frame_rate.den );
+
+    return 0;
+}
+
+static int multiscale_xma_config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->dst;
+    AVFilterLink *inlink = outlink->dst->inputs[0];
+    enum AVPixelFormat outpixfmt;
+    XmaScalerProperties props;
+    MultiScalerContext *s = ctx->priv;
+    int n = 0, count=0, ret;
+    int chan_id = 0;
+    char* endptr;
+
+    s->fps = 25;
+    s->p_mixrate_session = 0;
+
+    if (inlink->format == AV_PIX_FMT_YUV420P10LE || inlink->format == AV_PIX_FMT_XV15 ||
+        inlink->format == AV_PIX_FMT_XVBM_10)
+        s->bits_per_sample = SC_BITDEPTH_10BIT;
+    else if (inlink->format == AV_PIX_FMT_NV12 ||
+             inlink->format == AV_PIX_FMT_XVBM_8)
+        s->bits_per_sample = SC_BITDEPTH_8BIT;
+
+    memset((void*)&props, 0, sizeof(XmaScalerProperties));
+    props.hwscaler_type = XMA_POLYPHASE_SCALER_TYPE;
+    strcpy(props.hwvendor_string, "Xilinx");
+    props.num_outputs = s->nb_outputs;
+
+    props.input.format = get_xma_format(inlink->format);
+    if ((props.input.format)==XMA_NONE_FMT_TYPE)
+       return XMA_ERROR;
+
+    props.input.width  = inlink->w;
+    props.input.height = inlink->h;
+
+    //Validate input resolution against MAX supported
+    if ((inlink->w > MAX_INPUT_WIDTH) || //for landscape use-case
+        (inlink->h > MAX_INPUT_WIDTH) || //for portrait use-case
+        ((inlink->w * inlink->h) > MAX_INPUT_PIXELS)) {
+        av_log (ctx, AV_LOG_ERROR, "MultiScaler Input %4dx%4d exceeds max supported resolution %4dx%4d (or %4dx%4d portrait mode)\n",
+                inlink->w, inlink->h, MAX_INPUT_WIDTH, MAX_INPUT_HEIGHT, MAX_INPUT_HEIGHT, MAX_INPUT_WIDTH);
+       return XMA_ERROR;
+    }
+
+    if (outlink->time_base.den > 0) {
+        int fps = outlink->frame_rate.num/outlink->frame_rate.den;
+        av_log(NULL, AV_LOG_DEBUG, "fps set as %d/%d=%d\n", outlink->frame_rate.num,outlink->frame_rate.den, fps);
+        s->fps = fps;
+        s->in_frame_rate.num = outlink->frame_rate.num;
+        s->in_frame_rate.den = outlink->frame_rate.den;
+    }
+
+    props.input.framerate.numerator   = s->fps;
+    props.input.framerate.denominator = 1;
+
+    //When coeffLoad is set to 2, app expects a FilterCoeff.txt to load coefficients from
+    for (n=0; n < MAX_OUTS; n++) {
+        if (props.output[n].coeffLoad==2) {
+            sprintf(props.input.coeffFile, "FilterCoeff.txt");
+            break;
+        }
+    }
+
+    //run-time parameter configuration
+    strcpy(s->sc_param_name[0], "enable_pipeline");    s->sc_params[0].name  = s->sc_param_name[0];    s->sc_params[0].type = XMA_UINT32;    s->sc_params[0].length = sizeof(s->enable_pipeline);  s->sc_params[0].value  = &(s->enable_pipeline);
+    strcpy(s->sc_param_name[1], "MixRate");            s->sc_params[1].name  = s->sc_param_name[1];    s->sc_params[1].type = XMA_UINT64;    s->sc_params[1].length = sizeof(s->p_mixrate_session);  s->sc_params[1].value  = &(s->p_mixrate_session);
+    strcpy(s->sc_param_name[2], "latency_logging");    s->sc_params[2].name  = s->sc_param_name[2];    s->sc_params[2].type = XMA_UINT32;    s->sc_params[2].length = sizeof(s->latency_logging);    s->sc_params[2].value  = &(s->latency_logging);
+    props.params           = s->sc_params;
+    props.param_cnt        = MAX_PARAMS;
+
+    //validate rate configuration params
+    ret = validate_rate_config(s);
+    if(ret ==-1) {
+        av_log (ctx, AV_LOG_ERROR, "Multi Scaler Configuration - All outputs at half-rate not supported\n");
+        return XMA_ERROR;
+    }
+    else if (ret ==-2) {
+        av_log (ctx, AV_LOG_ERROR, "Multi Scaler Configuration -outputs rate config shall be given 'half' or 'full' only and all outputs at half rate is not supported.\n");
+        return XMA_ERROR;
+    }
+
+    //determine num sessions to create
+    s->num_sessions = get_num_scaler_sessions(s);
+
+    //All-rate session includes all outputs
+    s->session_nb_outputs[SC_SESSION_ALL_RATE] = s->nb_outputs;
+
+     if (s->num_sessions > 1) {
+        s->session_nb_outputs[SC_SESSION_FULL_RATE] = get_num_full_rate_outputs(s);
+        if(s->session_nb_outputs[SC_SESSION_FULL_RATE] < 0) {
+            return XMA_ERROR;
+        }
+        // 2 sessions with half input frame-rate each
+        s->fps /= 2;
+        props.input.framerate.numerator     = s->fps;
+        props.input.framerate.denominator   = 1;
+    }
+    //log session configuration
+    write_session_log(s);
+
+    //create XRM local context
+    s->xrm_ctx = (xrmContext *)xrmCreateContext(XRM_API_VERSION_1);
+    if (ctx == NULL) {
+        av_log (ctx, AV_LOG_ERROR, "create local XRM context failed\n");
+        return XMA_ERROR;
+    }
+
+    //Get XRM Reservation Id
+    if (getenv("XRM_RESERVE_ID")) {
+       errno = 0;
+       s->xrm_reserve_id = strtol(getenv("XRM_RESERVE_ID"), &endptr, 0);
+       if (errno != 0)
+       {
+          av_log(NULL, AV_LOG_ERROR, "Fail to use XRM_RESERVE_ID in scaler filter plugin\n");
+          return -1;
+       }
+    } else {
+        s->xrm_reserve_id = -1;
+    }
+
+    for (count = 0; count < s->num_sessions; ++count) {
+        props.num_outputs = s->session_nb_outputs[count];
+
+        for (chan_id = 0; chan_id < props.num_outputs; chan_id++) {
+            props.output[chan_id].format         =  get_xma_format(multiscale_xma_get_pix_fmt(inlink->format, s->out_format[chan_id]));
+            if ((props.output[chan_id].format)==XMA_NONE_FMT_TYPE)
+               return XMA_ERROR;
+            outpixfmt = multiscale_xma_get_pix_fmt(inlink->format, s->out_format[chan_id]);
+            if (((s->bits_per_sample == SC_BITDEPTH_10BIT) && ((outpixfmt == AV_PIX_FMT_NV12) || (outpixfmt == AV_PIX_FMT_XVBM_8))) ||
+                ((s->bits_per_sample == SC_BITDEPTH_8BIT) && ((outpixfmt == AV_PIX_FMT_XV15) || (outpixfmt == AV_PIX_FMT_XVBM_10)))) {
+                av_log (NULL, AV_LOG_ERROR, "[%s][%d]ERROR : multiscaler output format is %s, but incoming bits per pixel is %d!\n",
+                        __func__, __LINE__, s->out_format[chan_id], s->bits_per_sample);
+                return AVERROR(EINVAL);
+            }
+            props.output[chan_id].bits_per_pixel = s->bits_per_sample;
+            props.output[chan_id].width          = s->out_width[chan_id];
+            props.output[chan_id].height         = s->out_height[chan_id];
+            props.output[chan_id].coeffLoad      = 0;
+            props.output[chan_id].framerate.numerator   = props.input.framerate.numerator;
+            props.output[chan_id].framerate.denominator = props.input.framerate.denominator;
+
+           if ((s->out_width[chan_id] > MAX_INPUT_WIDTH) || //for landscape use-case
+                (s->out_height[chan_id] > MAX_INPUT_WIDTH) || //for portrait use-case
+                ((s->out_width[chan_id] * s->out_height[chan_id] ) > MAX_INPUT_PIXELS))
+           {
+                av_log (ctx, AV_LOG_ERROR, "MultiScaler Output %4dx%4d exceeds max supported resolution %4dx%4d (or %4dx%4d portrait mode)\n",
+                s->out_width[chan_id], s->out_height[chan_id], MAX_INPUT_WIDTH, MAX_INPUT_HEIGHT, MAX_INPUT_HEIGHT, MAX_INPUT_WIDTH);
+                return XMA_ERROR;
+           }
+        }
+
+        /*----------------------------------------------------
+          Allocate scaler resource from XRM reserved resource
+         ----------------------------------------------------*/
+        s->xrm_scalres_count = count;
+        if(_allocate_xrm_scaler_cu(ctx, &props) < 0) {
+            av_log(ctx, AV_LOG_ERROR, "XRM_ALLOCATION: resource allocation failed\n");
+            return XMA_ERROR;
+        }
+
+        s->session[count] = xma_scaler_session_create(&props);
+        if (!s->session[count]) {
+            av_log(ctx, AV_LOG_ERROR, "session %d creation failed.\n", count);
+            return XMA_ERROR;
+        }
+        s->p_mixrate_session = (uint64_t)s->session[count]; //send first session handle to next session
+    }
+    s->session_frame = 0; //start with even frame
+
+    return 0;
+}
+
+void xma_multiscaler_filter_flush(AVFilterLink *link)
+{
+    AVFilterLink *inlink = link->dst->inputs[0];
+    AVFilterContext *ctx = link->dst;
+    MultiScalerContext *s = ctx->priv;
+    int ret = s->send_status;
+    int rtt = -1;
+    int count = 0;
+    int flush_status = 0;
+    int *outLink = (int *)link;
+    AVFrame *nframe = av_frame_alloc();
+
+    nframe->format = s->bits_per_sample == SC_BITDEPTH_8BIT ? AV_PIX_FMT_NV12 :
+                     AV_PIX_FMT_XV15; // sending dummy fixed format
+    nframe->width  = inlink->w;
+    nframe->height = inlink->h;
+
+    /* creating dummy AVFrame */
+    rtt =  av_frame_get_buffer(nframe, SCL_IN_STRIDE_ALIGN);
+    if (rtt < 0) {
+        av_log(ctx, AV_LOG_ERROR, "failed to create dummy AV frame\n");
+        return;
+    }
+
+    if (outLink == s->copyOutLink) {
+        s->flush        = 1;
+        nframe->data[0] = NULL;
+        nframe->data[1] = NULL;
+        nframe->data[2] = NULL;
+        //flush pipeline for all sessions
+        for (count = 0; count < s->num_sessions; ++count) {
+            while (ret != XMA_EOS) {
+                flush_status= multiscale_xma_filter_frame(link, nframe);
+                ret = s->send_status;
+                //exit in cases where scaler erros out at send/recv frame
+                if (flush_status == -1)
+                  break;
+            }
+            //reset status for last frame in last session
+            ret = XMA_SUCCESS;
+        }
+    }
+
+    if (nframe->data[0])
+        av_freep(&nframe->data[0]) ;
+    if (nframe->data[1])
+        av_freep(&nframe->data[1]);
+    if (nframe->data[2])
+        av_freep(&nframe->data[2]);
+    av_frame_free(&nframe);
+}
+
+static int
+multiscale_xma_filter_frame(AVFilterLink *link, AVFrame *in_frame)
+{
+    AVFilterContext *ctx = link->dst;
+    MultiScalerContext *s = ctx->priv;
+    XmaFrame *xframe = NULL;
+    int ret = 0;
+    int i = 0;
+    int plane_id;
+    int session_num_out = 0;
+    AVFrame *a_frame_list[MAX_OUTS] = {0};
+    XmaFrame *x_frame_list[MAX_OUTS] = {0};
+    XmaFrameData frame_data = {0, };
+    XmaFrameProperties frame_props = {0, };
+    XmaScalerSession    *curr_session;
+    MultiScalerSessionType  session_type;
+
+    s->copyOutLink = (int*)link;
+
+    if (s->num_sessions > 1) {
+        //Odd Frame = SC_SESSION_FULL_RATE, Even Frame = SC_SESSION_ALL_RATE
+        session_type = ((s->session_frame & 0x01) ? SC_SESSION_FULL_RATE : SC_SESSION_ALL_RATE);
+        s->session_frame = (s->session_frame + 1) % SC_MAX_SESSIONS;
+    } else {
+        session_type = SC_SESSION_ALL_RATE;
+    }
+    curr_session    = s->session[session_type];
+    session_num_out = s->session_nb_outputs[session_type];
+
+    if ((AV_PIX_FMT_XVBM_8 == in_frame->format) || (AV_PIX_FMT_XVBM_10 == in_frame->format)) {
+        xframe = av_frame_get_xma_frame (in_frame);
+        xvbm_buffer_refcnt_inc (xframe->data[0].buffer);
+        xframe->pts = in_frame->pts; // Not required if previous elements packs pts
+    } else {
+        // Clone input frame from an AVFrame to an XmaFrame
+        frame_props.format = get_xma_format(in_frame->format);
+        frame_props.width  = in_frame->width;
+        frame_props.height = in_frame->height;
+
+        frame_props.bits_per_pixel = s->bits_per_sample;
+        if(frame_props.format == XMA_VCU_NV12_10LE32_FMT_TYPE) {
+            frame_props.bits_per_pixel = 10;
+        }
+
+        for (plane_id = 0; plane_id < av_pix_fmt_count_planes (in_frame->format); plane_id++) {
+            frame_props.linesize[plane_id] = in_frame->linesize[plane_id];
+            frame_data.data[plane_id] = in_frame->data[plane_id];
+        }
+
+        xframe = xma_frame_from_buffers_clone(&frame_props, &frame_data);
+        xframe->pts = in_frame->pts;
+    }
+
+    // Copy AVFrame HDR side data to XMAFrame
+    if(in_frame->side_data){
+        AVFrameSideData *avframe_sidedata = av_frame_get_side_data(in_frame, AV_FRAME_XLNX_HDR_SIDEBAND_DATA);
+        if (avframe_sidedata)
+        {
+            uint8_t *sd_ptr = (uint8_t*)avframe_sidedata->data;
+            size_t  sd_size = avframe_sidedata->size;
+            XmaSideDataHandle hdr_sd = xma_side_data_alloc(sd_ptr, XMA_FRAME_HDR, sd_size, 0);
+            if(hdr_sd == NULL) {
+                av_log (ctx, AV_LOG_ERROR, "Failed to allocate XMA side data memory \n");
+                return AVERROR(ENOMEM);
+            }
+            xma_frame_add_side_data(xframe, hdr_sd);
+            xma_side_data_dec_ref(hdr_sd);
+            av_frame_remove_side_data(in_frame, AV_FRAME_XLNX_HDR_SIDEBAND_DATA);
+        }
+    }
+
+#ifdef DUMP_FRAME_PARAM
+    av_log(NULL, AV_LOG_INFO, "MultiScaler Input : w = %d, h = %d, fmt = %d, bps = %d, pts = %lld, data[0] = %p, data[1] = %p, data[2] = %p\n",
+        frame_props.width, frame_props.height, frame_props.format, frame_props.bits_per_pixel, in_frame->pts,
+        frame_data.data[0], frame_data.data[1], frame_data.data[2]);
+#endif
+
+    s->send_status = xma_scaler_session_send_frame(curr_session, xframe);
+
+    /* only receive output frame after XMA_SUCESS or XMA_FLUSH_AGAIN */
+    if((s->send_status== XMA_SUCCESS) || (s->send_status == XMA_FLUSH_AGAIN)) {
+        int xma_ret = XMA_SUCCESS;
+        /* Create output frames */
+        for (i = 0; i < session_num_out; i++) {
+            XmaFrameProperties fprops;
+            XmaFrameData fdata;
+
+            ctx->outputs[i]->format = multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i]);
+
+            if ((AV_PIX_FMT_XVBM_8 == multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i])) ||
+                (AV_PIX_FMT_XVBM_10 == multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i]))) {
+                a_frame_list[i] = av_frame_alloc();
+                if (a_frame_list[i] == NULL) {
+                    av_log (ctx, AV_LOG_ERROR, "failed to allocate memory...\n");
+                    ret = AVERROR(ENOMEM);
+                    goto error;
+                }
+                a_frame_list[i]->data[0] = NULL;
+
+                fprops.format = get_xma_format(multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i]));
+                fprops.width = ctx->outputs[i]->w;
+                fprops.height = ctx->outputs[i]->h;
+                fprops.bits_per_pixel = s->bits_per_sample;
+                fdata.data[0] = a_frame_list[i]->data[0];
+                x_frame_list[i] = xma_frame_from_buffers_clone(&fprops, &fdata);
+                x_frame_list[i]->data[0].buffer_type = XMA_DEVICE_BUFFER_TYPE;
+            } else {
+                a_frame_list[i] = ff_get_video_buffer(ctx->outputs[i], FFALIGN(ctx->outputs[i]->w, SCL_OUT_STRIDE_ALIGN), FFALIGN(ctx->outputs[i]->h, SCL_OUT_HEIGHT_ALIGN));
+                if (a_frame_list[i] == NULL) {
+                    av_log (ctx, AV_LOG_ERROR, "failed to allocate output frame...\n");
+                    ret = AVERROR(ENOMEM);
+                    goto error;
+                }
+
+                a_frame_list[i]->width = ctx->outputs[i]->w;
+                a_frame_list[i]->height = ctx->outputs[i]->h;
+                fprops.format = get_xma_format(multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i]));
+                fprops.width = FFALIGN(ctx->outputs[i]->w, SCL_OUT_STRIDE_ALIGN);
+                fprops.height = FFALIGN(ctx->outputs[i]->h, SCL_OUT_HEIGHT_ALIGN);
+                fprops.bits_per_pixel = s->bits_per_sample;
+
+                for (plane_id = 0; plane_id < av_pix_fmt_count_planes (multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i])); plane_id++) {
+                    fdata.data[plane_id] = a_frame_list[i]->data[plane_id];
+                }
+                x_frame_list[i] = xma_frame_from_buffers_clone(&fprops, &fdata);
+            }
+        }
+
+        xma_ret = xma_scaler_session_recv_frame_list(curr_session, x_frame_list);
+        if (xma_ret != XMA_SUCCESS) {
+            av_log (ctx, AV_LOG_ERROR, "failed to receive frame list from XMA plugin\n");
+            ret = AVERROR_UNKNOWN;
+            if (xma_ret == XMA_ERROR)
+               ret = XMA_ERROR;
+            goto error;
+        }
+
+        for (i = 0; i < session_num_out; i++) {
+            av_frame_copy_props(a_frame_list[i], in_frame);
+            a_frame_list[i]->width = ctx->outputs[i]->w;
+            a_frame_list[i]->height = ctx->outputs[i]->h;
+            a_frame_list[i]->pts = x_frame_list[i]->pts;
+            a_frame_list[i]->format  = multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[i]);
+            a_frame_list[i]->linesize[0] = x_frame_list[i]->frame_props.linesize[0];
+            a_frame_list[i]->linesize[1] = x_frame_list[i]->frame_props.linesize[1];
+
+	        // Copy HDR side data from XMAFrame to AVFrame
+            XmaSideDataHandle sd_handle = xma_frame_get_side_data(x_frame_list[i], XMA_FRAME_HDR);
+            if(sd_handle)
+            {
+                uint8_t *sd_ptr  = (uint8_t *)xma_side_data_get_buffer(sd_handle);
+                size_t sd_size = xma_side_data_get_size(sd_handle);
+
+                AVFrameSideData *avframe_sidedata = av_frame_new_side_data(a_frame_list[i], AV_FRAME_XLNX_HDR_SIDEBAND_DATA, sd_size);
+                if (!avframe_sidedata){
+                    av_log(NULL, AV_LOG_ERROR, "Out of memory. Unable to allocate AVFrameSideData\n");
+                    return AVERROR(ENOMEM);
+                }
+                memcpy(avframe_sidedata->data, sd_ptr, sd_size);
+                /* Clear all side data from xmaframe to free the side data allocation */
+                xma_frame_clear_all_side_data(x_frame_list[i]);
+            }
+
+            if ((AV_PIX_FMT_XVBM_8 == multiscale_xma_get_pix_fmt(ctx->inputs[0]->format,
+                    s->out_format[i])) ||
+                    (AV_PIX_FMT_XVBM_10 == multiscale_xma_get_pix_fmt(ctx->inputs[0]->format,
+                    s->out_format[i]))) {
+                ret = av_frame_clone_xma_frame (a_frame_list[i], x_frame_list[i]);
+                if (ret)
+                    goto error;
+            }
+
+#ifdef DUMP_OUT_FRAMES
+            {
+              int written = fwrite (a_frame_list[i]->data[0], 1, (2048*1088*3)>>1, outfp);
+              av_log(NULL, AV_LOG_INFO, "written %d bytes\n", written);
+              //written = fwrite (a_frame_list[i]->data[1], 1, (2048*1080) >> 1, outfp);
+              //printf ("written %d bytes\n", written);
+            }
+#endif
+#ifdef DUMP_FRAME_PARAM
+            av_log(NULL, AV_LOG_INFO,  "Output[%d] : w = %d, h = %d, fmt = %d, pts = %lld, linesize[0] = %d,"
+                "linesize[1] = %d, linesize[2] = %d, data[0] = %p, data[1]= %p, data[2] = %p\n",
+                i, a_frame_list[i]->width, a_frame_list[i]->height, a_frame_list[i]->format, a_frame_list[i]->pts,
+                a_frame_list[i]->linesize[0], a_frame_list[i]->linesize[1], a_frame_list[i]->linesize[2],
+                a_frame_list[i]->data[0], a_frame_list[i]->data[1], a_frame_list[i]->data[2]);
+#endif
+
+            ret = ff_filter_frame(ctx->outputs[i], a_frame_list[i]);
+            if (ret < 0) {
+                av_log(ctx, AV_LOG_ERROR, "ff_filter_frame failed: ret=%d\n", ret);
+                goto error;
+            }
+
+            xma_frame_free(x_frame_list[i]);
+        }
+        s->frames_out++;
+} else if((s->send_status == XMA_ERROR)|| (s->send_status == XMA_TRY_AGAIN)) {
+        ret = s->send_status;
+        goto error;
+    }
+
+    xma_frame_free (xframe);
+
+    if (s->flush == 0)
+        av_frame_free(&in_frame);
+
+    return 0;
+
+error:
+    if (xframe)
+        xma_frame_free (xframe);
+
+    if (s->flush == 0)
+        av_frame_free(&in_frame);
+
+    for (i = 0; i < session_num_out; i++)
+        if (x_frame_list[i])
+            xma_frame_free(x_frame_list[i]);
+
+    if (ret == XMA_EOS)
+        return 0;
+
+    return mpsoc_report_error(s, "multiscaler filter_frame failed", ret);
+}
+
+static int query_formats(AVFilterContext *ctx)
+{
+    MultiScalerContext *s = ctx->priv;
+    int res, chan_id, i;
+    AVFilterFormats *formats;
+    AVFilterLink* link;
+    const AVPixFmtDescriptor* desc;
+
+    if (!ctx->inputs[0]->outcfg.formats) {
+        static const enum AVPixelFormat pix_fmts[] = {
+            AV_PIX_FMT_XVBM_8,
+            AV_PIX_FMT_XVBM_10,
+            AV_PIX_FMT_NV12,
+            AV_PIX_FMT_XV15,
+            AV_PIX_FMT_NONE,
+        };
+        formats = ff_make_format_list(pix_fmts);
+
+        if (!formats)
+            return AVERROR(ENOMEM);
+        if (multiscale_xma_get_pix_fmt(ctx->inputs[0]->format, s->out_format[0]) == AV_PIX_FMT_NONE)
+            return ff_set_common_formats(ctx, formats);
+        res = ff_formats_ref(formats, &ctx->inputs[0]->outcfg.formats);
+        if (res < 0)
+            return res;
+        return AVERROR(EAGAIN);
+    }
+
+    if (ctx->inputs[0]->outcfg.formats->nb_formats > 1) {
+        // ffmpeg has the inputs we support, but is having trouble deciding which to use.
+        // Most likely the format conversion (scaler) has been added before this to convert
+        // between what is coming in and what we support. Help it out by narrowing it down
+        // to 8 or 10 bit formats.
+        if (ctx->inputs[0]->src && (strncmp(ctx->inputs[0]->src->name, "auto_scale", strlen("auto_scale")) == 0)) {
+            // get the link between the scaler and whatever is upstream of it
+            link = ctx->inputs[0]->src->inputs[0];
+            if (link && link->outcfg.formats && (link->outcfg.formats->nb_formats >= 1)) {
+                desc = av_pix_fmt_desc_get(link->outcfg.formats->formats[0]);
+                formats = NULL;
+                if (desc->comp[0].depth <= SC_BITDEPTH_8BIT) {
+                    // the source is 8 bit or less, only support 8 bit formats
+                    for (i = 0; i < ctx->inputs[0]->outcfg.formats->nb_formats; i++) {
+                        if ((ctx->inputs[0]->outcfg.formats->formats[i] == AV_PIX_FMT_XVBM_8) ||
+                            (ctx->inputs[0]->outcfg.formats->formats[i] == AV_PIX_FMT_NV12)) {
+                            res = ff_add_format(&formats, ctx->inputs[0]->outcfg.formats->formats[i]);
+                            if (res < 0)
+                                return res;
+                        }
+                    }
+                } else {
+                    // the source is 9 bit or more, only support 10 bit formats
+                    for (i = 0; i < ctx->inputs[0]->outcfg.formats->nb_formats; i++) {
+                        if ((ctx->inputs[0]->outcfg.formats->formats[i] == AV_PIX_FMT_XVBM_10) ||
+                            (ctx->inputs[0]->outcfg.formats->formats[i] == AV_PIX_FMT_XV15)) {
+                            res = ff_add_format(&formats, ctx->inputs[0]->outcfg.formats->formats[i]);
+                            if (res < 0)
+                                return res;
+                        }
+                    }
+                }
+                if ((formats == NULL) || (formats->nb_formats == 0))
+                    return AVERROR(AVERROR_UNKNOWN);
+                res = ff_formats_ref(formats, &ctx->inputs[0]->outcfg.formats);
+                if (res < 0)
+                    return res;
+            }
+        }
+    }
+
+    if (ctx->inputs[0]->outcfg.formats->nb_formats > 1)
+        return AVERROR(EAGAIN);
+
+    for (chan_id = 0; chan_id < s->nb_outputs; chan_id++) {
+        formats = NULL;
+        res = ff_add_format(&formats, multiscale_xma_get_pix_fmt(ctx->inputs[0]->outcfg.formats->formats[0], s->out_format[chan_id]));
+        if (res < 0)
+            return res;
+        res = ff_formats_ref(formats, &ctx->outputs[chan_id]->incfg.formats);
+        if (res < 0)
+            return res;
+    }
+    return res;
+}
+
+#define OFFSET(x) offsetof(MultiScalerContext, x)
+#define FLAGS (AV_OPT_FLAG_VIDEO_PARAM | AV_OPT_FLAG_FILTERING_PARAM)
+static const AVOption options[] = {
+    { "outputs", "set number of outputs", OFFSET(nb_outputs), AV_OPT_TYPE_INT, { .i64 = 8 }, 1, MAX_OUTS, FLAGS },
+    { "enable_pipeline", "enable pipelining in multiscaler", OFFSET(enable_pipeline), AV_OPT_TYPE_INT, { .i64 = -1 }, -1, 1, FLAGS, "enable_pipeline" },
+    { "auto", "Automatic", 0, AV_OPT_TYPE_CONST, { .i64 = -1 }, 0, 0, FLAGS, "enable_pipeline"},
+    { "lxlnx_hwdev", "set local device ID for scaler if it needs to be different from global xlnx_hwdev.", OFFSET(lxlnx_hwdev), AV_OPT_TYPE_INT, { .i64 = -1 }, -1, INT_MAX, FLAGS },
+    { "out_1_width", "set width of output 1 (should be multiple of 4)", OFFSET(out_width[0]), AV_OPT_TYPE_INT, { .i64 = 1600 }, 128, 3840, FLAGS },
+    { "out_1_height", "set height of output 1 (should be multiple of 4)", OFFSET(out_height[0]), AV_OPT_TYPE_INT, { .i64 = 900 }, 128, 3840, FLAGS },
+    { "out_1_pix_fmt", "set format of output 1", OFFSET(out_format[0]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_1_rate", "set rate of output 1", OFFSET(out_rate[0]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_2_width", "set width of output 2 (should be multiple of 4)", OFFSET(out_width[1]), AV_OPT_TYPE_INT, { .i64 = 1280 }, 128, 3840, FLAGS },
+    { "out_2_height", "set height of output 2 (should be multiple of 4)", OFFSET(out_height[1]), AV_OPT_TYPE_INT, { .i64 = 720 }, 128, 3840, FLAGS },
+    { "out_2_pix_fmt", "set format of output 2", OFFSET(out_format[1]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_2_rate", "set rate of output 2", OFFSET(out_rate[1]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_3_width", "set width of output 3 (should be multiple of 4)", OFFSET(out_width[2]), AV_OPT_TYPE_INT, { .i64 = 800 }, 128, 3840, FLAGS },
+    { "out_3_height", "set height of output 3 (should be multiple of 4)", OFFSET(out_height[2]), AV_OPT_TYPE_INT, { .i64 = 600 }, 128, 3840, FLAGS },
+    { "out_3_pix_fmt", "set format of output 3", OFFSET(out_format[2]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_3_rate", "set rate of output 3", OFFSET(out_rate[2]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_4_width", "set width of output 4 (should be multiple of 4)", OFFSET(out_width[3]), AV_OPT_TYPE_INT, { .i64 = 832 }, 128, 3840, FLAGS },
+    { "out_4_height", "set height of output 4 (should be multiple of 4)", OFFSET(out_height[3]), AV_OPT_TYPE_INT, { .i64 = 480 }, 128, 3840, FLAGS },
+    { "out_4_pix_fmt", "set format of output 4", OFFSET(out_format[3]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_4_rate", "set rate of output 4", OFFSET(out_rate[3]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_5_width", "set width of output 5 (should be multiple of 4)", OFFSET(out_width[4]), AV_OPT_TYPE_INT, { .i64 = 640 }, 128, 3840, FLAGS },
+    { "out_5_height", "set height of output 5 (should be multiple of 4)", OFFSET(out_height[4]), AV_OPT_TYPE_INT, { .i64 = 480 }, 128, 3840, FLAGS },
+    { "out_5_pix_fmt", "set format of output 5", OFFSET(out_format[4]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_5_rate", "set rate of output 5", OFFSET(out_rate[4]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_6_width", "set width of output 6 (should be multiple of 4)", OFFSET(out_width[5]), AV_OPT_TYPE_INT, { .i64 = 480 }, 128, 3840, FLAGS },
+    { "out_6_height", "set height of output 6 (should be multiple of 4)", OFFSET(out_height[5]), AV_OPT_TYPE_INT, { .i64 = 320 }, 128, 3840, FLAGS },
+    { "out_6_pix_fmt", "set format of output 6", OFFSET(out_format[5]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_6_rate", "set rate of output 6", OFFSET(out_rate[5]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_7_width", "set width of output 7 (should be multiple of 4)", OFFSET(out_width[6]), AV_OPT_TYPE_INT, { .i64 = 320 }, 128, 3840, FLAGS },
+    { "out_7_height", "set height of output 7 (should be multiple of 4)", OFFSET(out_height[6]), AV_OPT_TYPE_INT, { .i64 = 240 }, 128, 3840, FLAGS },
+    { "out_7_pix_fmt", "set format of output 7", OFFSET(out_format[6]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_7_rate", "set rate of output 7", OFFSET(out_rate[6]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "out_8_width", "set width of output 8 (should be multiple of 4)", OFFSET(out_width[7]), AV_OPT_TYPE_INT, { .i64 = 224 }, 128, 3840, FLAGS },
+    { "out_8_height", "set height of output 8 (should be multiple of 4)", OFFSET(out_height[7]), AV_OPT_TYPE_INT, { .i64 = 224 }, 128, 3840, FLAGS },
+    { "out_8_pix_fmt", "set format of output 8", OFFSET(out_format[7]), AV_OPT_TYPE_STRING, { .str = "xlnx_xvbm"}, CHAR_MIN, CHAR_MAX, FLAGS },
+    { "out_8_rate", "set rate of output 8", OFFSET(out_rate[7]), AV_OPT_TYPE_STRING, { .str = "full" }, CHAR_MIN, CHAR_MAX, FLAGS},
+    { "latency_logging", "Log latency information to syslog", OFFSET(latency_logging), AV_OPT_TYPE_INT, { .i64 = 0 }, 0, 1, FLAGS, "latency_logging" },
+    { NULL }
+};
+
+#define multiscale_xma_options options
+AVFILTER_DEFINE_CLASS(multiscale_xma);
+
+static const AVFilterPad avfilter_vf_multiscale_xma_inputs[] = {
+    {
+        .name = "default",
+        .type = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = multiscale_xma_filter_frame,
+        .config_props = multiscale_xma_config_props,
+    }
+};
+
+AVFilter ff_vf_multiscale_xma = {
+    .name = "multiscale_xma",
+    .description = NULL_IF_CONFIG_SMALL("Xilinx Multi Scaler (in ABR mode) using XMA APIs"),
+    .priv_size = sizeof(MultiScalerContext),
+    .priv_class = &multiscale_xma_class,
+    FILTER_QUERY_FUNC(query_formats),
+    .init = multiscale_xma_init,
+    .uninit = multiscale_xma_uninit,
+    FILTER_INPUTS(avfilter_vf_multiscale_xma_inputs),
+    .outputs = NULL,
+    .flags = AVFILTER_FLAG_DYNAMIC_OUTPUTS,
+};
diff --git a/libavfilter/vf_scale.c b/libavfilter/vf_scale.c
index 2b12cf283c..f8fc906971 100644
--- a/libavfilter/vf_scale.c
+++ b/libavfilter/vf_scale.c
@@ -1,4 +1,6 @@
 /*
+ * Modifications Copyright(C) [2024] Advanced Micro Devices, Inc.
+ *
  * Copyright (c) 2007 Bobby Bingham
  *
  * This file is part of FFmpeg.
@@ -151,6 +153,7 @@ typedef struct ScaleContext {
 
     int eval_mode;              ///< expression evaluation mode
 
+    AVFrame *temp_frame[2];
 } ScaleContext;
 
 const AVFilter ff_vf_scale2ref;
@@ -324,6 +327,8 @@ static av_cold int init_dict(AVFilterContext *ctx, AVDictionary **opts)
     *opts = NULL;
 
     scale->in_frame_range = AVCOL_RANGE_UNSPECIFIED;
+    scale->temp_frame[0] = NULL;
+    scale->temp_frame[1] = NULL;
 
     return 0;
 }
@@ -339,6 +344,10 @@ static av_cold void uninit(AVFilterContext *ctx)
     sws_freeContext(scale->isws[1]);
     scale->sws = NULL;
     av_dict_free(&scale->opts);
+    if (scale->temp_frame[0])
+        av_frame_unref(scale->temp_frame[0]);
+    if (scale->temp_frame[1])
+        av_frame_unref(scale->temp_frame[1]);
 }
 
 static int query_formats(AVFilterContext *ctx)
@@ -483,11 +492,16 @@ static int config_props(AVFilterLink *outlink)
     AVFilterLink *inlink  = ctx->filter == &ff_vf_scale2ref ?
                             outlink->src->inputs[1] :
                             outlink->src->inputs[0];
+    enum AVPixelFormat infmt = inlink0->format;
     enum AVPixelFormat outfmt = outlink->format;
     const AVPixFmtDescriptor *desc = av_pix_fmt_desc_get(inlink->format);
     ScaleContext *scale = ctx->priv;
     int ret;
 
+    if (infmt == AV_PIX_FMT_XV15)
+        infmt = AV_PIX_FMT_YUV420P10LE;
+    if (outfmt == AV_PIX_FMT_XV15)
+        outfmt = AV_PIX_FMT_YUV420P10LE;
     if ((ret = scale_eval_dimensions(ctx)) < 0)
         goto fail;
 
@@ -536,7 +550,7 @@ static int config_props(AVFilterLink *outlink)
 
             av_opt_set_int(s, "srcw", inlink0 ->w, 0);
             av_opt_set_int(s, "srch", inlink0 ->h >> !!i, 0);
-            av_opt_set_int(s, "src_format", inlink0->format, 0);
+            av_opt_set_int(s, "src_format", infmt, 0);
             av_opt_set_int(s, "dstw", outlink->w, 0);
             av_opt_set_int(s, "dsth", outlink->h >> !!i, 0);
             av_opt_set_int(s, "dst_format", outfmt, 0);
@@ -564,11 +578,11 @@ static int config_props(AVFilterLink *outlink)
             /* Override YUV420P default settings to have the correct (MPEG-2) chroma positions
              * MPEG-2 chroma positions are used by convention
              * XXX: support other 4:2:0 pixel formats */
-            if (inlink0->format == AV_PIX_FMT_YUV420P && scale->in_v_chr_pos == -513) {
+            if (infmt == AV_PIX_FMT_YUV420P && scale->in_v_chr_pos == -513) {
                 in_v_chr_pos = (i == 0) ? 128 : (i == 1) ? 64 : 192;
             }
 
-            if (outlink->format == AV_PIX_FMT_YUV420P && scale->out_v_chr_pos == -513) {
+            if (outfmt == AV_PIX_FMT_YUV420P && scale->out_v_chr_pos == -513) {
                 out_v_chr_pos = (i == 0) ? 128 : (i == 1) ? 64 : 192;
             }
 
@@ -590,7 +604,7 @@ static int config_props(AVFilterLink *outlink)
         outlink->sample_aspect_ratio = inlink0->sample_aspect_ratio;
 
     av_log(ctx, AV_LOG_VERBOSE, "w:%d h:%d fmt:%s sar:%d/%d -> w:%d h:%d fmt:%s sar:%d/%d flags:0x%0x\n",
-           inlink ->w, inlink ->h, av_get_pix_fmt_name( inlink->format),
+           inlink ->w, inlink ->h, av_get_pix_fmt_name( inlink0->format),
            inlink->sample_aspect_ratio.num, inlink->sample_aspect_ratio.den,
            outlink->w, outlink->h, av_get_pix_fmt_name(outlink->format),
            outlink->sample_aspect_ratio.num, outlink->sample_aspect_ratio.den,
@@ -633,6 +647,544 @@ static void frame_offset(AVFrame *frame, int dir, int is_pal)
     }
 }
 
+#if CONFIG_LIBXMA2API
+/**
+ * Extracts a 10 bit pixel from a vcu word and stores it in a 16 bit word
+ * @param pixel_index Which pixel of the vcu word to take (0-2)
+ * @param vcu_word The source vcu word containing 3 pixels
+ * @param out_word Where to store the first (LSB) pixel
+ * @return void
+ */
+static void extract_pixel_from_xv15_word(uint8_t pixel_index, uint32_t vcu_word,
+                                       uint16_t** out_word)
+{
+    if(pixel_index == 0) {
+        *(*out_word)++ = (uint16_t) (vcu_word & 0x3FF);
+    } else if(pixel_index == 1) {
+        *(*out_word)++ = (uint16_t) ((vcu_word & 0xFFC00)    >> 10);
+    } else {
+        *(*out_word)++ = (uint16_t) ((vcu_word & 0x3FF00000) >> 20);
+    }
+}
+
+/**
+ * Converts an xv15 word into yuv420p10le words stored in the y plane.
+ * @param num_pxls_to_xtrct The number of pixels to extract from the source
+ * word
+ * @param xv15_word The source xv15 word containing 3 pixels of data
+ * @param y_plane The output y plane
+ * @return void
+ */
+static void y_xv15_wrd_10le_wrds(uint8_t num_pxls_to_xtrct, uint32_t xv15_word,
+                                 uint16_t** y_plane)
+{
+    switch(num_pxls_to_xtrct) {
+        case 3:
+            extract_pixel_from_xv15_word(0, xv15_word, y_plane);
+            extract_pixel_from_xv15_word(1, xv15_word, y_plane);
+            extract_pixel_from_xv15_word(2, xv15_word, y_plane);
+            break;
+        case 2:
+            extract_pixel_from_xv15_word(0, xv15_word, y_plane);
+            extract_pixel_from_xv15_word(1, xv15_word, y_plane);
+            break;
+        case 1:
+            extract_pixel_from_xv15_word(0, xv15_word, y_plane);
+            break;
+        default:
+            return;
+    }
+}
+
+/**
+ * Converts 1-2 xv15 words into yuv420p10le words stored in their respective u
+ * & v planes.
+ * @param num_pxls_to_xtrct The number of pixels to extract from the source
+ * words
+ * @param xv15_word1 The first xv15 source word
+ * @param xv15_word2 The second xv15 source word
+ * @param u_plane The output u plane
+ * @param v_plane The output v plane
+ * @return void
+ */
+static void uv_xv15_wrd_to_10le_wrds(uint8_t num_pxls_to_xtrct,
+                                     uint32_t xv15_word1, uint32_t xv15_word2,
+                                     uint16_t** u_plane, uint16_t** v_plane)
+{
+    switch(num_pxls_to_xtrct) {
+        case 6:
+            extract_pixel_from_xv15_word(0, xv15_word1, u_plane);
+            extract_pixel_from_xv15_word(1, xv15_word1, v_plane);
+            extract_pixel_from_xv15_word(2, xv15_word1, u_plane);
+
+            extract_pixel_from_xv15_word(0, xv15_word2, v_plane);
+            extract_pixel_from_xv15_word(1, xv15_word2, u_plane);
+            extract_pixel_from_xv15_word(2, xv15_word2, v_plane);
+            break;
+        case 5:
+            extract_pixel_from_xv15_word(0, xv15_word1, u_plane);
+            extract_pixel_from_xv15_word(1, xv15_word1, v_plane);
+            extract_pixel_from_xv15_word(2, xv15_word1, u_plane);
+
+            extract_pixel_from_xv15_word(0, xv15_word2, v_plane);
+            extract_pixel_from_xv15_word(1, xv15_word2, u_plane);
+            break;
+        case 4:
+            extract_pixel_from_xv15_word(0, xv15_word1, u_plane);
+            extract_pixel_from_xv15_word(1, xv15_word1, v_plane);
+            extract_pixel_from_xv15_word(2, xv15_word1, u_plane);
+
+            extract_pixel_from_xv15_word(0, xv15_word2, v_plane);
+            break;
+        case 3:
+            extract_pixel_from_xv15_word(0, xv15_word1, u_plane);
+            extract_pixel_from_xv15_word(1, xv15_word1, v_plane);
+            extract_pixel_from_xv15_word(2, xv15_word1, u_plane);
+            break;
+        case 2:
+            extract_pixel_from_xv15_word(0, xv15_word1, u_plane);
+            extract_pixel_from_xv15_word(1, xv15_word1, v_plane);
+            break;
+        case 1:
+            extract_pixel_from_xv15_word(0, xv15_word1, u_plane);
+            break;
+        default:
+            return;
+    }
+}
+
+/**
+ * Get the buffer from the fpga and format it into yuv420p10le format.
+ * @param xframe The frame which is used to get the buffer from device
+ * @param in The input AVFrame containing frame info
+ * @param out The AVFrame into which the yuv420p10le frame will be stored.
+ * @return 0 on success or -1 on error
+ */
+static int conv_xv15_to_yuv420p10le(AVFrame* in, AVFrame* out)
+{
+    out->linesize[0] = out->width * 2;
+    out->linesize[1] = out->linesize[0] / 2;
+    out->linesize[2] = out->linesize[1];
+    uint16_t* y_plane       = (uint16_t*)out->data[0];
+    uint32_t* current_line  = (uint32_t*)(in->data[0]);
+    uint16_t total_words_in_line = in->linesize[0] / sizeof(uint32_t);
+    uint16_t valid_words_in_line = in->width / 3;
+    uint8_t  leftover_pixels     = in->width % 3;
+    uint16_t num_rows_in_plane   = in->height;
+    uint16_t w, h;
+    for (h = 0; h < num_rows_in_plane; h++) {
+        for (w = 0; w < valid_words_in_line; w++) {
+            y_xv15_wrd_10le_wrds(3, current_line[w], &y_plane);
+        }
+        y_xv15_wrd_10le_wrds(leftover_pixels, current_line[w],
+                                             &y_plane);
+        current_line += total_words_in_line;
+    }
+    uint16_t* u_plane = (uint16_t*)out->data[1];
+    uint16_t* v_plane = (uint16_t*)out->data[2];
+    current_line      = (uint32_t*)(in->data[1]);
+    num_rows_in_plane   = in->height / 2;
+    valid_words_in_line = in->width / 6; // Reading 2 words at a time
+    leftover_pixels     = in->width % 6;
+    size_t word_index;
+    for (h = 0; h < num_rows_in_plane; h++) {
+        word_index = 0;
+        for (w = 0; w < valid_words_in_line; w++) {
+            uv_xv15_wrd_to_10le_wrds(6, current_line[word_index],
+                                     current_line[word_index+1], &u_plane,
+                                     &v_plane);
+            word_index += 2;
+        }
+        uv_xv15_wrd_to_10le_wrds(leftover_pixels,
+                                 current_line[word_index],
+                                 current_line[word_index+1], &u_plane,
+                                 &v_plane);
+        current_line += total_words_in_line;
+    }
+    return 0;
+}
+
+/**
+ * Write the values of 3 pixels into the next word of the xv15 (aka nv12_10le32)
+ * buffer and increment the buffer to the next 32 bit WORD.
+ * @param p1 The first pixel to be written (LSB)
+ * @param p2 The second pixel to be written
+ * @param p3 The third pixel to be written
+ * @param xv15_buffer A pointer to the output xv15 (aka nv12_10le32)
+ * buffer
+ * @return void
+ */
+static void yuv10b_pixls_to_xv15_wrd(uint16_t p1, uint16_t p2,
+                                     uint16_t p3,
+                                     uint32_t** xv15_buffer) {
+    *(*xv15_buffer)++ = 0x3FFFFFFF & (p1 | (p2 << 10) | (p3 << 20));
+}
+
+/**
+ * Write up to 3 pixels from the source y buffer into the xv15 (aka nv12_10le32)
+ * buffer
+ * @param num_pixels_to_write The number of pixels to write. 1-3
+ * @param y_buffer A pointer to the source y plane buffer
+ * @param xv15_buffer A pointer to the output xv15 (aka nv12_10le32) buffer
+ * @return void
+ */
+static void y_10b_seg_to_xv15_wrd(uint8_t num_pixels_to_write,
+                                  uint16_t** y_buffer, uint32_t** xv15_buffer)
+{
+    switch(num_pixels_to_write) {
+        case 3:
+            yuv10b_pixls_to_xv15_wrd((*y_buffer)[0], (*y_buffer)[1],
+                                    (*y_buffer)[2], xv15_buffer);
+            break;
+        case 2:
+            yuv10b_pixls_to_xv15_wrd((*y_buffer)[0], (*y_buffer)[1], 0,
+                                     xv15_buffer);
+            break;
+        case 1:
+            yuv10b_pixls_to_xv15_wrd((*y_buffer)[0], 0, 0, xv15_buffer);
+            break;
+        default:
+            return;
+    }
+    *y_buffer += num_pixels_to_write;
+}
+
+/**
+ * Write up to 6 pixels from the source u & v buffers into the xv15
+ * (aka nv12_10le32) buffer
+ * @param num_pixels_to_write The number of pixels to write. 1-6
+ * @param u_buffer A pointer to the source u plane buffer
+ * @param v_buffer A pointer to the source v plane buffer
+ * @param xv15_buffer A pointer to the output xv15 (aka nv12_10le32) buffer
+ * @return void
+ */
+static void uv_10b_seg_to_xv15_wrd(uint8_t num_pixels_to_write,
+                                   uint16_t** u_buffer, uint16_t** v_buffer,
+                                   uint32_t** xv15_buffer)
+{
+    switch(num_pixels_to_write) {
+        case 6:
+            yuv10b_pixls_to_xv15_wrd((*u_buffer)[0], (*v_buffer)[0],
+                                    (*u_buffer)[1], xv15_buffer);
+            yuv10b_pixls_to_xv15_wrd((*v_buffer)[1], (*u_buffer)[2],
+                                    (*v_buffer)[2], xv15_buffer);
+            break;
+        case 5:
+            yuv10b_pixls_to_xv15_wrd((*u_buffer)[0], (*v_buffer)[0],
+                                    (*u_buffer)[1], xv15_buffer);
+            yuv10b_pixls_to_xv15_wrd((*v_buffer)[1], (*u_buffer)[2], 0,
+                                     xv15_buffer);
+            break;
+        case 4:
+            yuv10b_pixls_to_xv15_wrd((*u_buffer)[0], (*v_buffer)[0],
+                                    (*u_buffer)[1], xv15_buffer);
+            yuv10b_pixls_to_xv15_wrd((*v_buffer)[1], 0, 0, xv15_buffer);
+            break;
+        case 3:
+            yuv10b_pixls_to_xv15_wrd((*u_buffer)[0], (*v_buffer)[0],
+                                    (*u_buffer)[1], xv15_buffer);
+            break;
+        case 2:
+            yuv10b_pixls_to_xv15_wrd((*u_buffer)[0], (*v_buffer)[0], 0,
+                                     xv15_buffer);
+            break;
+        case 1:
+            yuv10b_pixls_to_xv15_wrd((*u_buffer)[0], 0, 0, xv15_buffer);
+            break;
+        default:
+            return;
+    }
+    *u_buffer += (num_pixels_to_write + 1) / 2;
+    *v_buffer += num_pixels_to_write / 2;
+}
+
+/**
+ * Convert the input yuv420p10le frame into the xv15 (nv12_10le32) format
+ * @param in The input AVFrame containing frame info + the yuv420p10le frame
+ * @param out The AVFrame into which the vcu formatted frame will be stored
+ * @return 0 on success or -1 on error
+ */
+static int32_t conv_yuv420p10le_to_xv15(const AVFrame* in, AVFrame* out)
+{
+    out->linesize[0] = ((in->width + 2) / 3) * 4;
+    out->linesize[1] = out->linesize[0];
+    out->data[0] = out->buf[0]->data;
+    out->data[1] = out->buf[1]->data;
+
+    uint16_t  pixels_per_word   = 3;
+    uint16_t* y_buffer;
+    uint32_t* current_buffer    = (uint32_t*)(out->data[0]);
+    uint16_t  rows_in_plane     = in->height;
+    uint16_t  words_in_line     = in->width / pixels_per_word;
+    uint8_t   leftover_pixels   = in->width % pixels_per_word;
+    for(uint16_t h = 0; h < rows_in_plane; h++) {
+        y_buffer                = (uint16_t*)((uint8_t*)in->data[0] + (h * in->linesize[0]));
+        for(uint16_t w = 0; w < words_in_line; w++) {
+            y_10b_seg_to_xv15_wrd(pixels_per_word, &y_buffer, &current_buffer);
+        }
+        if(leftover_pixels) {
+            y_10b_seg_to_xv15_wrd(leftover_pixels, &y_buffer, &current_buffer);
+        }
+    }
+
+    pixels_per_word     = 6;
+    uint16_t* u_buffer;
+    uint16_t* v_buffer;
+    current_buffer      = (uint32_t*)(out->data[1]);
+    words_in_line       = in->width / pixels_per_word;
+    leftover_pixels     = in->width % pixels_per_word;
+    rows_in_plane       = in->height / 2;
+    for(uint16_t h = 0; h < rows_in_plane; h++) {
+        u_buffer                = (uint16_t*)((uint8_t*)in->data[1] + (h * in->linesize[1]));
+        v_buffer                = (uint16_t*)((uint8_t*)in->data[2] + (h * in->linesize[2]));
+        for(uint16_t w = 0; w < words_in_line; w++) {
+            uv_10b_seg_to_xv15_wrd(pixels_per_word, &u_buffer, &v_buffer, &current_buffer);
+        }
+        if(leftover_pixels) {
+            uv_10b_seg_to_xv15_wrd(leftover_pixels, &u_buffer, &v_buffer,
+                                    &current_buffer);
+        }
+    }
+    return 0;
+}
+#endif
+
+static int alloc_temp_frame(AVFrame *pic, int format, AVFrame **frame)
+{
+    ptrdiff_t linesizes[4];
+    size_t sizes[4];
+    int i, ret = 0, padded_height;
+
+    *frame = av_frame_alloc();
+    (*frame)->format = format;
+    (*frame)->width = pic->width;
+    (*frame)->height = pic->height;
+    for(i=1; i<=32; i+=i) {
+        ret = av_image_fill_linesizes((*frame)->linesize, format,
+                                      FFALIGN(pic->width, i));
+        if (ret < 0)
+            return ret;
+        if (!((*frame)->linesize[0] & 31))
+            break;
+    }
+
+    for(i = 0; i < 4 && (*frame)->linesize[i]; i++)
+        (*frame)->linesize[i] = FFALIGN((*frame)->linesize[i], 32);
+
+    for(i = 0; i < 4; i++)
+        linesizes[i] = (*frame)->linesize[i];
+
+    padded_height = FFALIGN((*frame)->height, 32);
+    if ((ret = av_image_fill_plane_sizes(sizes, format,
+                                         padded_height, linesizes)) < 0)
+        return ret;
+
+    for(i = 0; i < 4; i++) {
+        if(sizes[i] > INT_MAX - 32)
+            return AVERROR(EINVAL);
+        if (sizes[i] > 0) {
+            (*frame)->buf[i] = av_buffer_alloc(sizes[i]);
+            if (!(*frame)->buf[i])
+                return AVERROR(ENOMEM);
+            (*frame)->data[i] = (*frame)->buf[i]->data;
+        } else {
+            (*frame)->buf[i] = NULL;
+            (*frame)->data[i] = NULL;
+        }
+    }
+
+    return ret;
+}
+
+static void free_side_data(AVFrameSideData **ptr_sd)
+{
+    AVFrameSideData *sd = *ptr_sd;
+
+    av_buffer_unref(&sd->buf);
+    av_dict_free(&sd->metadata);
+    av_freep(ptr_sd);
+}
+
+static void wipe_side_data(AVFrame *frame)
+{
+    int i;
+
+    for (i = 0; i < frame->nb_side_data; i++) {
+        free_side_data(&frame->side_data[i]);
+    }
+    frame->nb_side_data = 0;
+
+    av_freep(&frame->side_data);
+}
+
+static int frame_copy_props(AVFrame *dst, const AVFrame *src, int force_copy)
+{
+    int ret, i;
+
+    dst->key_frame              = src->key_frame;
+    dst->pict_type              = src->pict_type;
+    dst->sample_aspect_ratio    = src->sample_aspect_ratio;
+    dst->crop_top               = src->crop_top;
+    dst->crop_bottom            = src->crop_bottom;
+    dst->crop_left              = src->crop_left;
+    dst->crop_right             = src->crop_right;
+    dst->pts                    = src->pts;
+    dst->repeat_pict            = src->repeat_pict;
+    dst->interlaced_frame       = src->interlaced_frame;
+    dst->top_field_first        = src->top_field_first;
+    dst->palette_has_changed    = src->palette_has_changed;
+    dst->sample_rate            = src->sample_rate;
+    dst->opaque                 = src->opaque;
+#if FF_API_PKT_PTS
+FF_DISABLE_DEPRECATION_WARNINGS
+    dst->pkt_pts                = src->pkt_pts;
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+    dst->pkt_dts                = src->pkt_dts;
+    dst->pkt_pos                = src->pkt_pos;
+    dst->pkt_size               = src->pkt_size;
+    dst->pkt_duration           = src->pkt_duration;
+    dst->reordered_opaque       = src->reordered_opaque;
+    dst->quality                = src->quality;
+    dst->best_effort_timestamp  = src->best_effort_timestamp;
+    dst->coded_picture_number   = src->coded_picture_number;
+    dst->display_picture_number = src->display_picture_number;
+    dst->flags                  = src->flags;
+    dst->decode_error_flags     = src->decode_error_flags;
+    dst->color_primaries        = src->color_primaries;
+    dst->color_trc              = src->color_trc;
+    dst->colorspace             = src->colorspace;
+    dst->color_range            = src->color_range;
+    dst->chroma_location        = src->chroma_location;
+
+    av_dict_copy(&dst->metadata, src->metadata, 0);
+
+#if FF_API_ERROR_FRAME
+FF_DISABLE_DEPRECATION_WARNINGS
+    memcpy(dst->error, src->error, sizeof(dst->error));
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+
+    for (i = 0; i < src->nb_side_data; i++) {
+        const AVFrameSideData *sd_src = src->side_data[i];
+        AVFrameSideData *sd_dst;
+        if (   sd_src->type == AV_FRAME_DATA_PANSCAN
+            && (src->width != dst->width || src->height != dst->height))
+            continue;
+        if (force_copy) {
+            sd_dst = av_frame_new_side_data(dst, sd_src->type,
+                                            sd_src->size);
+            if (!sd_dst) {
+                wipe_side_data(dst);
+                return AVERROR(ENOMEM);
+            }
+            memcpy(sd_dst->data, sd_src->data, sd_src->size);
+        } else {
+            AVBufferRef *ref = av_buffer_ref(sd_src->buf);
+            sd_dst = av_frame_new_side_data_from_buf(dst, sd_src->type, ref);
+            if (!sd_dst) {
+                av_buffer_unref(&ref);
+                wipe_side_data(dst);
+                return AVERROR(ENOMEM);
+            }
+        }
+        av_dict_copy(&sd_dst->metadata, sd_src->metadata, 0);
+    }
+
+#if FF_API_FRAME_QP
+FF_DISABLE_DEPRECATION_WARNINGS
+    dst->qscale_table = NULL;
+    dst->qstride      = 0;
+    dst->qscale_type  = 0;
+    av_buffer_replace(&dst->qp_table_buf, src->qp_table_buf);
+    if (dst->qp_table_buf) {
+        dst->qscale_table = dst->qp_table_buf->data;
+        dst->qstride      = src->qstride;
+        dst->qscale_type  = src->qscale_type;
+    }
+FF_ENABLE_DEPRECATION_WARNINGS
+#endif
+
+    ret = av_buffer_replace(&dst->opaque_ref, src->opaque_ref);
+    ret |= av_buffer_replace(&dst->private_ref, src->private_ref);
+    return ret;
+}
+
+#if CONFIG_LIBXMA2API
+static int handle_xv15_yuv420p10le_conv(ScaleContext *scale, AVFrame *out, AVFrame *in) {
+    AVFrame* temp;
+    int ret;
+    if ((in->width == out->width) &&
+        (in->height == out->height) &&
+        (!scale->out_color_matrix) &&
+        (scale->in_range == scale->out_range)) {
+        if ((in->format == AV_PIX_FMT_XV15) &&
+            (out->format == AV_PIX_FMT_YUV420P10LE)) {
+            return conv_xv15_to_yuv420p10le(in, out);
+        } else if ((in->format == AV_PIX_FMT_YUV420P10LE) &&
+            (out->format == AV_PIX_FMT_XV15)) {
+            out->linesize[0] = ((in->width + 2) / 3) * 4;
+            out->linesize[1] = out->linesize[0];
+            return conv_yuv420p10le_to_xv15(in, out);
+        }
+    }
+    if(in->format == AV_PIX_FMT_XV15) {
+        if(scale->temp_frame[0] == NULL) {
+            ret = alloc_temp_frame(in, AV_PIX_FMT_YUV420P10LE, &scale->temp_frame[0]);
+            if (ret < 0)
+                return ret;
+        }
+        ret = frame_copy_props(scale->temp_frame[0], in, 0);
+        if (ret < 0)
+            return ret;
+        scale->temp_frame[0]->extended_data = scale->temp_frame[0]->data;
+
+        conv_xv15_to_yuv420p10le(in, scale->temp_frame[0]);
+
+        temp = scale->temp_frame[0];
+        scale->temp_frame[0] = in;
+        in = temp;
+    }
+    if(out->format == AV_PIX_FMT_XV15) {
+        if(scale->temp_frame[1] == NULL) {
+            ret = alloc_temp_frame(out, AV_PIX_FMT_YUV422P10LE, &scale->temp_frame[1]);
+            if (ret < 0)
+                return ret;
+        }
+        scale->temp_frame[1]->extended_data = scale->temp_frame[1]->data;
+
+        temp = scale->temp_frame[1];
+        scale->temp_frame[1] = out;
+        out = temp;
+    }
+    return 1;
+}
+
+static int scale_xv15_yuv420p10le_conv(ScaleContext *scale, AVFrame *dst, AVFrame *src) {
+    AVFrame* temp;
+    int ret;
+    if(scale->temp_frame[0]) {
+        temp = scale->temp_frame[0];
+        scale->temp_frame[0] = src;
+        src = temp;
+    }
+    if(scale->temp_frame[1]) {
+        ret = conv_yuv420p10le_to_xv15(dst, scale->temp_frame[1]);
+        if (ret < 0)
+            return ret;
+        ret = frame_copy_props(dst, scale->temp_frame[1], 0);
+        if (ret < 0)
+            return ret;
+
+        temp = scale->temp_frame[1];
+        scale->temp_frame[1] = dst;
+        dst = temp;
+    }
+
+    return 0;
+}
+#endif
+
 static int scale_field(ScaleContext *scale, AVFrame *dst, AVFrame *src,
                        int field)
 {
@@ -658,7 +1210,14 @@ static int scale_field(ScaleContext *scale, AVFrame *dst, AVFrame *src,
     if (ret < 0)
         return ret;
 
-    // undo the changes we made above
+    #if CONFIG_LIBXMA2API
+    ret = scale_xv15_yuv420p10le_conv(scale, dst, src);
+    if(ret < 0) {
+        return ret;
+    }
+    #endif
+
+   // undo the changes we made above
     for (int i = 0; i < 4; i++) {
         src->linesize[i] /= 2;
         dst->linesize[i] /= 2;
@@ -685,7 +1244,6 @@ static int scale_frame(AVFilterLink *link, AVFrame *in, AVFrame **frame_out)
     int ret;
     int in_range;
     int frame_changed;
-
     *frame_out = NULL;
     if (in->colorspace == AVCOL_SPC_YCGCO)
         av_log(link->dst, AV_LOG_WARNING, "Detected unsupported YCgCo colorspace.\n");
@@ -836,12 +1394,31 @@ scale:
               (int64_t)in->sample_aspect_ratio.den * outlink->w * link->h,
               INT_MAX);
 
+    #if CONFIG_LIBXMA2API
+    ret = handle_xv15_yuv420p10le_conv(scale, out, in);
+    if(ret == 0 || ret < 0) {
+        return ret;
+    }
+    #endif
+
     if (scale->interlaced>0 || (scale->interlaced<0 && in->interlaced_frame)) {
         ret = scale_field(scale, out, in, 0);
         if (ret >= 0)
             ret = scale_field(scale, out, in, 1);
     } else {
         ret = sws_scale_frame(scale->sws, out, in);
+        #if CONFIG_LIBXMA2API
+        ret = scale_xv15_yuv420p10le_conv(scale, out, in);
+        if(ret < 0) {
+            return ret;
+        }
+        #endif
+        if(ret == AVERROR(EINVAL)) {
+            av_frame_free(&in);
+            av_frame_free(&out);
+            *frame_out = NULL;
+            return AVERROR(EINVAL);
+        }
     }
 
     av_frame_free(&in);
diff --git a/libavfilter/vf_stereo3d.c b/libavfilter/vf_stereo3d.c
index 71041d2fee..acf34677d1 100644
--- a/libavfilter/vf_stereo3d.c
+++ b/libavfilter/vf_stereo3d.c
@@ -259,6 +259,7 @@ static const enum AVPixelFormat other_pix_fmts[] = {
     AV_PIX_FMT_YUV444P9LE,  AV_PIX_FMT_YUVA444P9LE,
     AV_PIX_FMT_YUV444P9BE,  AV_PIX_FMT_YUVA444P9BE,
     AV_PIX_FMT_YUV420P10LE, AV_PIX_FMT_YUVA420P10LE,
+    AV_PIX_FMT_XV15,
     AV_PIX_FMT_YUV420P10BE, AV_PIX_FMT_YUVA420P10BE,
     AV_PIX_FMT_YUV422P10LE, AV_PIX_FMT_YUVA422P10LE,
     AV_PIX_FMT_YUV422P10BE, AV_PIX_FMT_YUVA422P10BE,
diff --git a/libavfilter/vf_xvbm_convert.c b/libavfilter/vf_xvbm_convert.c
new file mode 100644
index 0000000000..09f9ae3ebc
--- /dev/null
+++ b/libavfilter/vf_xvbm_convert.c
@@ -0,0 +1,563 @@
+/*
+ * Copyright (C) 2022-2024 Advanced Micro Devices, Inc.
+ * Copyright (C) 2020-2022 Xilinx Inc.
+ * All rights reserved.
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 3.0 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+/**
+ * @file
+ * Xilinx Video Buffer Manager frame format to AV Frame format converter
+ */
+#include <sys/prctl.h>
+#include <xma.h>
+#include <xvbm.h>
+#include <pthread.h>
+#include <libavutil/threadmessage.h>
+#include "libavutil/pixfmt.h"
+#include "libavutil/fifo.h"
+#include "libavutil/time.h"
+#include "avfilter.h"
+#include "formats.h"
+#include "internal.h"
+
+
+#define MAX_REQ_MSGQ_SIZE     20
+#define MAX_RSP_MSGQ_SIZE     20
+
+typedef enum _XVBM_DMA_STATE {
+    XVBM_DMA_REQ_NEW = 0,
+    XVBM_DMA_REQ_PROCESSING,
+    XVBM_DMA_REQ_DONE,
+    XVBM_DMA_REQ_FLUSH,
+    XVBM_DMA_REQ_FLUSH_COMPLETE,
+    XVBM_REQ_END
+}XVBM_DMA_STATE;
+
+
+typedef struct _XVBM_CONV_REQ_MSG {
+    AVFrame         *pFrame;
+    XVBM_DMA_STATE  state;
+} XVBM_CONV_REQ_MSG;
+
+typedef struct _XVBM_CONV_RSP_MSG {
+    AVFrame         *pFrame;
+    XVBM_DMA_STATE  state;
+} XVBM_CONV_RSP_MSG;
+
+typedef struct XvbmConvertContext {
+    pthread_t             thread;
+    AVThreadMessageQueue  *ReqMsgQ;
+    AVThreadMessageQueue  *RspMsgQ;
+    AVFilterLink          *xvbm_filterLink;
+}XvbmConvertContext;
+
+static int xvbm_convert_filter_frame(AVFilterLink *link, AVFrame *in);
+static enum AVPixelFormat xvbm_conv_get_av_format(XmaFormatType xmaFormat);
+static size_t xvbm_conv_get_plane_size(int32_t       width,
+                                       int32_t       height,
+                                       XmaFormatType format,
+                                       int32_t       plane_id);
+static void* xvbm_conv_thread(void *xvbmConvCtx);
+static AVFrame* conv_xmaframe2avframe(AVFrame *frame_in);
+
+static enum AVPixelFormat xvbm_conv_get_av_format(XmaFormatType xmaFormat)
+{
+    enum AVPixelFormat avformat;
+
+    switch(xmaFormat) {
+        case XMA_YUV420_FMT_TYPE:           avformat = AV_PIX_FMT_YUV420P;     break;
+        case XMA_YUV422_FMT_TYPE:           avformat = AV_PIX_FMT_YUV422P;     break;
+        case XMA_YUV444_FMT_TYPE:           avformat = AV_PIX_FMT_YUV444P;     break;
+        case XMA_RGBP_FMT_TYPE:             avformat = AV_PIX_FMT_GBRP;        break;
+        case XMA_VCU_NV12_10LE32_FMT_TYPE:  avformat = AV_PIX_FMT_XV15;        break;
+        case XMA_VCU_NV12_FMT_TYPE:         avformat = AV_PIX_FMT_NV12;        break;
+        default:                            avformat = AV_PIX_FMT_NONE;        break;
+    }
+    return(avformat);
+}
+
+static size_t xvbm_conv_get_plane_size(int32_t       width,
+                                       int32_t       height,
+                                       XmaFormatType format,
+                                       int32_t       plane_id)
+{
+    size_t p_size;
+
+    switch (format) {
+        case XMA_VCU_NV12_10LE32_FMT_TYPE:
+            width = ((width + 2) / 3) * 4;
+
+        case XMA_VCU_NV12_FMT_TYPE:
+            switch(plane_id) {
+                case 0: p_size = width * height;         break;
+                case 1: p_size = 0.5 * width * height;   break;
+                default: p_size = 0;                     break;
+            }
+
+        case XMA_YUV420_FMT_TYPE:
+            switch(plane_id) {
+                case 0:  p_size = width * height;        break;
+                case 1:  p_size = ((width * height)>>2); break;
+                case 2:  p_size = ((width * height)>>2); break;
+                default: p_size = 0;                     break;
+            }
+            break;
+
+        case XMA_YUV422_FMT_TYPE:
+            switch(plane_id) {
+                case 0:  p_size = width * height;        break;
+                case 1:  p_size = ((width * height)>>1); break;
+                case 2:  p_size = ((width * height)>>1); break;
+                default: p_size = 0;                     break;
+            }
+            break;
+
+        case XMA_YUV444_FMT_TYPE:
+        case XMA_RGBP_FMT_TYPE:
+            p_size = (width * height);
+            break;
+
+        default:
+              av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: Unsupported format...\n");
+              p_size = 0;
+              break;
+    }
+    return(p_size);
+}
+
+/**
+ * Get a buffer from device using the given parameters
+ * @param xframe The xma frame which will be used to get the host pointer
+ * @param plane_id The current plane which should be retreived (Often both planes
+ * are stored in plane 0)
+ * @param size The size of the plane/buffer to take out.
+ * @return The host buffer gotten from the device. NULL if error.
+ */
+static void* get_buffer_from_device(XmaFrame* xframe, int plane_id, size_t size) {
+    void* host_buff = (void*)xvbm_buffer_get_host_ptr(xframe->data[plane_id].buffer);
+    /* read Y + U/V plane data */
+    int ret = xvbm_buffer_read(xframe->data[plane_id].buffer, host_buff, size, 0);
+    if (ret) {
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: xvbm_buffer_read failed\n");
+        return NULL;
+    }
+    return host_buff;
+}
+
+
+/**
+ * Get the buffer from the fpga
+ * @param xframe The frame which is used to get the buffer from device
+ * @param in The input AVFrame containing frame info
+ * @param out The AVFrame into which the fpga output
+ * @return XMA_SUCCESS on success or XMA_ERROR on error
+ */
+static int vcu_xmaframe_to_avframe(XmaFrame* xframe, AVFrame* in, AVFrame* out)
+{
+    uint32_t aligned_width = xframe->frame_props.linesize[0];
+    uint32_t aligned_height = xframe->frame_props.linesize[1];
+    uint32_t buff_plane_size = aligned_width * aligned_height;
+    size_t master_buff_size = (buff_plane_size*3)>> 1;
+    out->buf[0]  = av_buffer_alloc(master_buff_size);
+    if (out->buf[0] == NULL) {
+        av_frame_free(&out);
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: Out of memory\n");
+        return XMA_ERROR;
+    }
+    out->data[0] = out->buf[0]->data;
+    out->data[1] = out->buf[0]->data + buff_plane_size;
+    out->linesize[0] = aligned_width;
+    out->linesize[1] = aligned_width;
+    int ret = xvbm_buffer_read(xframe->data[0].buffer, out->data[0], master_buff_size, 0);
+    if (ret) {
+        av_frame_free(&out);
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: xvbm_buffer_read failed\n");
+        return XMA_ERROR;
+    }
+    return XMA_SUCCESS;
+}
+
+static int planar_xmaframe_to_avframe(XmaFrame* xframe, AVFrame* in, AVFrame* out)
+{
+    out->linesize[0] = xframe->frame_props.width * ((xframe->frame_props.bits_per_pixel + 7) >> 3);
+    switch(xframe->frame_props.format)
+    {
+        case XMA_YUV420_FMT_TYPE:
+        case XMA_YUV422_FMT_TYPE:
+            {
+                int div_factor = ((XMA_YUV422_FMT_TYPE == xframe->frame_props.format) ? 2 : 4);
+                out->buf[0] = av_buffer_alloc(in->width*in->height);
+                out->buf[1] = av_buffer_alloc((in->width*in->height)/div_factor);
+                out->buf[2] = av_buffer_alloc((in->width*in->height)/div_factor);
+                out->linesize[1] = out->linesize[0] / 2;
+                out->linesize[2] = out->linesize[1];
+            }
+            break;
+
+        case XMA_YUV444_FMT_TYPE:
+        case XMA_RGBP_FMT_TYPE:
+            out->buf[0] = av_buffer_alloc (in->width*in->height);
+            out->buf[1] = av_buffer_alloc (in->width*in->height);
+            out->buf[2] = av_buffer_alloc (in->width*in->height);
+            out->linesize[1] = out->linesize[0];
+            out->linesize[2] = out->linesize[1];
+            break;
+
+        default:
+            av_frame_free(&out);
+            av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: Unsupported format...\n");
+            return XMA_ERROR;
+    }
+    if ((out->buf[0] == NULL) || (out->buf[1] == NULL) || (out->buf[2] == NULL)) {
+        av_frame_free(&out);
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: Out of memory\n");
+        return XMA_ERROR;
+    }
+    out->data[0] = out->buf[0]->data;
+    out->data[1] = out->buf[1]->data;
+    out->data[2] = out->buf[2]->data;
+
+    size_t size;
+    uint8_t* host_buff;
+    //Planar Buffers
+    for (int plane_id = 0; plane_id < xma_frame_planes_get(&xframe->frame_props); plane_id++) {
+        size = xvbm_conv_get_plane_size(out->width, out->height, xframe->frame_props.format, plane_id);
+        host_buff = (uint8_t*)get_buffer_from_device(xframe, plane_id, size);
+        if (!host_buff) {
+            return XMA_ERROR;
+        }
+        memcpy (out->data[plane_id], host_buff, size);
+    }
+    return XMA_SUCCESS;
+}
+
+/**
+ * Convert the finished xma frame into an AVFrame
+ * @param in The input AVFrame (Contains the xma frame in in->data[0])
+ * @return The new AVFrame which contains the completed XmaFrame's data from device.
+ * NULL if error.
+ */
+static AVFrame* conv_xmaframe2avframe(AVFrame *in)
+{
+    XmaFrame* xframe  = NULL;
+    AVFrame*  out;
+    int ret;
+
+    out = av_frame_alloc();
+    if (!out) {
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: unable to allocate AVFrame\n");
+        return NULL;
+    }
+    ret = av_frame_copy_props(out, in);
+    if (ret < 0) {
+        av_frame_free(&out);
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: unable to copy AVFrame properties (%d)\n", ret);
+        return NULL;
+    }
+
+    xframe = (XmaFrame*)in->data[0];
+    if (!xframe) {
+        av_log(NULL, AV_LOG_ERROR, "xvbm_conv:: Invalid input frame\n");
+        av_frame_free(&out);
+        return NULL;
+    }
+
+    out->format = xvbm_conv_get_av_format(xframe->frame_props.format);
+    out->width  = xframe->frame_props.width;
+    out->height = xframe->frame_props.height;
+    if(xframe->frame_props.format == XMA_VCU_NV12_FMT_TYPE ||
+       xframe->frame_props.format == XMA_VCU_NV12_10LE32_FMT_TYPE) {
+        vcu_xmaframe_to_avframe(xframe, in, out);
+    } else {
+        planar_xmaframe_to_avframe(xframe, in, out);
+    }
+    return out;
+}
+
+static void* xvbm_conv_thread(void *xvbmConvCtx)
+{
+    XvbmConvertContext *ctx = (XvbmConvertContext *)xvbmConvCtx;
+    XVBM_CONV_REQ_MSG reqMsg;
+    XVBM_CONV_RSP_MSG rspMsg;
+
+    av_log(NULL, AV_LOG_DEBUG, "xvbm_conv:: Starting xvbm_conv thread\n");
+    prctl(PR_SET_NAME, "xvbm_thread");
+
+    while (1) {
+        av_thread_message_queue_recv(ctx->ReqMsgQ, &reqMsg, 0);
+
+        switch (reqMsg.state) {
+            case XVBM_DMA_REQ_NEW:
+                //Initiate DMA Tx
+                rspMsg.state  = XVBM_DMA_REQ_PROCESSING;
+                rspMsg.pFrame = conv_xmaframe2avframe(reqMsg.pFrame);
+                av_frame_free(&reqMsg.pFrame);
+                //DMA Tx complete - send response
+                rspMsg.state  = XVBM_DMA_REQ_DONE;
+                av_thread_message_queue_send(ctx->RspMsgQ, &rspMsg, 0);
+                break;
+
+            case XVBM_DMA_REQ_FLUSH:
+                rspMsg.state = XVBM_DMA_REQ_FLUSH_COMPLETE;
+                av_thread_message_queue_send(ctx->RspMsgQ, &rspMsg, 0);
+                break;
+
+            case XVBM_REQ_END:
+                goto exit;
+        }
+    }
+exit:
+    av_log(NULL, AV_LOG_DEBUG, "xvbm_conv:: Exiting xvbm_conv thread\n");
+
+    return NULL;
+}
+
+void xvbm_convert_filter_flush(AVFilterLink *link)
+{
+    AVFilterContext *ctx  = link->dst;
+    AVFilterLink *outlink = ctx->outputs[0];
+    XvbmConvertContext *s = ctx->priv;
+    XVBM_CONV_REQ_MSG reqMsg;
+    XVBM_CONV_RSP_MSG rspMsg;
+    AVFrame *out;
+    int ret;
+
+   if (link == s->xvbm_filterLink) {
+        //send flush request to thread
+        reqMsg.state = XVBM_DMA_REQ_FLUSH;
+        av_thread_message_queue_send(s->ReqMsgQ, &reqMsg, 0);
+
+        do {
+            ret = av_thread_message_queue_recv(s->RspMsgQ, &rspMsg, 0); //blocking call
+            if(rspMsg.state != XVBM_DMA_REQ_FLUSH_COMPLETE) {
+                if(!rspMsg.pFrame) {
+                    av_log(ctx, AV_LOG_ERROR, "xvbm_conv:: conversion failed\n");
+                    return;
+                }
+                out = rspMsg.pFrame;
+                ret = ff_filter_frame(outlink, out);
+                if (ret < 0) {
+                    av_log(NULL, AV_LOG_ERROR, "%s():: ff_filter_frame failed: ret=%d\n", __func__,ret);
+                    return;
+                }
+            }
+        } while(rspMsg.state != XVBM_DMA_REQ_FLUSH_COMPLETE);
+   } else {
+       av_log(NULL, AV_LOG_ERROR, "%s():: filterlink mismatch (ctx: %p   in: %p)\n", __func__,s->xvbm_filterLink, link);
+   }
+}
+
+static int xvbm_convert_filter_frame(AVFilterLink *link, AVFrame *in)
+{
+    AVFilterContext *ctx  = link->dst;
+    AVFilterLink *outlink = ctx->outputs[0];
+    XvbmConvertContext *s = ctx->priv;
+    XVBM_CONV_REQ_MSG reqMsg;
+    XVBM_CONV_RSP_MSG rspMsg;
+    AVFrame *out;
+    int ret;
+
+    s->xvbm_filterLink = link;
+
+    if ((in->format == AV_PIX_FMT_XVBM_8) || (in->format == AV_PIX_FMT_XVBM_10)) {
+        reqMsg.pFrame = in;
+        reqMsg.state  = XVBM_DMA_REQ_NEW;
+        av_thread_message_queue_send(s->ReqMsgQ, &reqMsg, 0);
+        ret = av_thread_message_queue_recv(s->RspMsgQ, &rspMsg, AV_THREAD_MESSAGE_NONBLOCK);
+        if (ret == AVERROR(EAGAIN)) {
+            av_log(ctx, AV_LOG_INFO, "xvbm_conv:: wait for conversion to finish...\n");
+            return 0;
+        }
+        out = rspMsg.pFrame;
+    } else {
+        //clone input frame to output
+        out = in;
+    }
+    if(!out) {
+        av_log(ctx, AV_LOG_ERROR, "xvbm_conv:: conversion failed\n");
+        return AVERROR_EXIT;
+    }
+    ret = ff_filter_frame(outlink, out);
+    if (ret < 0) {
+        av_log(NULL, AV_LOG_ERROR, "%s():: ff_filter_frame failed: ret=%d\n", __func__,ret);
+        return ret;
+    }
+    return 0;
+}
+
+static int xvbm_convert_query_formats(AVFilterContext *ctx)
+{
+    AVFilterFormats *inpix_formats = NULL;
+    AVFilterFormats *outpix_formats = NULL;
+    int ret;
+
+    if ((!ctx->inputs[0]->outcfg.formats) || (ctx->inputs[0]->outcfg.formats->nb_formats > 1)) {
+        if (!ctx->inputs[0]->outcfg.formats) {
+            static const enum AVPixelFormat in_fmts[] = {
+                AV_PIX_FMT_XVBM_8,
+                AV_PIX_FMT_XVBM_10,
+                AV_PIX_FMT_NONE
+            };
+            inpix_formats  = ff_make_format_list(in_fmts);
+
+            if (!inpix_formats)
+                return AVERROR(ENOMEM);
+
+            if((ret = ff_formats_ref(inpix_formats,  &ctx->inputs[0]->outcfg.formats)) < 0)
+               goto fail;
+        }
+
+        return AVERROR(EAGAIN);
+    }
+
+    enum AVPixelFormat out_fmts[2] = {
+        AV_PIX_FMT_NONE,
+        AV_PIX_FMT_NONE
+    };
+
+    switch (ctx->inputs[0]->outcfg.formats->formats[0]) {
+        case AV_PIX_FMT_XVBM_8:
+            out_fmts[0] = AV_PIX_FMT_NV12;
+            break;
+        case AV_PIX_FMT_XVBM_10:
+            out_fmts[0] = AV_PIX_FMT_XV15;
+            break;
+        default:
+            av_log(NULL, AV_LOG_ERROR, "%s():: ff_query_formats failed: unsupported input format\n", __func__);
+            return AVERROR(EINVAL);
+    }
+
+    outpix_formats = ff_make_format_list(out_fmts);
+
+    if (!outpix_formats)
+        return AVERROR(ENOMEM);
+
+    if((ret = ff_formats_ref(outpix_formats, &ctx->outputs[0]->incfg.formats)) < 0)
+        goto fail;
+
+     return 0;
+fail:
+    if(inpix_formats) {
+        av_freep(&inpix_formats->formats);
+        av_freep(&inpix_formats);
+    }
+    if(outpix_formats) {
+        av_freep(&outpix_formats->formats);
+        av_freep(&outpix_formats);
+    }
+    return ret;
+}
+
+static int config_props(AVFilterLink *outlink)
+{
+    AVFilterContext *ctx = outlink->dst;
+    AVFilterLink *inlink = outlink->src->inputs[0];
+
+    if (inlink->w % 2 || inlink->h % 2) {
+        av_log(ctx, AV_LOG_ERROR, "Invalid odd size (%dx%d)\n",
+               inlink->w, inlink->h);
+        return AVERROR_EXIT;
+    }
+
+    outlink->w = inlink->w;
+    outlink->h = inlink->h;
+    outlink->sample_aspect_ratio = inlink->sample_aspect_ratio;
+    outlink->time_base = inlink->time_base;
+
+    return 0;
+}
+
+static av_cold int xvbm_conv_init(AVFilterContext *ctx)
+{
+    XvbmConvertContext *xc = ctx->priv;
+    int ret;
+
+    ret  = av_thread_message_queue_alloc(&xc->ReqMsgQ, MAX_REQ_MSGQ_SIZE, sizeof(XVBM_CONV_REQ_MSG));
+    ret |= av_thread_message_queue_alloc(&xc->RspMsgQ, MAX_RSP_MSGQ_SIZE, sizeof(XVBM_CONV_RSP_MSG));
+    if (ret < 0) {
+        av_log(ctx, AV_LOG_ERROR, "xvbm_conv:: Failed to allocate message queue\n");
+        exit(1);
+    }
+
+    av_log(ctx, AV_LOG_DEBUG, "xvbm_conv:: Creating xvbm_conv thread\n");
+    ret = pthread_create(&xc->thread, NULL, xvbm_conv_thread, xc);
+    if (ret) {
+        av_log(ctx, AV_LOG_ERROR, "pthread_create failed : %s\n", av_err2str(ret));
+        exit(1);
+    }
+
+    return 0;
+}
+
+static av_cold void xvbm_conv_uninit(AVFilterContext *ctx)
+{
+    int ret;
+    XvbmConvertContext *xc = ctx->priv;
+    XVBM_CONV_REQ_MSG reqMsg;
+
+    //trigger thread exit
+    reqMsg.state = XVBM_REQ_END;
+    av_thread_message_queue_send(xc->ReqMsgQ, &reqMsg, 0);
+
+    //join with ffmpeg thread
+    ret = pthread_join(xc->thread, NULL);
+    if (ret != 0) {
+        av_log(ctx, AV_LOG_ERROR, "pthread_join failed : %s\n", av_err2str(ret));
+    }
+    //free queues
+    XVBM_CONV_RSP_MSG rspMsg;
+    while (av_thread_message_queue_nb_elems(xc->ReqMsgQ)) {
+        av_thread_message_queue_recv(xc->ReqMsgQ, &reqMsg, 0);
+        av_frame_free(&reqMsg.pFrame);
+    }
+    while (av_thread_message_queue_nb_elems(xc->RspMsgQ)) {
+        av_thread_message_queue_recv(xc->RspMsgQ, &rspMsg, 0);
+        av_frame_free(&rspMsg.pFrame);
+    }
+    av_thread_message_queue_free(&xc->ReqMsgQ);
+    av_thread_message_queue_free(&xc->RspMsgQ);
+}
+
+
+static const AVFilterPad inputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .filter_frame = xvbm_convert_filter_frame,
+    }
+};
+
+static const AVFilterPad outputs[] = {
+    {
+        .name         = "default",
+        .type         = AVMEDIA_TYPE_VIDEO,
+        .config_props = config_props,
+    }
+};
+
+AVFilter ff_vf_xvbm_convert = {
+    .name            = "xvbm_convert",
+    .description     = NULL_IF_CONFIG_SMALL("convert xvbm frame to av frame"),
+    .priv_size       = sizeof(XvbmConvertContext),
+    .init            = xvbm_conv_init,
+    .uninit          = xvbm_conv_uninit,
+    FILTER_INPUTS(inputs),
+    FILTER_OUTPUTS(outputs),
+    FILTER_QUERY_FUNC(xvbm_convert_query_formats)
+};
diff --git a/libavfilter/video.c b/libavfilter/video.c
index e9eb110ff4..1e0744b001 100644
--- a/libavfilter/video.c
+++ b/libavfilter/video.c
@@ -64,8 +64,10 @@ AVFrame *ff_default_get_video_buffer2(AVFilterLink *link, int w, int h, int alig
     if (!link->frame_pool) {
         link->frame_pool = ff_frame_pool_video_init(av_buffer_allocz, w, h,
                                                     link->format, align);
-        if (!link->frame_pool)
+        if (!link->frame_pool) {
+            printf ("retuning frame pool nulll....\n");
             return NULL;
+        }
     } else {
         if (ff_frame_pool_get_video_config(link->frame_pool,
                                            &pool_width, &pool_height,
diff --git a/libavformat/Makefile b/libavformat/Makefile
index 6c6b779080..121ebea004 100644
--- a/libavformat/Makefile
+++ b/libavformat/Makefile
@@ -495,6 +495,7 @@ OBJS-$(CONFIG_RTP_MUXER)                 += rtp.o         \
                                             rtpenc_h261.o    \
                                             rtpenc_h263.o    \
                                             rtpenc_h263_rfc2190.o \
+                                            rtpenc_rfc4175.o \
                                             rtpenc_h264_hevc.o    \
                                             rtpenc_jpeg.o \
                                             rtpenc_mpv.o     \
diff --git a/libavformat/demux.c b/libavformat/demux.c
index 1620716716..83ea786569 100644
--- a/libavformat/demux.c
+++ b/libavformat/demux.c
@@ -1,5 +1,7 @@
 /*
  * Core demuxing component
+ * Modifications Copyright(C) [2024] Advanced Micro Devices, Inc.
+ *
  * Copyright (c) 2000, 2001, 2002 Fabrice Bellard
  *
  * This file is part of FFmpeg.
@@ -38,6 +40,9 @@
 #include "libavcodec/internal.h"
 #include "libavcodec/packet_internal.h"
 #include "libavcodec/raw.h"
+#include "libavcodec/avcodec.h"
+#include "libavcodec/h264_parse.h"
+#include "libavcodec/mpegutils.h"
 
 #include "avformat.h"
 #include "avio_internal.h"
@@ -1140,6 +1145,25 @@ static int parse_packet(AVFormatContext *s, AVPacket *pkt,
                                &out_pkt->data, &out_pkt->size, data, size,
                                pkt->pts, pkt->dts, pkt->pos);
 
+        //Interlace check
+        if(s->video_codec) //Need to have a codec specified
+        {
+            if(s->video_codec->name &&
+            (strcmp(s->video_codec->name, "mpsoc_vcu_h264") == 0 ||
+            strcmp(s->video_codec->name, "mpsoc_vcu_hevc") == 0))
+            {
+                //get private data
+                AVCodecParserContext *parser = av_stream_get_parser(st);
+                H264ParseContext *p = parser->priv_data;
+                //parse and check interlace
+                if(p->picture_structure == PICT_TOP_FIELD || p->picture_structure == PICT_BOTTOM_FIELD)
+                {
+                    av_log(s, AV_LOG_FATAL, "Interlace video is unsupported on this platform. Exitting...\n");
+                    return AVERROR_EXIT;
+                }
+            }
+        }
+
         pkt->pts = pkt->dts = AV_NOPTS_VALUE;
         pkt->pos = -1;
         /* increment read pointer */
diff --git a/libavformat/rtpenc.c b/libavformat/rtpenc.c
index ce629a8095..01c5b5466c 100644
--- a/libavformat/rtpenc.c
+++ b/libavformat/rtpenc.c
@@ -639,8 +639,9 @@ static int rtp_write_packet(AVFormatContext *s1, AVPacket *pkt)
         }
         /* Intentional fallthrough */
     default:
+        ff_rtp_send_raw_rfc4175 (s1, pkt->data, size, 0, 0);
         /* better than nothing : send the codec raw data */
-        rtp_send_raw(s1, pkt->data, size);
+        //rtp_send_raw(s1, pkt->data, size);
         break;
     }
     return 0;
diff --git a/libavutil/frame.c b/libavutil/frame.c
index 4c16488c66..4db5f5ec26 100644
--- a/libavutil/frame.c
+++ b/libavutil/frame.c
@@ -27,6 +27,7 @@
 #include "mem.h"
 #include "samplefmt.h"
 #include "hwcontext.h"
+#include <xvbm.h>
 
 #if FF_API_OLD_CHANNEL_LAYOUT
 #define CHECK_CHANNELS_CONSISTENCY(frame) \
@@ -35,6 +36,10 @@
                av_get_channel_layout_nb_channels((frame)->channel_layout))
 #endif
 
+#if CONFIG_LIBXMA2API
+#define IS_VCU_FORMAT(x) ((x == XMA_VCU_NV12_FMT_TYPE) || (x == XMA_VCU_NV12_10LE32_FMT_TYPE))
+#endif
+
 #if FF_API_COLORSPACE_NAME
 const char *av_get_colorspace_name(enum AVColorSpace val)
 {
@@ -343,6 +348,10 @@ static int frame_copy_props(AVFrame *dst, const AVFrame *src, int force_copy)
 int av_frame_ref(AVFrame *dst, const AVFrame *src)
 {
     int i, ret = 0;
+#if CONFIG_LIBXVBM
+    XmaFrame *xframe = NULL;
+    int num_planes;
+#endif
 
     av_assert1(dst->width == 0 && dst->height == 0);
 #if FF_API_OLD_CHANNEL_LAYOUT
@@ -454,6 +463,20 @@ FF_ENABLE_DEPRECATION_WARNINGS
     memcpy(dst->data,     src->data,     sizeof(src->data));
     memcpy(dst->linesize, src->linesize, sizeof(src->linesize));
 
+#if CONFIG_LIBXVBM
+    if ((dst->format == AV_PIX_FMT_XVBM_8) || (dst->format == AV_PIX_FMT_XVBM_10)) {
+        if (dst->data[0]) {
+            xframe = (XmaFrame*)dst->data[0];
+            if (xframe) {
+                num_planes = (IS_VCU_FORMAT(xframe->frame_props.format)  ? 1 : xma_frame_planes_get(&xframe->frame_props));
+                for(int i=0; i<num_planes; i++) {
+                    xvbm_buffer_refcnt_inc(xframe->data[i].buffer);
+                }
+            }
+        }
+    }
+#endif
+
     return 0;
 
 fail:
@@ -477,12 +500,30 @@ AVFrame *av_frame_clone(const AVFrame *src)
 void av_frame_unref(AVFrame *frame)
 {
     int i;
+#if CONFIG_LIBXVBM
+    XmaFrame *xframe = NULL;
+    int num_planes;
+#endif
 
     if (!frame)
         return;
 
     wipe_side_data(frame);
 
+#if CONFIG_LIBXVBM
+    if ((frame->format == AV_PIX_FMT_XVBM_8) || (frame->format == AV_PIX_FMT_XVBM_10)) {
+        if (frame->data[0]) {
+            xframe = (XmaFrame*)frame->data[0];
+            if (xframe) {
+                num_planes = (IS_VCU_FORMAT(xframe->frame_props.format)  ? 1 : xma_frame_planes_get(&xframe->frame_props));
+                for(int i=0; i<num_planes; i++) {
+                    xvbm_buffer_pool_entry_free(xframe->data[i].buffer);
+                }
+            }
+        }
+    }
+#endif
+
     for (i = 0; i < FF_ARRAY_ELEMS(frame->buf); i++)
         av_buffer_unref(&frame->buf[i]);
     for (i = 0; i < frame->nb_extended_buf; i++)
@@ -828,6 +869,54 @@ const char *av_frame_side_data_name(enum AVFrameSideDataType type)
     return NULL;
 }
 
+#if CONFIG_LIBXVBM
+int av_frame_clone_xma_frame (AVFrame *frame, XmaFrame *xframe)
+{
+    if ((frame->format != AV_PIX_FMT_XVBM_8) && (frame->format != AV_PIX_FMT_XVBM_10)) {
+        av_log(NULL, AV_LOG_ERROR, "unsupported pixel format : %s\n",av_get_pix_fmt_name (frame->format));
+        return AVERROR(EINVAL);
+    }
+
+    frame->data[0] = av_mallocz (sizeof (XmaFrame));
+    if (NULL == frame->data[0]) {
+        av_log(NULL, AV_LOG_ERROR, "failed to allocate memory\n");
+        return AVERROR(ENOMEM);
+    }
+
+    frame->buf[0] = av_buffer_create(frame->data[0], sizeof (XmaFrame), av_buffer_default_free, NULL, AV_BUFFER_FLAG_READONLY);
+    if (NULL == frame->data[0]) {
+        av_log(NULL, AV_LOG_ERROR, "failed to allocate memory\n");
+        av_free (frame->data[0]);
+        return AVERROR(ENOMEM);
+    }
+
+    memcpy (frame->data[0], xframe, sizeof (XmaFrame));
+
+    return 0;
+}
+
+XmaFrame *av_frame_get_xma_frame (AVFrame *frame)
+{
+    XmaFrame *xframe = NULL;
+
+    if ((frame->format != AV_PIX_FMT_XVBM_8) && (frame->format != AV_PIX_FMT_XVBM_10)) {
+        av_log(NULL, AV_LOG_ERROR, "unsupported pixel format : %s\n",av_get_pix_fmt_name (frame->format));
+        return NULL;
+    }
+
+    xframe = (XmaFrame *) calloc (sizeof (XmaFrame), 1);
+    if (NULL == xframe) {
+        av_log(NULL, AV_LOG_ERROR, "failed to allocate memory\n");
+        return NULL;
+    }
+
+    memcpy (xframe, frame->data[0], sizeof (XmaFrame));
+
+    return xframe;
+}
+#endif
+
+
 static int calc_cropping_offsets(size_t offsets[4], const AVFrame *frame,
                                  const AVPixFmtDescriptor *desc)
 {
diff --git a/libavutil/frame.h b/libavutil/frame.h
index 33fac2054c..18307751c1 100644
--- a/libavutil/frame.h
+++ b/libavutil/frame.h
@@ -203,6 +203,11 @@ enum AVFrameSideDataType {
      */
     AV_FRAME_DATA_DOVI_METADATA,
 
+    /**
+     * Xilinx XMA frame side data.
+     */
+    AV_FRAME_XLNX_HDR_SIDEBAND_DATA,
+
     /**
      * HDR Vivid dynamic metadata associated with a video frame. The payload is
      * an AVDynamicHDRVivid type and contains information for color
@@ -940,6 +945,13 @@ int av_frame_apply_cropping(AVFrame *frame, int flags);
  */
 const char *av_frame_side_data_name(enum AVFrameSideDataType type);
 
+#if CONFIG_LIBXVBM
+#include <app/xmabuffers.h>
+
+int av_frame_clone_xma_frame (AVFrame *frame, XmaFrame *xframe);
+XmaFrame *av_frame_get_xma_frame (AVFrame *frame);
+#endif
+
 /**
  * @}
  */
diff --git a/libavutil/imgutils.c b/libavutil/imgutils.c
index 9ab5757cf6..474b6c5a73 100644
--- a/libavutil/imgutils.c
+++ b/libavutil/imgutils.c
@@ -67,6 +67,11 @@ int image_get_linesize(int width, int plane,
     if (shifted_w && max_step > INT_MAX / shifted_w)
         return AVERROR(EINVAL);
     linesize = max_step * shifted_w;
+    #if CONFIG_LIBXMA2API
+    if(strcmp(desc->name, "xv15") == 0) {
+        linesize = ((width + 2) / 3) * 4;
+    }
+    #endif
 
     if (desc->flags & AV_PIX_FMT_FLAG_BITSTREAM)
         linesize = (linesize + 7) >> 3;
diff --git a/libavutil/mem.c b/libavutil/mem.c
index 18aff5291f..4bfa18678c 100644
--- a/libavutil/mem.c
+++ b/libavutil/mem.c
@@ -62,7 +62,11 @@ void  free(void *ptr);
 
 #endif /* MALLOC_PREFIX */
 
-#define ALIGN (HAVE_AVX512 ? 64 : (HAVE_AVX ? 32 : 16))
+#if CONFIG_LIBXVBM
+#define ALIGN (4096)
+#else
+ #define ALIGN (HAVE_AVX512 ? 64 : (HAVE_AVX ? 32 : 16))
+#endif //CONFIG_LIBXVBM
 
 /* NOTE: if you want to override these functions with your own
  * implementations (not recommended) you have to link libav* as
diff --git a/libavutil/pixdesc.c b/libavutil/pixdesc.c
index 6e57a82cb6..24aa200599 100644
--- a/libavutil/pixdesc.c
+++ b/libavutil/pixdesc.c
@@ -544,6 +544,42 @@ static const AVPixFmtDescriptor av_pix_fmt_descriptors[AV_PIX_FMT_NB] = {
         },
         .flags = AV_PIX_FMT_FLAG_PLANAR,
     },
+    [AV_PIX_FMT_XV15] = {
+        .name = "xv15",
+        .nb_components = 3,
+        .log2_chroma_w = 0,
+        .log2_chroma_h = 1,
+        .comp = {
+            { 0, 4, 0, 0, 10, 1, 9, 1 },        /* Y */
+            { 1, 4, 1, 0, 10, 1, 9, 1 },        /* U */
+            { 1, 4, 1, 0, 10, 1, 9, 1 },        /* V */
+        },
+        .flags = AV_PIX_FMT_FLAG_PLANAR, //get_video_buffer
+    },
+    [AV_PIX_FMT_XVBM_8] = {
+        .name = "xlnx_xvbm_8",
+        .nb_components = 3,
+        .log2_chroma_w = 1,
+        .log2_chroma_h = 1,
+        .comp = {
+            { 0, 1, 0, 0, 8, 0, 7, 1 },        /* Y */
+            { 1, 2, 0, 0, 8, 1, 7, 1 },        /* U */
+            { 1, 2, 1, 0, 8, 1, 7, 2 },        /* V */
+        },
+        .flags = AV_PIX_FMT_FLAG_HWACCEL,
+    },
+    [AV_PIX_FMT_XVBM_10] = {
+        .name = "xlnx_xvbm_10",
+        .nb_components = 3,
+        .log2_chroma_w = 1,
+        .log2_chroma_h = 1,
+        .comp = {
+            { 0, 1, 0, 0, 10, 0, 9, 1 },        /* Y */
+            { 1, 2, 0, 0, 10, 1, 9, 1 },        /* U */
+            { 1, 2, 1, 0, 10, 1, 9, 2 },        /* V */
+        },
+        .flags = AV_PIX_FMT_FLAG_HWACCEL,
+    },
     [AV_PIX_FMT_NV21] = {
         .name = "nv21",
         .nb_components = 3,
diff --git a/libavutil/pixfmt.h b/libavutil/pixfmt.h
index 2d3927cc3f..166662e9d9 100644
--- a/libavutil/pixfmt.h
+++ b/libavutil/pixfmt.h
@@ -88,6 +88,7 @@ enum AVPixelFormat {
     AV_PIX_FMT_RGB4_BYTE, ///< packed RGB 1:2:1,  8bpp, (msb)1R 2G 1B(lsb)
     AV_PIX_FMT_NV12,      ///< planar YUV 4:2:0, 12bpp, 1 plane for Y and 1 plane for the UV components, which are interleaved (first byte U and the following byte V)
     AV_PIX_FMT_NV21,      ///< as above, but U and V bytes are swapped
+    AV_PIX_FMT_XV15,      ///< 10 bpp NV12 with 3 pixels packed into 32 bit words, 2 MSB are empty.
 
     AV_PIX_FMT_ARGB,      ///< packed ARGB 8:8:8:8, 32bpp, ARGBARGB...
     AV_PIX_FMT_RGBA,      ///< packed RGBA 8:8:8:8, 32bpp, RGBARGBA...
@@ -367,6 +368,8 @@ enum AVPixelFormat {
     AV_PIX_FMT_P416BE,      ///< interleaved chroma YUV 4:4:4, 48bpp, big-endian
     AV_PIX_FMT_P416LE,      ///< interleaved chroma YUV 4:4:4, 48bpp, little-endian
 
+    AV_PIX_FMT_XVBM_8,    ///< Xilinx Video Buffer Format for 8bit Zero Copy
+    AV_PIX_FMT_XVBM_10,   ///< Xilinx Video Buffer Format for 10bit Zero Copy
     AV_PIX_FMT_NB         ///< number of pixel formats, DO NOT USE THIS if you want to link with shared libav* because the number of formats might differ between versions
 };
 
diff --git a/libswscale/input.c b/libswscale/input.c
index 4f7b1f8473..9ef8882895 100644
--- a/libswscale/input.c
+++ b/libswscale/input.c
@@ -1168,6 +1168,7 @@ av_cold void ff_sws_init_input_funcs(SwsContext *c)
     case AV_PIX_FMT_YUV422P9LE:
     case AV_PIX_FMT_YUV444P9LE:
     case AV_PIX_FMT_YUV420P10LE:
+    case AV_PIX_FMT_XV15:
     case AV_PIX_FMT_YUV422P10LE:
     case AV_PIX_FMT_YUV440P10LE:
     case AV_PIX_FMT_YUV444P10LE:
@@ -1500,6 +1501,7 @@ av_cold void ff_sws_init_input_funcs(SwsContext *c)
     case AV_PIX_FMT_YUV422P9LE:
     case AV_PIX_FMT_YUV444P9LE:
     case AV_PIX_FMT_YUV420P10LE:
+    case AV_PIX_FMT_XV15:
     case AV_PIX_FMT_YUV422P10LE:
     case AV_PIX_FMT_YUV440P10LE:
     case AV_PIX_FMT_YUV444P10LE:
diff --git a/libswscale/utils.c b/libswscale/utils.c
index cb4f5b521c..9dfd9624dd 100644
--- a/libswscale/utils.c
+++ b/libswscale/utils.c
@@ -177,6 +177,7 @@ static const FormatEntry format_entries[] = {
     [AV_PIX_FMT_YUV420P9LE]  = { 1, 1 },
     [AV_PIX_FMT_YUV420P10BE] = { 1, 1 },
     [AV_PIX_FMT_YUV420P10LE] = { 1, 1 },
+    [AV_PIX_FMT_XV15]        = { 1, 1 },
     [AV_PIX_FMT_YUV420P12BE] = { 1, 1 },
     [AV_PIX_FMT_YUV420P12LE] = { 1, 1 },
     [AV_PIX_FMT_YUV420P14BE] = { 1, 1 },
diff --git a/xmaPropsTOjson.h b/xmaPropsTOjson.h
new file mode 100644
index 0000000000..6a770ed77b
--- /dev/null
+++ b/xmaPropsTOjson.h
@@ -0,0 +1,51 @@
+/*
+ * Copyright (C) 2022-2024 Advanced Micro Devices, Inc.
+ * Copyright (C) 2020-2022 Xilinx Inc.
+ * All rights reserved.
+ *
+ * This file is part of FFmpeg.
+ *
+ * FFmpeg is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * FFmpeg is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with FFmpeg; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
+ */
+
+#ifndef _XMAPROPSTOJSON_H_
+#define _XMAPROPSTOJSON_H_
+
+//#include <string.h>
+#include <stdio.h>
+#include <syslog.h>
+//#include <vector>
+//#include <tuple>
+//#include <string>
+
+#include "/opt/xilinx/xrm/include/xrm.h"
+#include "/opt/xilinx/xrm/include/xrm_error.h"
+#include "/opt/xilinx/xrm/include/xrm_limits.h"
+#include <xma.h>
+
+#define MAX_CH_SIZE 4096
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+  void convertDecPropsToJson(void* props, char* funcName, char* jsonJob);
+  void convertDecPropsToJson1(XmaDecoderProperties* props, char* funcName, char* jsonJob);
+
+#ifdef __cplusplus
+}
+#endif
+
+#endif //_XRM_U30_CALC_PERCENT_PLUGIN_HPP_
